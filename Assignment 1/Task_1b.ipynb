{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "## 2\n",
    "\n",
    "Next, take the two well-known datasets: Fashion MNIST (introduced in Ch 10, p.  298) and CIFAR-10.The first dataset contains 2D (grayscale) images of size 28x28, split into 10 categories; 60,000 images for training  and  10,000  for  testing,  while  the  latter  contains  32x32x3  RGB  images  (50,000/10,000train/test). Apply two reference networks on the fashion MNIST dataset\n",
    "\n",
    "### b\n",
    "A convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.datasets import load_sample_image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 28 28\n"
     ]
    }
   ],
   "source": [
    "# Creating the train and test sets\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Check the dimensions \n",
    "batch_size, height, width = X_train_full.shape\n",
    "print(batch_size, height, width)\n",
    "input_shape = (height, width, 1) #because 1 channel\n",
    "\n",
    "# As it only has 1 channel we want to reshape it for symmetry\n",
    "X_train_full = X_train_full.reshape(batch_size, height, width, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], height, width, 1)\n",
    "\n",
    "# Normalising the pixel values to the range [0, 1]\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Creating a validation set of 10%\n",
    "validation_size = int(0.1 * len(X_train_full))\n",
    "\n",
    "X_valid, X_train = X_train_full[:validation_size], X_train_full[validation_size:]\n",
    "y_valid, y_train = y_train_full[:validation_size], y_train_full[validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more efficient code we\"ll change the data types to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Lets first try the model from the book\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "    keras.layers.MaxPooling2D(2), # divides each spatial dimension by 2\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"), # double filters\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), # divide dimensions by 2\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"), # again double filters\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), # needs to be 1D for dense network\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), # droupout of 50% to prevent overfitting\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 181ms/step - accuracy: 0.6105 - loss: 1.0420 - val_accuracy: 0.7513 - val_loss: 0.6913\n",
      "Epoch 2/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 195ms/step - accuracy: 0.6803 - loss: 0.8617 - val_accuracy: 0.7772 - val_loss: 0.5991\n",
      "Epoch 3/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 243ms/step - accuracy: 0.7248 - loss: 0.7464 - val_accuracy: 0.8045 - val_loss: 0.5210\n",
      "Epoch 4/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 243ms/step - accuracy: 0.7537 - loss: 0.6771 - val_accuracy: 0.8205 - val_loss: 0.4922\n",
      "Epoch 5/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 267ms/step - accuracy: 0.7758 - loss: 0.6168 - val_accuracy: 0.8308 - val_loss: 0.4667\n",
      "Epoch 6/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 304ms/step - accuracy: 0.7914 - loss: 0.5843 - val_accuracy: 0.8427 - val_loss: 0.4333\n",
      "Epoch 7/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 181ms/step - accuracy: 0.8012 - loss: 0.5542 - val_accuracy: 0.8408 - val_loss: 0.4258\n",
      "Epoch 8/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 208ms/step - accuracy: 0.8134 - loss: 0.5294 - val_accuracy: 0.8518 - val_loss: 0.3974\n",
      "Epoch 9/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 225ms/step - accuracy: 0.8200 - loss: 0.5124 - val_accuracy: 0.8540 - val_loss: 0.4051\n",
      "Epoch 10/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 227ms/step - accuracy: 0.8268 - loss: 0.4963 - val_accuracy: 0.8558 - val_loss: 0.3844\n",
      "Epoch 11/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 219ms/step - accuracy: 0.8310 - loss: 0.4820 - val_accuracy: 0.8598 - val_loss: 0.3715\n",
      "Epoch 12/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 894ms/step - accuracy: 0.8340 - loss: 0.4705 - val_accuracy: 0.8705 - val_loss: 0.3584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255dae40620>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=12, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.39081478118896484\n",
      "Test accuracy: 0.857699990272522\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
