{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "## 2\n",
    "\n",
    "Next, take the two well-known datasets: Fashion MNIST (introduced in Ch 10, p.  298) and CIFAR-10.The first dataset contains 2D (grayscale) images of size 28x28, split into 10 categories; 60,000 images for training  and  10,000  for  testing,  while  the  latter  contains  32x32x3  RGB  images  (50,000/10,000train/test). Apply two reference networks on the fashion MNIST dataset\n",
    "\n",
    "### b\n",
    "A convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.datasets import load_sample_image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 28 28\n"
     ]
    }
   ],
   "source": [
    "# Creating the train and test sets\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Check the dimensions \n",
    "batch_size, height, width = X_train_full.shape\n",
    "print(batch_size, height, width)\n",
    "input_shape = (height, width, 1) #because 1 channel\n",
    "\n",
    "# As it only has 1 channel we want to reshape it for symmetry\n",
    "X_train_full = X_train_full.reshape(batch_size, height, width, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], height, width, 1)\n",
    "\n",
    "# Normalising the pixel values to the range [0, 1]\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Creating a validation set of 10%\n",
    "validation_size = int(0.1 * len(X_train_full))\n",
    "\n",
    "X_valid, X_train = X_train_full[:validation_size], X_train_full[validation_size:]\n",
    "y_valid, y_train = y_train_full[:validation_size], y_train_full[validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more efficient code we\"ll change the data types to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Lets first try the model from the book\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "    keras.layers.MaxPooling2D(2), # divides each spatial dimension by 2\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"), # double filters\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), # divide dimensions by 2\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"), # again double filters\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), # needs to be 1D for dense network\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), # droupout of 50% to prevent overfitting\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m3,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m295,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,413,836</span> (5.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,413,836\u001b[0m (5.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,413,834</span> (5.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,413,834\u001b[0m (5.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 181ms/step - accuracy: 0.6105 - loss: 1.0420 - val_accuracy: 0.7513 - val_loss: 0.6913\n",
      "Epoch 2/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 195ms/step - accuracy: 0.6803 - loss: 0.8617 - val_accuracy: 0.7772 - val_loss: 0.5991\n",
      "Epoch 3/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 243ms/step - accuracy: 0.7248 - loss: 0.7464 - val_accuracy: 0.8045 - val_loss: 0.5210\n",
      "Epoch 4/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 243ms/step - accuracy: 0.7537 - loss: 0.6771 - val_accuracy: 0.8205 - val_loss: 0.4922\n",
      "Epoch 5/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 267ms/step - accuracy: 0.7758 - loss: 0.6168 - val_accuracy: 0.8308 - val_loss: 0.4667\n",
      "Epoch 6/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 304ms/step - accuracy: 0.7914 - loss: 0.5843 - val_accuracy: 0.8427 - val_loss: 0.4333\n",
      "Epoch 7/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 181ms/step - accuracy: 0.8012 - loss: 0.5542 - val_accuracy: 0.8408 - val_loss: 0.4258\n",
      "Epoch 8/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 208ms/step - accuracy: 0.8134 - loss: 0.5294 - val_accuracy: 0.8518 - val_loss: 0.3974\n",
      "Epoch 9/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 225ms/step - accuracy: 0.8200 - loss: 0.5124 - val_accuracy: 0.8540 - val_loss: 0.4051\n",
      "Epoch 10/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 227ms/step - accuracy: 0.8268 - loss: 0.4963 - val_accuracy: 0.8558 - val_loss: 0.3844\n",
      "Epoch 11/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 219ms/step - accuracy: 0.8310 - loss: 0.4820 - val_accuracy: 0.8598 - val_loss: 0.3715\n",
      "Epoch 12/12\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 894ms/step - accuracy: 0.8340 - loss: 0.4705 - val_accuracy: 0.8705 - val_loss: 0.3584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255dae40620>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=12, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put a break in between for the health of my laptop. If needed ill keep adding epochs in steps of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 169ms/step - accuracy: 0.8419 - loss: 0.4554 - val_accuracy: 0.8705 - val_loss: 0.3512\n",
      "Epoch 2/2\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 228ms/step - accuracy: 0.8487 - loss: 0.4360 - val_accuracy: 0.8732 - val_loss: 0.3538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255dada3bc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try 2 more. 14 in total now\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=2, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 158ms/step - accuracy: 0.8482 - loss: 0.4289 - val_accuracy: 0.8735 - val_loss: 0.3348\n",
      "Epoch 2/2\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 189ms/step - accuracy: 0.8494 - loss: 0.4259 - val_accuracy: 0.8797 - val_loss: 0.3319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255dada22a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 more, now 16\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=2, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 168ms/step - accuracy: 0.8559 - loss: 0.4202 - val_accuracy: 0.8748 - val_loss: 0.3282\n",
      "Epoch 2/4\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 205ms/step - accuracy: 0.8618 - loss: 0.4018 - val_accuracy: 0.8818 - val_loss: 0.3296\n",
      "Epoch 3/4\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 245ms/step - accuracy: 0.8618 - loss: 0.3985 - val_accuracy: 0.8762 - val_loss: 0.3352\n",
      "Epoch 4/4\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 245ms/step - accuracy: 0.8658 - loss: 0.3851 - val_accuracy: 0.8853 - val_loss: 0.3154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255daf5c140>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 more, now 20\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=4, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.345167875289917\n",
      "Test accuracy: 0.8741000294685364\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took quite a while. In theory this could give an accuracy of 92% on the test set according to the book. This is already better than the results from the MLP model. The official repository mentioned in the assignment contained a file called example_mnist_cnn.py. They made a different cnn model which they ran on the MNIST dataset. They claim to score over 99% accuracy on the test set in only 12 epochs. I used this model with some modifications in the following section to see how it would perform on the fashion_MNIST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 75ms/step - accuracy: 0.1058 - loss: 2.3027 - val_accuracy: 0.3632 - val_loss: 2.2230\n",
      "Epoch 2/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 75ms/step - accuracy: 0.2311 - loss: 2.2150 - val_accuracy: 0.5563 - val_loss: 2.1150\n",
      "Epoch 3/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 80ms/step - accuracy: 0.3233 - loss: 2.1149 - val_accuracy: 0.5910 - val_loss: 1.9829\n",
      "Epoch 4/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 83ms/step - accuracy: 0.3890 - loss: 1.9941 - val_accuracy: 0.6025 - val_loss: 1.8298\n",
      "Epoch 5/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 87ms/step - accuracy: 0.4430 - loss: 1.8561 - val_accuracy: 0.6180 - val_loss: 1.6637\n",
      "Epoch 6/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 92ms/step - accuracy: 0.4689 - loss: 1.7144 - val_accuracy: 0.6327 - val_loss: 1.5022\n",
      "Epoch 7/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 84ms/step - accuracy: 0.4961 - loss: 1.5834 - val_accuracy: 0.6418 - val_loss: 1.3608\n",
      "Epoch 8/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 89ms/step - accuracy: 0.5179 - loss: 1.4753 - val_accuracy: 0.6478 - val_loss: 1.2465\n",
      "Epoch 9/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 91ms/step - accuracy: 0.5323 - loss: 1.3848 - val_accuracy: 0.6573 - val_loss: 1.1578\n",
      "Epoch 10/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 91ms/step - accuracy: 0.5469 - loss: 1.3158 - val_accuracy: 0.6630 - val_loss: 1.0889\n",
      "Epoch 11/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 100ms/step - accuracy: 0.5637 - loss: 1.2621 - val_accuracy: 0.6688 - val_loss: 1.0342\n",
      "Epoch 12/12\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 94ms/step - accuracy: 0.5729 - loss: 1.2157 - val_accuracy: 0.6785 - val_loss: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255db013980>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model_cnn = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(32, kernel_size=(3,3),\n",
    "                                activation= 'relu',\n",
    "                                input_shape=input_shape), #uses a smaller filter size. No padding function is suplied so the default \"valid\"\n",
    "                                                        #will be used. This means a reduction in dimension will be applied\n",
    "        keras.layers.Conv2D(64, (3,3), activation='relu'), #uses less convolutional layers and of smaller size\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)), # only one time maxpooling used\n",
    "        keras.layers.Dropout(0.25), # smaller dropout\n",
    "        # fully connected network:\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(10, activation='softmax') # output layer\n",
    "])\n",
    "\n",
    "\n",
    "model_cnn.compile(loss=keras.losses.categorical_crossentropy, # because output is changed to categorical instead of integers\n",
    "                optimizer=keras.optimizers.Adadelta(), # uses a different optimizer. Adadelta has an adaptive learning rate so no need for manual tweeking\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_cnn.fit(X_train, y_train,\n",
    "        batch_size=128,\n",
    "        epochs=12,\n",
    "        verbose=1,\n",
    "        validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.010797142982483\n",
      "Test accuracy: 0.6638000011444092\n"
     ]
    }
   ],
   "source": [
    "score = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs worse on the data than the example from the book but we can use it to modify things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to edit some things to see if it becomes more efficient. Ideas:\n",
    "- add an extra convolutional layer \n",
    "- keep output categories as integers as this won't require convertion\n",
    "- decrease dropout last time\n",
    "- keep adadelta for the learnig rate\n",
    "- change relu to LeakyReLU\n",
    "- changing the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo the transformation\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis= 1)\n",
    "y_valid = np.argmax(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 179ms/step - accuracy: 0.1101 - loss: 2.3013 - val_accuracy: 0.3533 - val_loss: 2.2884\n",
      "Epoch 2/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 230ms/step - accuracy: 0.1796 - loss: 2.2862 - val_accuracy: 0.4517 - val_loss: 2.2607\n",
      "Epoch 3/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 205ms/step - accuracy: 0.2242 - loss: 2.2548 - val_accuracy: 0.4117 - val_loss: 2.1789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255e84e7860>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, 7, padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "        keras.layers.LeakyReLU(alpha = 0.1), # add leakyrelu\n",
    "        keras.layers.MaxPooling2D(2), \n",
    "        keras.layers.Conv2D(128, 3, padding=\"same\"),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1), \n",
    "        keras.layers.Conv2D(128, 3, padding=\"same\"),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.MaxPooling2D(2), # \n",
    "        keras.layers.Conv2D(256, 3, padding=\"same\"), \n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.Conv2D(256, 3, padding=\"same\"),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.MaxPooling2D(2), \n",
    "        # fully connected network:\n",
    "        keras.layers.Flatten(), \n",
    "        keras.layers.Dense(128),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.Dropout(0.5), # droupout of 50% to prevent overfitting\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.Dropout(0.25), # change to 25%\n",
    "        keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])\n",
    "\n",
    "\n",
    "model_imp.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=keras.optimizers.Adadelta(), # keeep adadelta\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_imp.fit(X_train, y_train, batch_size=64, epochs=3, validation_data=(X_valid, y_valid)) # only 3 to see if it performs similar in the beginning to previous models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.181572675704956\n",
      "Test accuracy: 0.397599995136261\n"
     ]
    }
   ],
   "source": [
    "score = model_imp.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this performed a lot worse. Lets edit the original code one feature at the time. I'll only do 3 epochs per test because of computation time. <br>\n",
    "At 3 epochs the original model performed like this: <br>\n",
    "-accuracy: 0.7248 - loss: 0.7464 - val_accuracy: 0.8045 - val_loss: 0.5210 <br>\n",
    "\n",
    "- First changing relu to leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 185ms/step - accuracy: 0.2798 - loss: 1.9559 - val_accuracy: 0.7107 - val_loss: 0.8080\n",
      "Epoch 2/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 223ms/step - accuracy: 0.6408 - loss: 0.9795 - val_accuracy: 0.7612 - val_loss: 0.6557\n",
      "Epoch 3/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 188ms/step - accuracy: 0.7106 - loss: 0.7956 - val_accuracy: 0.7803 - val_loss: 0.5784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2561603aba0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, 7, padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "        keras.layers.LeakyReLU(alpha = 0.1), # add leakyrelu\n",
    "        keras.layers.MaxPooling2D(2), \n",
    "        keras.layers.Conv2D(128, 3, padding=\"same\"),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1), \n",
    "        keras.layers.Conv2D(128, 3, padding=\"same\"),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.MaxPooling2D(2), # \n",
    "        keras.layers.Conv2D(256, 3, padding=\"same\"), \n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.Conv2D(256, 3, padding=\"same\"),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.MaxPooling2D(2), \n",
    "        # fully connected network:\n",
    "        keras.layers.Flatten(), \n",
    "        keras.layers.Dense(128),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.Dropout(0.5), \n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.LeakyReLU(alpha = 0.1),\n",
    "        keras.layers.Dropout(0.5), \n",
    "        keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])\n",
    "\n",
    "\n",
    "model_imp.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_imp.fit(X_train, y_train, batch_size=64, epochs=3, validation_data=(X_valid, y_valid)) # only 3 to see if it performs similar in the beginning to previous models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to perform slightly worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decreasing the last dropout percentage to 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 190ms/step - accuracy: 0.2957 - loss: 1.9203 - val_accuracy: 0.7237 - val_loss: 0.7599\n",
      "Epoch 2/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 199ms/step - accuracy: 0.6655 - loss: 0.9033 - val_accuracy: 0.7713 - val_loss: 0.6273\n",
      "Epoch 3/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 171ms/step - accuracy: 0.7236 - loss: 0.7438 - val_accuracy: 0.7863 - val_loss: 0.5517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255ece2d1f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), \n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25), # decrease dropout\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])\n",
    "\n",
    "model_imp.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_imp.fit(X_train, y_train, batch_size=64, epochs=3, validation_data=(X_valid, y_valid)) # only 3 to see if it performs similar in the beginning to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs similar to the original but it overfits more as the validation set performs worse. For this reason I believe that completely removing the dropout layer would result in worse results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 185ms/step - accuracy: 0.1015 - loss: 2.3020 - val_accuracy: 0.0990 - val_loss: 2.2942\n",
      "Epoch 2/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 200ms/step - accuracy: 0.1324 - loss: 2.2937 - val_accuracy: 0.1380 - val_loss: 2.2814\n",
      "Epoch 3/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 199ms/step - accuracy: 0.1552 - loss: 2.2811 - val_accuracy: 0.1523 - val_loss: 2.2589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x255e9add6a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), \n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), # decrease dropout\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])\n",
    "\n",
    "model_imp.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=keras.optimizers.Adadelta(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_imp.fit(X_train, y_train, batch_size=64, epochs=3, validation_data=(X_valid, y_valid)) # only 3 to see if it performs similar in the beginning to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What if we add another convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 291ms/step - accuracy: 0.2202 - loss: 2.1341 - val_accuracy: 0.6547 - val_loss: 0.9005\n",
      "Epoch 2/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 345ms/step - accuracy: 0.5881 - loss: 1.1034 - val_accuracy: 0.7435 - val_loss: 0.7300\n",
      "Epoch 3/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 327ms/step - accuracy: 0.6733 - loss: 0.8841 - val_accuracy: 0.7685 - val_loss: 0.6340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x249ad2d2630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"), # additional layer\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), \n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])\n",
    "\n",
    "model_imp.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_imp.fit(X_train, y_train, batch_size=64, epochs=3, validation_data=(X_valid, y_valid)) # only 3 to see if it performs similar in the beginning to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is worse than the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Changing the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 65ms/step - accuracy: 0.2286 - loss: 2.1030 - val_accuracy: 0.6370 - val_loss: 1.0333\n",
      "Epoch 2/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 99ms/step - accuracy: 0.5554 - loss: 1.1894 - val_accuracy: 0.7077 - val_loss: 0.8173\n",
      "Epoch 3/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 70ms/step - accuracy: 0.6590 - loss: 0.9221 - val_accuracy: 0.7538 - val_loss: 0.6606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x249b5469370>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imp = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"valid\",\n",
    "                        input_shape = input_shape), \n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"valid\"),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"valid\"), #MaxPooling layer removed as output is smaller with valid padding\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"valid\"), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"valid\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), \n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "model_imp.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_imp.fit(X_train, y_train, batch_size=64, epochs=3, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this is worse than the base level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately non of the modifications performed better than the base model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
