{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "## 2\n",
    "\n",
    "After you have found the best-performing hyperparameter sets, take the 3 best onesand train new models on the CIFAR-10 dataset to see whether your performance gains translate to a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.datasets import load_sample_image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating the train and test sets\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(X_train_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare this to the fashion_MNIST dataset we can see the following:\n",
    "- the dimensions of each image is bigger\n",
    "- it has 3 channels instead of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, height, width, channels = X_train_full.shape\n",
    "input_shape = (height, width, channels)\n",
    "\n",
    "# Normalising the pixel values to the range [0, 1]\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Creating a validation set of 10%\n",
    "validation_size = int(0.1 * len(X_train_full))\n",
    "\n",
    "X_valid, X_train = X_train_full[:validation_size], X_train_full[validation_size:]\n",
    "y_valid, y_train = y_train_full[:validation_size], y_train_full[validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more efficient code we\"ll change the data types to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first try to run the final MLP model on this dataset. For the fashion_mnist dataset this model had an accuracy of 88.2% and a loss of 33.2% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.1445 - loss: 2.2809 - val_accuracy: 0.2512 - val_loss: 2.0319\n",
      "Epoch 2/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2225 - loss: 2.0813 - val_accuracy: 0.3316 - val_loss: 1.9067\n",
      "Epoch 3/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2627 - loss: 2.0054 - val_accuracy: 0.3436 - val_loss: 1.8800\n",
      "Epoch 4/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2814 - loss: 1.9548 - val_accuracy: 0.3372 - val_loss: 1.8452\n",
      "Epoch 5/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2990 - loss: 1.9237 - val_accuracy: 0.3702 - val_loss: 1.8013\n",
      "Epoch 6/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3140 - loss: 1.8935 - val_accuracy: 0.3668 - val_loss: 1.7764\n",
      "Epoch 7/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3205 - loss: 1.8641 - val_accuracy: 0.3834 - val_loss: 1.7509\n",
      "Epoch 8/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3361 - loss: 1.8433 - val_accuracy: 0.3806 - val_loss: 1.7300\n",
      "Epoch 9/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3397 - loss: 1.8266 - val_accuracy: 0.3606 - val_loss: 1.7462\n",
      "Epoch 10/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3508 - loss: 1.8094 - val_accuracy: 0.3978 - val_loss: 1.6959\n",
      "Epoch 11/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3579 - loss: 1.7940 - val_accuracy: 0.4046 - val_loss: 1.6831\n",
      "Epoch 12/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3582 - loss: 1.7906 - val_accuracy: 0.4134 - val_loss: 1.6718\n",
      "Epoch 13/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3669 - loss: 1.7572 - val_accuracy: 0.3842 - val_loss: 1.7117\n",
      "Epoch 14/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3710 - loss: 1.7620 - val_accuracy: 0.3902 - val_loss: 1.7176\n",
      "Epoch 15/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3751 - loss: 1.7387 - val_accuracy: 0.4084 - val_loss: 1.6497\n",
      "Epoch 16/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3804 - loss: 1.7253 - val_accuracy: 0.4058 - val_loss: 1.6451\n",
      "Epoch 17/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3779 - loss: 1.7273 - val_accuracy: 0.4302 - val_loss: 1.6140\n",
      "Epoch 18/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3873 - loss: 1.7147 - val_accuracy: 0.4326 - val_loss: 1.5940\n",
      "Epoch 19/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3937 - loss: 1.7093 - val_accuracy: 0.4222 - val_loss: 1.6114\n",
      "Epoch 20/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3932 - loss: 1.6992 - val_accuracy: 0.4144 - val_loss: 1.6060\n",
      "Epoch 21/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3966 - loss: 1.6844 - val_accuracy: 0.3798 - val_loss: 1.7285\n",
      "Epoch 22/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4005 - loss: 1.6767 - val_accuracy: 0.4374 - val_loss: 1.5915\n",
      "Epoch 23/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4002 - loss: 1.6711 - val_accuracy: 0.4376 - val_loss: 1.5622\n",
      "Epoch 24/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4073 - loss: 1.6590 - val_accuracy: 0.4238 - val_loss: 1.5964\n",
      "Epoch 25/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4044 - loss: 1.6586 - val_accuracy: 0.4420 - val_loss: 1.5510\n",
      "Epoch 26/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4152 - loss: 1.6412 - val_accuracy: 0.4304 - val_loss: 1.6044\n",
      "Epoch 27/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4140 - loss: 1.6428 - val_accuracy: 0.4270 - val_loss: 1.5757\n",
      "Epoch 28/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4129 - loss: 1.6406 - val_accuracy: 0.4466 - val_loss: 1.5490\n",
      "Epoch 29/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4192 - loss: 1.6262 - val_accuracy: 0.4474 - val_loss: 1.5452\n",
      "Epoch 30/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4174 - loss: 1.6293 - val_accuracy: 0.4476 - val_loss: 1.5458\n",
      "Epoch 31/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4181 - loss: 1.6201 - val_accuracy: 0.4700 - val_loss: 1.5133\n",
      "Epoch 32/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4245 - loss: 1.6243 - val_accuracy: 0.4508 - val_loss: 1.5217\n",
      "Epoch 33/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4206 - loss: 1.6117 - val_accuracy: 0.4434 - val_loss: 1.5239\n",
      "Epoch 34/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4243 - loss: 1.6127 - val_accuracy: 0.4418 - val_loss: 1.5533\n",
      "Epoch 35/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4285 - loss: 1.6007 - val_accuracy: 0.4506 - val_loss: 1.5586\n",
      "Epoch 36/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4286 - loss: 1.5988 - val_accuracy: 0.4538 - val_loss: 1.5239\n",
      "Epoch 37/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4271 - loss: 1.6005 - val_accuracy: 0.4664 - val_loss: 1.4971\n",
      "Epoch 38/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4380 - loss: 1.5765 - val_accuracy: 0.4722 - val_loss: 1.4930\n",
      "Epoch 39/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4335 - loss: 1.5812 - val_accuracy: 0.4690 - val_loss: 1.4924\n",
      "Epoch 40/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4392 - loss: 1.5801 - val_accuracy: 0.4622 - val_loss: 1.4801\n",
      "Epoch 41/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4361 - loss: 1.5753 - val_accuracy: 0.4604 - val_loss: 1.4908\n",
      "Epoch 42/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4436 - loss: 1.5637 - val_accuracy: 0.4496 - val_loss: 1.4979\n",
      "Epoch 43/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4410 - loss: 1.5623 - val_accuracy: 0.4744 - val_loss: 1.4864\n",
      "Epoch 44/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4425 - loss: 1.5575 - val_accuracy: 0.4680 - val_loss: 1.4827\n",
      "Epoch 45/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4439 - loss: 1.5636 - val_accuracy: 0.4758 - val_loss: 1.4601\n",
      "Epoch 46/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4423 - loss: 1.5603 - val_accuracy: 0.4776 - val_loss: 1.4595\n",
      "Epoch 47/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4461 - loss: 1.5519 - val_accuracy: 0.4528 - val_loss: 1.5282\n",
      "Epoch 48/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4460 - loss: 1.5504 - val_accuracy: 0.4590 - val_loss: 1.4820\n",
      "Epoch 49/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4480 - loss: 1.5392 - val_accuracy: 0.4864 - val_loss: 1.4430\n",
      "Epoch 50/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4481 - loss: 1.5424 - val_accuracy: 0.4590 - val_loss: 1.4902\n",
      "Epoch 51/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4458 - loss: 1.5388 - val_accuracy: 0.4706 - val_loss: 1.4794\n",
      "Epoch 52/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4560 - loss: 1.5313 - val_accuracy: 0.4712 - val_loss: 1.4570\n",
      "Epoch 53/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4495 - loss: 1.5371 - val_accuracy: 0.4866 - val_loss: 1.4584\n",
      "Epoch 54/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4589 - loss: 1.5238 - val_accuracy: 0.4818 - val_loss: 1.4477\n",
      "Epoch 55/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4548 - loss: 1.5253 - val_accuracy: 0.4918 - val_loss: 1.4298\n",
      "Epoch 56/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4564 - loss: 1.5139 - val_accuracy: 0.4758 - val_loss: 1.4829\n",
      "Epoch 57/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4518 - loss: 1.5226 - val_accuracy: 0.4988 - val_loss: 1.4268\n",
      "Epoch 58/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4590 - loss: 1.5134 - val_accuracy: 0.4696 - val_loss: 1.4835\n",
      "Epoch 59/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4589 - loss: 1.5143 - val_accuracy: 0.4884 - val_loss: 1.4253\n",
      "Epoch 60/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4651 - loss: 1.5043 - val_accuracy: 0.4886 - val_loss: 1.4344\n",
      "Epoch 61/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4611 - loss: 1.5024 - val_accuracy: 0.4934 - val_loss: 1.4313\n",
      "Epoch 62/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4619 - loss: 1.5021 - val_accuracy: 0.4960 - val_loss: 1.4277\n",
      "Epoch 63/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4613 - loss: 1.5042 - val_accuracy: 0.4834 - val_loss: 1.4279\n",
      "Epoch 64/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4692 - loss: 1.4924 - val_accuracy: 0.4982 - val_loss: 1.4147\n",
      "Epoch 65/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4677 - loss: 1.4806 - val_accuracy: 0.5090 - val_loss: 1.4093\n",
      "Epoch 66/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4722 - loss: 1.4828 - val_accuracy: 0.4960 - val_loss: 1.4425\n",
      "Epoch 67/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4729 - loss: 1.4826 - val_accuracy: 0.5028 - val_loss: 1.4082\n",
      "Epoch 68/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4653 - loss: 1.4861 - val_accuracy: 0.4650 - val_loss: 1.4751\n",
      "Epoch 69/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4698 - loss: 1.4841 - val_accuracy: 0.5070 - val_loss: 1.3996\n",
      "Epoch 70/70\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4750 - loss: 1.4687 - val_accuracy: 0.4932 - val_loss: 1.4236\n",
      "epochs used: 69\n",
      "Test loss: 1.3912239074707031\n",
      "Test accuracy: 0.5059999823570251\n"
     ]
    }
   ],
   "source": [
    "model_mlp = keras.models.Sequential()\n",
    "model_mlp.add(keras.layers.Flatten(input_shape = input_shape)) # adjusted input shape\n",
    "\n",
    "model_mlp.add(keras.layers.Dense(300))\n",
    "model_mlp.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_mlp.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_mlp.add(keras.layers.Dense(200))\n",
    "model_mlp.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_mlp.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_mlp.add(keras.layers.Dense(100))\n",
    "model_mlp.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "model_mlp.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_mlp.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "model_mlp.compile(loss = \"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate = learning_rate), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience= 7, restore_best_weights= True) \n",
    "history = model_mlp.fit(X_train, y_train, epochs=70, # try 70\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks = [early_stopping]) \n",
    "\n",
    "# final score\n",
    "score_all = model_mlp.evaluate(X_test, y_test, verbose=0)\n",
    "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "print('epochs used:', best_epoch)\n",
    "print('Test loss:', score_all[0])\n",
    "print('Test accuracy:', score_all[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy seems to still be increasing so lets add 30 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4718 - loss: 1.4832 - val_accuracy: 0.5026 - val_loss: 1.4069\n",
      "Epoch 2/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4739 - loss: 1.4633 - val_accuracy: 0.5022 - val_loss: 1.3944\n",
      "Epoch 3/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4715 - loss: 1.4771 - val_accuracy: 0.4898 - val_loss: 1.4215\n",
      "Epoch 4/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4740 - loss: 1.4711 - val_accuracy: 0.5118 - val_loss: 1.3905\n",
      "Epoch 5/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4751 - loss: 1.4671 - val_accuracy: 0.4890 - val_loss: 1.4259\n",
      "Epoch 6/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4728 - loss: 1.4646 - val_accuracy: 0.4860 - val_loss: 1.4090\n",
      "Epoch 7/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4780 - loss: 1.4655 - val_accuracy: 0.4954 - val_loss: 1.3941\n",
      "Epoch 8/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4804 - loss: 1.4549 - val_accuracy: 0.5042 - val_loss: 1.3937\n",
      "Epoch 9/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4791 - loss: 1.4527 - val_accuracy: 0.4886 - val_loss: 1.4079\n",
      "Epoch 10/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4793 - loss: 1.4605 - val_accuracy: 0.4998 - val_loss: 1.3835\n",
      "Epoch 11/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4766 - loss: 1.4685 - val_accuracy: 0.5088 - val_loss: 1.3792\n",
      "Epoch 12/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4834 - loss: 1.4460 - val_accuracy: 0.5048 - val_loss: 1.3816\n",
      "Epoch 13/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4833 - loss: 1.4438 - val_accuracy: 0.5042 - val_loss: 1.4020\n",
      "Epoch 14/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4810 - loss: 1.4525 - val_accuracy: 0.5020 - val_loss: 1.3781\n",
      "Epoch 15/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4865 - loss: 1.4427 - val_accuracy: 0.5060 - val_loss: 1.3814\n",
      "Epoch 16/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4909 - loss: 1.4339 - val_accuracy: 0.4900 - val_loss: 1.4047\n",
      "Epoch 17/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4832 - loss: 1.4428 - val_accuracy: 0.5204 - val_loss: 1.3695\n",
      "Epoch 18/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4878 - loss: 1.4309 - val_accuracy: 0.4942 - val_loss: 1.3928\n",
      "Epoch 19/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4927 - loss: 1.4350 - val_accuracy: 0.4922 - val_loss: 1.4104\n",
      "Epoch 20/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4901 - loss: 1.4352 - val_accuracy: 0.4962 - val_loss: 1.4250\n",
      "Epoch 21/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4882 - loss: 1.4391 - val_accuracy: 0.5026 - val_loss: 1.3856\n",
      "Epoch 22/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4926 - loss: 1.4202 - val_accuracy: 0.5148 - val_loss: 1.3915\n",
      "Epoch 23/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4899 - loss: 1.4312 - val_accuracy: 0.5104 - val_loss: 1.3628\n",
      "Epoch 24/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4915 - loss: 1.4299 - val_accuracy: 0.5178 - val_loss: 1.3656\n",
      "Epoch 25/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4957 - loss: 1.4169 - val_accuracy: 0.4982 - val_loss: 1.4124\n",
      "Epoch 26/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4956 - loss: 1.4155 - val_accuracy: 0.5124 - val_loss: 1.3634\n",
      "Epoch 27/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4937 - loss: 1.4202 - val_accuracy: 0.5134 - val_loss: 1.4082\n",
      "Epoch 28/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5001 - loss: 1.4051 - val_accuracy: 0.5096 - val_loss: 1.3707\n",
      "Epoch 29/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4969 - loss: 1.4178 - val_accuracy: 0.4944 - val_loss: 1.4096\n",
      "Epoch 30/30\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4937 - loss: 1.4142 - val_accuracy: 0.4848 - val_loss: 1.4404\n",
      "epochs used: 23\n",
      "Test loss: 1.3591619729995728\n",
      "Test accuracy: 0.5094000101089478\n"
     ]
    }
   ],
   "source": [
    "history = model_mlp.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks = [early_stopping]) \n",
    "\n",
    "# final score\n",
    "score_all = model_mlp.evaluate(X_test, y_test, verbose=0)\n",
    "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "print('epochs used:', best_epoch)\n",
    "print('Test loss:', score_all[0])\n",
    "print('Test accuracy:', score_all[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a bad score. The model's performance does not seem to translate to the CIFAR10 dataset. This could be because of the fact that this CIFAR10 dataset is a lot more complex than the fashion_MNIST dataset. The MLP model therefore most likely is not complex enough due to insufficient layers. Also the model was made with data with only 1 channel in mind, the model now flattens CIFAR10's imagages. This results in a loss of information on the arrangement of the pixels. This makes it very hard for the model to recognize patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's also try the best CNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsuik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 242ms/step - accuracy: 0.1219 - loss: 2.2886 - val_accuracy: 0.1248 - val_loss: 2.2764\n",
      "Epoch 2/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 273ms/step - accuracy: 0.1937 - loss: 2.1543 - val_accuracy: 0.1326 - val_loss: 2.8423\n",
      "Epoch 3/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 300ms/step - accuracy: 0.2402 - loss: 2.0566 - val_accuracy: 0.3304 - val_loss: 1.8589\n",
      "Epoch 4/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 312ms/step - accuracy: 0.2807 - loss: 1.9451 - val_accuracy: 0.3632 - val_loss: 1.7788\n",
      "Epoch 5/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 296ms/step - accuracy: 0.3186 - loss: 1.8541 - val_accuracy: 0.1938 - val_loss: 2.3564\n",
      "Epoch 6/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 310ms/step - accuracy: 0.3397 - loss: 1.7846 - val_accuracy: 0.4320 - val_loss: 1.6229\n",
      "Epoch 7/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 303ms/step - accuracy: 0.3732 - loss: 1.7135 - val_accuracy: 0.4532 - val_loss: 1.5524\n",
      "Epoch 8/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 321ms/step - accuracy: 0.3972 - loss: 1.6536 - val_accuracy: 0.4498 - val_loss: 1.5123\n",
      "Epoch 9/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 306ms/step - accuracy: 0.4081 - loss: 1.6166 - val_accuracy: 0.4508 - val_loss: 1.5368\n",
      "Epoch 10/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 311ms/step - accuracy: 0.4332 - loss: 1.5640 - val_accuracy: 0.3780 - val_loss: 1.8414\n",
      "Epoch 11/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 292ms/step - accuracy: 0.4507 - loss: 1.5317 - val_accuracy: 0.4168 - val_loss: 1.7127\n",
      "Epoch 12/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 245ms/step - accuracy: 0.4614 - loss: 1.4943 - val_accuracy: 0.4914 - val_loss: 1.4111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c9d8be3770>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn1 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "    keras.layers.MaxPooling2D(2), # divides each spatial dimension by 2\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"), # double filters\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), # divide dimensions by 2\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"), # again double filters\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), # needs to be 1D for dense network\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), # droupout of 50% to prevent overfitting\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])\n",
    "\n",
    "model_cnn1.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_cnn1.fit(X_train, y_train, batch_size=64, epochs=12, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets do 12 more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 210ms/step - accuracy: 0.4765 - loss: 1.4557 - val_accuracy: 0.4732 - val_loss: 1.4899\n",
      "Epoch 2/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 259ms/step - accuracy: 0.4919 - loss: 1.4189 - val_accuracy: 0.3920 - val_loss: 1.6465\n",
      "Epoch 3/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 299ms/step - accuracy: 0.5130 - loss: 1.3672 - val_accuracy: 0.5084 - val_loss: 1.4694\n",
      "Epoch 4/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 292ms/step - accuracy: 0.5222 - loss: 1.3439 - val_accuracy: 0.5220 - val_loss: 1.3723\n",
      "Epoch 5/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 323ms/step - accuracy: 0.5372 - loss: 1.3018 - val_accuracy: 0.4480 - val_loss: 1.5795\n",
      "Epoch 6/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 333ms/step - accuracy: 0.5499 - loss: 1.2811 - val_accuracy: 0.5848 - val_loss: 1.1720\n",
      "Epoch 7/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 305ms/step - accuracy: 0.5676 - loss: 1.2214 - val_accuracy: 0.5034 - val_loss: 1.4022\n",
      "Epoch 8/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 298ms/step - accuracy: 0.5852 - loss: 1.1957 - val_accuracy: 0.6342 - val_loss: 1.0712\n",
      "Epoch 9/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 306ms/step - accuracy: 0.5917 - loss: 1.1692 - val_accuracy: 0.4620 - val_loss: 1.5800\n",
      "Epoch 10/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 296ms/step - accuracy: 0.6008 - loss: 1.1440 - val_accuracy: 0.5586 - val_loss: 1.2651\n",
      "Epoch 11/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 297ms/step - accuracy: 0.6174 - loss: 1.1100 - val_accuracy: 0.6556 - val_loss: 0.9943\n",
      "Epoch 12/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 311ms/step - accuracy: 0.6350 - loss: 1.0627 - val_accuracy: 0.6402 - val_loss: 1.0482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c985eb6b40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn1.fit(X_train, y_train, batch_size=64, epochs=12, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.064365267753601\n",
      "Test accuracy: 0.6254000067710876\n"
     ]
    }
   ],
   "source": [
    "score = model_cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a big improvement compared to the MLP model. However, compared to the models performance on the fashion_mnist dataset it scores bad...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's try the second best CNN model. This was the model with a decreased value for the second dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 214ms/step - accuracy: 0.1266 - loss: 2.2914 - val_accuracy: 0.2404 - val_loss: 2.1079\n",
      "Epoch 2/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 272ms/step - accuracy: 0.2155 - loss: 2.1210 - val_accuracy: 0.1488 - val_loss: 2.5503\n",
      "Epoch 3/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 298ms/step - accuracy: 0.2861 - loss: 1.9624 - val_accuracy: 0.3108 - val_loss: 1.8524\n",
      "Epoch 4/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 237ms/step - accuracy: 0.3428 - loss: 1.8122 - val_accuracy: 0.4128 - val_loss: 1.6062\n",
      "Epoch 5/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 245ms/step - accuracy: 0.3763 - loss: 1.7151 - val_accuracy: 0.4048 - val_loss: 1.6291\n",
      "Epoch 6/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1486s\u001b[0m 2s/step - accuracy: 0.4081 - loss: 1.6319 - val_accuracy: 0.3552 - val_loss: 1.7114\n",
      "Epoch 7/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 261ms/step - accuracy: 0.4266 - loss: 1.5799 - val_accuracy: 0.4510 - val_loss: 1.5009\n",
      "Epoch 8/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 232ms/step - accuracy: 0.4466 - loss: 1.5221 - val_accuracy: 0.4582 - val_loss: 1.4946\n",
      "Epoch 9/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 247ms/step - accuracy: 0.4626 - loss: 1.4796 - val_accuracy: 0.4684 - val_loss: 1.4563\n",
      "Epoch 10/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 268ms/step - accuracy: 0.4876 - loss: 1.4306 - val_accuracy: 0.4972 - val_loss: 1.4248\n",
      "Epoch 11/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 223ms/step - accuracy: 0.5066 - loss: 1.3845 - val_accuracy: 0.5322 - val_loss: 1.2997\n",
      "Epoch 12/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 275ms/step - accuracy: 0.5220 - loss: 1.3400 - val_accuracy: 0.5100 - val_loss: 1.3504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c9929aed20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn2 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                        input_shape = input_shape), # No stride because images are not very large\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"), \n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    # fully connected network:\n",
    "    keras.layers.Flatten(), \n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25), # decreased dropout\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # output layer\n",
    "])\n",
    "\n",
    "model_cnn2.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_cnn2.fit(X_train, y_train, batch_size=64, epochs=12, validation_data=(X_valid, y_valid)) # only 3 to see if it performs similar in the beginning to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now it seems to do better than the previous models at epoch 12. Let's do 12 more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 207ms/step - accuracy: 0.5345 - loss: 1.3017 - val_accuracy: 0.5524 - val_loss: 1.2276\n",
      "Epoch 2/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 255ms/step - accuracy: 0.5504 - loss: 1.2665 - val_accuracy: 0.5832 - val_loss: 1.1492\n",
      "Epoch 3/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 216ms/step - accuracy: 0.5690 - loss: 1.2187 - val_accuracy: 0.5142 - val_loss: 1.3589\n",
      "Epoch 4/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 254ms/step - accuracy: 0.5780 - loss: 1.1887 - val_accuracy: 0.6006 - val_loss: 1.1390\n",
      "Epoch 5/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 222ms/step - accuracy: 0.5944 - loss: 1.1522 - val_accuracy: 0.6016 - val_loss: 1.1433\n",
      "Epoch 6/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 254ms/step - accuracy: 0.6099 - loss: 1.1139 - val_accuracy: 0.5688 - val_loss: 1.2289\n",
      "Epoch 7/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 223ms/step - accuracy: 0.6311 - loss: 1.0567 - val_accuracy: 0.5576 - val_loss: 1.3043\n",
      "Epoch 8/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 253ms/step - accuracy: 0.6374 - loss: 1.0377 - val_accuracy: 0.5920 - val_loss: 1.2111\n",
      "Epoch 9/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 228ms/step - accuracy: 0.6523 - loss: 0.9974 - val_accuracy: 0.5934 - val_loss: 1.1631\n",
      "Epoch 10/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 260ms/step - accuracy: 0.6669 - loss: 0.9651 - val_accuracy: 0.5812 - val_loss: 1.1972\n",
      "Epoch 11/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 230ms/step - accuracy: 0.6718 - loss: 0.9362 - val_accuracy: 0.5148 - val_loss: 1.4045\n",
      "Epoch 12/12\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 275ms/step - accuracy: 0.6827 - loss: 0.9044 - val_accuracy: 0.6610 - val_loss: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c992a8c5f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn2.fit(X_train, y_train, batch_size=64, epochs=12, validation_data=(X_valid, y_valid)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9939793944358826\n",
      "Test accuracy: 0.6536999940872192\n"
     ]
    }
   ],
   "source": [
    "score = model_cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the other CNN model after 24 epochs this model scored a lot better, especially looking at the loss. Both models still seem to be improving with more epochs. Overall the CNN models seemed to perfrom better than the MLP model. This could be due to the fact that ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
