{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 22:05:58.390040: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 22:05:58.390764: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 22:05:58.392835: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 22:05:58.397933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731445558.406289 1105259 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731445558.408889 1105259 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-12 22:05:58.418612: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(237817)\n",
    "\n",
    "# Setting these as global variables so that they can be shuffled to ensure an even distribution- many times I wasn't getting all 24/720 labels in the validation set\n",
    "\n",
    "images = np.load(\"75/images.npy\")\n",
    "labels = np.load(\"75/labels.npy\")\n",
    "\n",
    "size = 75\n",
    "images = np.load(f'{size}/images.npy')\n",
    "total = 18000\n",
    "split = int(total*0.8)\n",
    "\n",
    "indices = np.random.permutation(images.shape[0])\n",
    "shuffled_images = images[indices,:,:]\n",
    "shuffled_labels = labels[indices,:]\n",
    "\n",
    "train_images = shuffled_images[0:split,:,:]\n",
    "train_labels = shuffled_labels[0:split,:]\n",
    "\n",
    "test_images = shuffled_images[split:,:,:]\n",
    "test_labels = shuffled_labels[split:,:]\n",
    "\n",
    "valid_images = train_images[0:500,:,:]\n",
    "valid_labels = train_labels[0:500,:]\n",
    "\n",
    "train_images = train_images[500:,:,:]\n",
    "train_labels = train_labels[500:,:]\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "valid_images = valid_images / 255.0\n",
    "\n",
    "train_images= train_images.reshape(train_images.shape[0],75,75,1)\n",
    "test_images  = test_images.reshape(test_images.shape[0],75,75,1)\n",
    "valid_images = valid_images.reshape(valid_images.shape[0],75,75,1)\n",
    "\n",
    "train_labels = train_labels.astype(\"float32\")\n",
    "test_labels = test_labels.astype(\"float32\")\n",
    "valid_labels = valid_labels.astype(\"float32\")\n",
    "\n",
    "train_hours = train_labels[:,0]\n",
    "train_minutes = train_labels[:,1] / 60.0\n",
    "test_hours = test_labels[:,0]\n",
    "test_minutes = test_labels[:,1] / 60.0\n",
    "valid_hours = valid_labels[:,0] \n",
    "valid_minutes = valid_labels[:,1] / 60.0\n",
    "\n",
    "# Convert the time into 24 separate labels\n",
    "def conv_time_24(hours, minutes):\n",
    "    h, m = int, float\n",
    "    if minutes <= .50:\n",
    "        h = int(hours)\n",
    "        m = 0.5\n",
    "    else:\n",
    "      m = 0\n",
    "      h = int(hours)\n",
    "    \n",
    "    return h, m\n",
    "\n",
    "# Convert the time into 720 separate labels \n",
    "def conv_time_720(time):\n",
    "    return time[0]*60 + time[1]\n",
    "\n",
    "conv_time = conv_time_24\n",
    "\n",
    "y_train_converted = np.empty(13900, dtype=float)\n",
    "y_test_converted = np.empty(3600, dtype=float)\n",
    "y_valid_converted = np.empty(500, dtype=float)\n",
    "\n",
    "for i in range(len(train_hours)):\n",
    "    hours, minutes = conv_time(train_hours[i], train_minutes[i])\n",
    "    y_train_converted[i] = hours + float(minutes)\n",
    "    \n",
    "for i in range(len(test_hours)):\n",
    "    hours, minutes = conv_time(test_hours[i], test_minutes[i])\n",
    "    y_test_converted[i] = hours + float(minutes) \n",
    "    \n",
    "for i in range(len(valid_hours)):   \n",
    "    hours, minutes = conv_time(valid_hours[i], valid_minutes[i])\n",
    "    y_valid_converted[i] = hours + float(minutes)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_test_encoded = encoder.fit_transform(y_test_converted)\n",
    "y_train_encoded = encoder.fit_transform(y_train_converted)\n",
    "y_valid_encoded = encoder.fit_transform(y_valid_converted)\n",
    "\n",
    "OH_Encoder = OneHotEncoder(sparse_output=False)\n",
    "onehot_encoded = OH_Encoder.fit_transform(y_train_encoded.reshape(-1, 1))\n",
    "onehot_encoded_valid = OH_Encoder.fit_transform(y_valid_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#Common sense error function- checks the smaller of the differences by converting to military time\n",
    "def common_sense_error(true, pred):\n",
    "    diff1 = K.abs(pred-true)\n",
    "    diff2 = K.abs(pred+12-true)\n",
    "    return K.minimum(diff1, diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13900, 75, 75, 1) (13900, 24) (75, 75, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9999)\n",
    "\n",
    "\n",
    "# Classification CNN\n",
    "input_shape=(images.shape[1], images.shape[2], 1)\n",
    "print(train_images.shape, onehot_encoded.shape, input_shape)\n",
    "\n",
    "model_classification = tf.keras.models.Sequential()\n",
    "model_classification.add(Input(shape=input_shape))\n",
    "model_classification.add(Conv2D(kernel_size=(5,5), strides = (2,2), activation=\"relu\", filters=32))\n",
    "model_classification.add(Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3), input_shape=input_shape))\n",
    "model_classification.add(MaxPooling2D(pool_size=2))\n",
    "model_classification.add(Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model_classification.add(Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model_classification.add(MaxPooling2D(pool_size=2))\n",
    "model_classification.add(Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "model_classification.add(Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "\n",
    "\n",
    "model_classification.add(Flatten())\n",
    "model_classification.add(Dense(units=1024, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=512, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=512, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=256, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=256, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=128, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=64, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=32, activation=\"relu\"))\n",
    "model_classification.add(Dense(units=24, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_classification.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.0415 - loss: 3.1780 - val_accuracy: 0.0340 - val_loss: 3.1781\n",
      "Epoch 2/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0426 - loss: 3.1776 - val_accuracy: 0.0340 - val_loss: 3.1782\n",
      "Epoch 3/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.0460 - loss: 3.1777 - val_accuracy: 0.0340 - val_loss: 3.1782\n",
      "Epoch 4/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0481 - loss: 3.1778 - val_accuracy: 0.0340 - val_loss: 3.1784\n",
      "Epoch 5/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0462 - loss: 3.1771 - val_accuracy: 0.0340 - val_loss: 3.1780\n",
      "Epoch 6/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.0477 - loss: 3.1767 - val_accuracy: 0.0380 - val_loss: 3.1718\n",
      "Epoch 7/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0518 - loss: 3.1580 - val_accuracy: 0.0600 - val_loss: 3.1113\n",
      "Epoch 8/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.0787 - loss: 3.0688 - val_accuracy: 0.0920 - val_loss: 2.9132\n",
      "Epoch 9/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.1142 - loss: 2.8649 - val_accuracy: 0.1100 - val_loss: 2.8813\n",
      "Epoch 10/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1465 - loss: 2.6571 - val_accuracy: 0.1780 - val_loss: 2.4704\n",
      "Epoch 11/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.1788 - loss: 2.4578 - val_accuracy: 0.1820 - val_loss: 2.4136\n",
      "Epoch 12/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.2002 - loss: 2.3329 - val_accuracy: 0.2280 - val_loss: 2.2654\n",
      "Epoch 13/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.2223 - loss: 2.2470 - val_accuracy: 0.2560 - val_loss: 2.1654\n",
      "Epoch 14/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.2430 - loss: 2.1764 - val_accuracy: 0.2400 - val_loss: 2.1006\n",
      "Epoch 15/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.2509 - loss: 2.1047 - val_accuracy: 0.2740 - val_loss: 2.0893\n",
      "Epoch 16/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.2640 - loss: 2.0703 - val_accuracy: 0.2480 - val_loss: 2.1116\n",
      "Epoch 17/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.2778 - loss: 2.0224 - val_accuracy: 0.2740 - val_loss: 2.0363\n",
      "Epoch 18/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.2919 - loss: 1.9784 - val_accuracy: 0.2740 - val_loss: 1.9472\n",
      "Epoch 19/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.3025 - loss: 1.9318 - val_accuracy: 0.2980 - val_loss: 1.9046\n",
      "Epoch 20/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3120 - loss: 1.8979 - val_accuracy: 0.3220 - val_loss: 1.8715\n",
      "Epoch 21/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.3276 - loss: 1.8450 - val_accuracy: 0.3480 - val_loss: 1.8690\n",
      "Epoch 22/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3369 - loss: 1.8258 - val_accuracy: 0.3340 - val_loss: 1.8608\n",
      "Epoch 23/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3437 - loss: 1.7908 - val_accuracy: 0.3360 - val_loss: 1.8252\n",
      "Epoch 24/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3570 - loss: 1.7484 - val_accuracy: 0.3560 - val_loss: 1.7930\n",
      "Epoch 25/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.3576 - loss: 1.7518 - val_accuracy: 0.3720 - val_loss: 1.7426\n",
      "Epoch 26/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.3717 - loss: 1.7112 - val_accuracy: 0.3780 - val_loss: 1.7139\n",
      "Epoch 27/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.3796 - loss: 1.6906 - val_accuracy: 0.3900 - val_loss: 1.6649\n",
      "Epoch 28/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4016 - loss: 1.6305 - val_accuracy: 0.3520 - val_loss: 1.7193\n",
      "Epoch 29/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.3869 - loss: 1.6354 - val_accuracy: 0.3920 - val_loss: 1.6559\n",
      "Epoch 30/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.4057 - loss: 1.5928 - val_accuracy: 0.3900 - val_loss: 1.6439\n",
      "Epoch 31/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.4140 - loss: 1.5814 - val_accuracy: 0.3900 - val_loss: 1.6488\n",
      "Epoch 32/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4149 - loss: 1.5673 - val_accuracy: 0.4320 - val_loss: 1.6113\n",
      "Epoch 33/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.4255 - loss: 1.5438 - val_accuracy: 0.3960 - val_loss: 1.6246\n",
      "Epoch 34/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4303 - loss: 1.5317 - val_accuracy: 0.4420 - val_loss: 1.5303\n",
      "Epoch 35/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4536 - loss: 1.4673 - val_accuracy: 0.4360 - val_loss: 1.4852\n",
      "Epoch 36/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4652 - loss: 1.4277 - val_accuracy: 0.4280 - val_loss: 1.5296\n",
      "Epoch 37/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4711 - loss: 1.4344 - val_accuracy: 0.4480 - val_loss: 1.4583\n",
      "Epoch 38/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.4702 - loss: 1.4218 - val_accuracy: 0.4420 - val_loss: 1.5488\n",
      "Epoch 39/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4689 - loss: 1.4139 - val_accuracy: 0.4700 - val_loss: 1.4329\n",
      "Epoch 40/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.4825 - loss: 1.3895 - val_accuracy: 0.4660 - val_loss: 1.4736\n",
      "Epoch 41/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4867 - loss: 1.3753 - val_accuracy: 0.4660 - val_loss: 1.4167\n",
      "Epoch 42/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5016 - loss: 1.3169 - val_accuracy: 0.4720 - val_loss: 1.3781\n",
      "Epoch 43/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.5175 - loss: 1.2983 - val_accuracy: 0.4920 - val_loss: 1.3568\n",
      "Epoch 44/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5223 - loss: 1.2781 - val_accuracy: 0.5420 - val_loss: 1.2923\n",
      "Epoch 45/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5329 - loss: 1.2483 - val_accuracy: 0.4680 - val_loss: 1.4158\n",
      "Epoch 46/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5437 - loss: 1.2321 - val_accuracy: 0.5220 - val_loss: 1.3158\n",
      "Epoch 47/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5537 - loss: 1.1882 - val_accuracy: 0.4860 - val_loss: 1.3930\n",
      "Epoch 48/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5401 - loss: 1.2197 - val_accuracy: 0.5280 - val_loss: 1.2442\n",
      "Epoch 49/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5636 - loss: 1.1566 - val_accuracy: 0.5200 - val_loss: 1.2831\n",
      "Epoch 50/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5615 - loss: 1.1695 - val_accuracy: 0.5480 - val_loss: 1.2576\n"
     ]
    }
   ],
   "source": [
    "cl_h = model_classification.fit(train_images, onehot_encoded, epochs=50, batch_size=180, validation_data=(valid_images, onehot_encoded_valid), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7a1c39b43550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph the model training\n",
    "print(cl_h.history.keys())\n",
    "plt.plot(cl_h.history['loss'])\n",
    "plt.plot(cl_h.history['accuracy'])\n",
    "plt.title('Model Performace')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Loss', 'Accuracy'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "51.44444444444445 %\n"
     ]
    }
   ],
   "source": [
    "# Measuring accuracy- picking the highest confidence label and comparing it to the true label\n",
    "predicted = model_classification.predict(test_images)\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "\n",
    "print(np.sum(predicted == y_test_encoded) / len(y_test_encoded) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#returning the common sense difference between two times\n",
    "def common_sense_error(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff_1 = K.abs(true - pred)\n",
    "    diff_2 = K.abs(true - (pred + 12))\n",
    "\n",
    "    return K.minimum(diff_1, diff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize()\n",
    "\n",
    "# Convert the time into a continuous value\n",
    "def conv_time(time):\n",
    "    return round(time[0] + time[1]/60, 3)\n",
    "\n",
    "train_labels_reg = np.array([conv_time(time) for time in train_labels])\n",
    "test_labels_reg = np.array([conv_time(time) for time in test_labels])\n",
    "val_labels_reg = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), input_shape=(75, 75, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[common_sense_error])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "regression_model = model.fit(train_imgs, train_labels_reg, epochs=10, batch_size = 512, validation_data = (val_imgs, val_labels_reg), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring accuracy within 1 minute of the true time\n",
    "reg_preds = model.predict(test_imgs)\n",
    "accuracy = np.mean(abs(reg_preds - test_labels_reg) < 0.16)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Headed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize()\n",
    "\n",
    "train_hours = train_labels[:, 0]\n",
    "train_minutes = train_labels[:, 1]\n",
    "\n",
    "val_hours = val_labels[:, 0]\n",
    "val_minutes = val_labels[:, 1]\n",
    "\n",
    "test_hours = test_labels[:, 0]\n",
    "test_minutes = test_labels[:, 1]\n",
    "\n",
    "train_minutes = train_minutes / 60\n",
    "test_minutes = test_minutes / 60\n",
    "val_minutes = val_minutes / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def common_sense_hour(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff1 = K.abs(pred-true)\n",
    "    diff2 = K.abs(pred+12-true)\n",
    "    return K.minimum(diff1, diff2)\n",
    "\n",
    "def common_sense_minute(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff1 = K.abs(pred-true)\n",
    "    diff2 = K.abs(pred+60-true)\n",
    "    return K.minimum(diff1, diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input(shape = (75,75,1))\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (5,5), strides= (2,2), activation = \"relu\")(inp)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (1,1),activation = \"relu\")(model)\n",
    "model = keras.layers.Flatten()(model)\n",
    "\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(model)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "d = keras.layers.Dropout(0.1)(d)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "\n",
    "# The hour head predicts confidence amonst 12 label classes- one for each hour \n",
    "hour = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "hour = keras.layers.Dense(128,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(64,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(32,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(16,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(12,activation= \"softmax\", name= \"hour\")(hour)\n",
    "\n",
    "# The minute head runs a regression on a continuous value\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(128,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(64,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(32,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(16,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(1, activation = \"softplus\", name = \"minute\")(minute)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=[hour, minute])\n",
    "optim = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'], optimizer=optim, metrics=['accuracy',\"mae\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, [train_hours, train_minutes], epochs=30, batch_size = 512, validation_data = (val_imgs, [val_hours, val_minutes]), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_imgs)\n",
    "hour_p = np.argmax(predictions[0], axis = 1)\n",
    "minutes_p = predictions[1]\n",
    "\n",
    "accuracy = np.mean(np.abs(hour_p - test_hours) < 1) * np.mean(np.abs(minutes_p - test_minutes) < 5)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf  # Import TensorFlow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Dense, Flatten, Conv2D, MaxPooling2D,\n",
    "                                     BatchNormalization, Dropout, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Load and preprocess images\n",
    "images = np.load('75/images.npy').astype('float32')\n",
    "\n",
    "# Function to initialize datasets\n",
    "def initialize():\n",
    "    global train_imgs, val_imgs, test_imgs, train_labels, val_labels, test_labels\n",
    "    labels = np.load('75/labels.npy').astype('int32')\n",
    "    indices = np.random.permutation(images.shape[0])\n",
    "    imgs = images[indices] / 255.0  # Normalize images\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    split_1 = int(images.shape[0] * 0.7)\n",
    "    split_2 = int(images.shape[0] * 0.9)\n",
    "    \n",
    "    train_imgs = imgs[:split_1].reshape(-1, 75, 75, 1)\n",
    "    train_labels = labels[:split_1]\n",
    "    val_imgs = imgs[split_1:split_2].reshape(-1, 75, 75, 1)\n",
    "    val_labels = labels[split_1:split_2]\n",
    "    test_imgs = imgs[split_2:].reshape(-1, 75, 75, 1)\n",
    "    test_labels = labels[split_2:]\n",
    "\n",
    "# Function to convert time into 24 labels (30-minute intervals)\n",
    "def conv_time_24(time):\n",
    "    total_minutes = time[0] * 60 + time[1]\n",
    "    return total_minutes // 30  # Integer division to get 30-minute intervals (0-23)\n",
    "\n",
    "# Initialize datasets\n",
    "initialize()\n",
    "\n",
    "# Convert labels\n",
    "train_labels_converted = np.array([conv_time_24(time) for time in train_labels])\n",
    "val_labels_converted = np.array([conv_time_24(time) for time in val_labels])\n",
    "test_labels_converted = np.array([conv_time_24(time) for time in test_labels])\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = 24\n",
    "train_labels_oh = to_categorical(train_labels_converted, num_classes)\n",
    "val_labels_oh = to_categorical(val_labels_converted, num_classes)\n",
    "test_labels_oh = to_categorical(test_labels_converted, num_classes)\n",
    "\n",
    "# Convert grayscale images to RGB\n",
    "train_imgs_rgb = np.repeat(train_imgs, 3, axis=-1)\n",
    "val_imgs_rgb = np.repeat(val_imgs, 3, axis=-1)\n",
    "test_imgs_rgb = np.repeat(test_imgs, 3, axis=-1)\n",
    "\n",
    "# Resize images to 224x224 using tf.image.resize\n",
    "train_imgs_resized = np.array([tf.image.resize(img, (224, 224)).numpy() for img in train_imgs_rgb])\n",
    "val_imgs_resized = np.array([tf.image.resize(img, (224, 224)).numpy() for img in val_imgs_rgb])\n",
    "test_imgs_resized = np.array([tf.image.resize(img, (224, 224)).numpy() for img in test_imgs_rgb])\n",
    "\n",
    "# Preprocess images\n",
    "train_imgs_preprocessed = preprocess_input(train_imgs_resized)\n",
    "val_imgs_preprocessed = preprocess_input(val_imgs_resized)\n",
    "test_imgs_preprocessed = preprocess_input(test_imgs_resized)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(train_imgs_preprocessed)\n",
    "\n",
    "# Load the VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the complete model\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Adjust batch size if necessary\n",
    "batch_size = 16  # Reduce this number if you run into memory issues\n",
    "\n",
    "# Train the model\n",
    "classification_history = model.fit(\n",
    "    datagen.flow(train_imgs_preprocessed, train_labels_oh, batch_size=batch_size),\n",
    "    epochs=10,\n",
    "    validation_data=(val_imgs_preprocessed, val_labels_oh),\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Fine-tune the base model\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "classification_history_finetune = model.fit(\n",
    "    datagen.flow(train_imgs_preprocessed, train_labels_oh, batch_size=batch_size),\n",
    "    epochs=10,\n",
    "    validation_data=(val_imgs_preprocessed, val_labels_oh),\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_imgs_preprocessed, test_labels_oh)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Calculate common sense error\n",
    "def common_sense_error(y_true_classes, y_pred_classes):\n",
    "    max_time = num_classes  # Total intervals\n",
    "    diff = np.abs(y_true_classes - y_pred_classes)\n",
    "    circular_diff = np.minimum(diff, max_time - diff)\n",
    "    return np.mean(circular_diff)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = model.predict(test_imgs_preprocessed)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(test_labels_oh, axis=1)\n",
    "\n",
    "# Calculate common sense error\n",
    "cse = common_sense_error(y_true_classes, y_pred_classes)\n",
    "print(f\"Common Sense Error on Test Set: {cse:.4f} intervals (each interval is 30 minutes)\")\n",
    "\n",
    "# Optionally, convert intervals back to time for better interpretation\n",
    "def interval_to_time(interval):\n",
    "    total_minutes = interval * 30\n",
    "    hours = (total_minutes // 60) % 24  # Use %24 for 24-hour format\n",
    "    minutes = total_minutes % 60\n",
    "    return f\"{int(hours):02d}:{int(minutes):02d}\"\n",
    "\n",
    "# Example of interpreting predictions\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Predicted time: {interval_to_time(y_pred_classes[i])}\")\n",
    "    print(f\"Actual time:    {interval_to_time(y_true_classes[i])}\")\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
