{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = np.load('75/images.npy')\n",
    "imgs = imgs.astype('float32')\n",
    "indices = np.random.permutation(imgs.shape[0])\n",
    "imgs = imgs[indices]\n",
    "\n",
    "split_1 = int(18000*0.8)\n",
    "split_2 = int(18000*0.9)\n",
    "\n",
    "train_imgs = imgs[:split_1]\n",
    "val_imgs = imgs[split_1:split_2]\n",
    "test_imgs = imgs[split_2:]\n",
    "\n",
    "train_imgs = train_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0\n",
    "val_imgs = val_imgs / 255.0\n",
    "\n",
    "labels = np.load('75/labels.npy')\n",
    "labels = labels.astype('int32')\n",
    "labels = labels[indices]\n",
    "train_labels = labels[:split_1]\n",
    "val_labels = labels[split_1:split_2]\n",
    "test_labels = labels[split_2:]\n",
    "\n",
    "train_imgs = train_imgs.reshape((train_imgs.shape[0], 75, 75, 1))\n",
    "val_imgs = val_imgs.reshape((val_imgs.shape[0], 75, 75, 1))\n",
    "test_imgs = test_imgs.reshape((test_imgs.shape[0], 75, 75, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_time(time):\n",
    "    ntime = 0\n",
    "    if time[1] > 30:\n",
    "        ntime = (time[0] + 0.5)\n",
    "    else:\n",
    "        ntime = time[0]\n",
    "    return ntime\n",
    "\n",
    "train_labels_converted = np.array([conv_time(time) for time in train_labels])\n",
    "test_labels_converted = np.array([conv_time(time) for time in test_labels])\n",
    "val_labels_converted = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "test_labels_encoded = encoder.fit_transform(test_labels_converted.reshape(-1))\n",
    "train_labels_encoded = encoder.fit_transform(train_labels_converted.reshape(-1))\n",
    "val_labels_encoded = encoder.fit_transform(val_labels_converted.reshape(-1))\n",
    "\n",
    "OHencoder = OneHotEncoder(sparse_output=False)\n",
    "train_labels_oh = OHencoder.fit_transform(train_labels_encoded.reshape(-1, 1))\n",
    "val_labels_oh = OHencoder.fit_transform(val_labels_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 75, 75, 1) (14400, 24)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1730479860.483291   78571 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.0412 - loss: 3.1781 - val_accuracy: 0.0428 - val_loss: 3.1781\n",
      "Epoch 2/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.0462 - loss: 3.1780 - val_accuracy: 0.0400 - val_loss: 3.1781\n",
      "Epoch 3/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0440 - loss: 3.1780 - val_accuracy: 0.0400 - val_loss: 3.1782\n",
      "Epoch 4/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0459 - loss: 3.1778 - val_accuracy: 0.0439 - val_loss: 3.1781\n",
      "Epoch 5/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0448 - loss: 3.1780 - val_accuracy: 0.0428 - val_loss: 3.1781\n",
      "Epoch 6/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.0422 - loss: 3.1777 - val_accuracy: 0.0439 - val_loss: 3.1781\n",
      "Epoch 7/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.0446 - loss: 3.1777 - val_accuracy: 0.0439 - val_loss: 3.1781\n",
      "Epoch 8/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0451 - loss: 3.1777 - val_accuracy: 0.0439 - val_loss: 3.1782\n",
      "Epoch 9/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.0452 - loss: 3.1772 - val_accuracy: 0.0450 - val_loss: 3.1752\n",
      "Epoch 10/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.0437 - loss: 3.1709 - val_accuracy: 0.0528 - val_loss: 3.1373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x715edc55d870>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (75, 75, 1)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(kernel_size=(5,5), strides = (2,2), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=24, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "print(train_imgs.shape, train_labels_oh.shape)\n",
    "val_labels_oh = val_labels_oh.reshape((val_labels_oh.shape[0], 24))\n",
    "\n",
    "model.fit(train_imgs, train_labels_oh, epochs=10, batch_size=256, validation_data=(val_imgs, val_labels_oh), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "5.277777777777778 %\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_imgs)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "\n",
    "results = encoder.inverse_transform(preds)\n",
    "\n",
    "accuracy = np.sum(results == test_labels_converted) / len(test_labels_converted)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#returning the common sense difference between two times\n",
    "def difference_func(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff_1 = K.abs(true - pred)\n",
    "    diff_2 = K.abs(true - (pred + 12*60))\n",
    "\n",
    "    return K.minimum(diff_1, diff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - difference_func: 179.8117 - loss: 179.8117 - val_difference_func: 180.3779 - val_loss: 180.3779\n",
      "Epoch 2/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - difference_func: 179.4547 - loss: 179.4547 - val_difference_func: 180.3785 - val_loss: 180.3785\n",
      "Epoch 3/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - difference_func: 179.3476 - loss: 179.3476 - val_difference_func: 180.3781 - val_loss: 180.3781\n",
      "Epoch 4/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 178.2844 - loss: 178.2844 - val_difference_func: 180.3785 - val_loss: 180.3785\n",
      "Epoch 5/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - difference_func: 178.8544 - loss: 178.8544 - val_difference_func: 180.3797 - val_loss: 180.3797\n",
      "Epoch 6/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 176.9682 - loss: 176.9682 - val_difference_func: 180.3802 - val_loss: 180.3802\n",
      "Epoch 7/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 178.7828 - loss: 178.7829 - val_difference_func: 180.3810 - val_loss: 180.3809\n",
      "Epoch 8/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - difference_func: 179.4059 - loss: 179.4049 - val_difference_func: 180.4593 - val_loss: 180.2873\n",
      "Epoch 9/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - difference_func: 180.4912 - loss: 180.1470 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 10/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - difference_func: 179.1889 - loss: 179.1889 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 11/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - difference_func: 178.1118 - loss: 178.1118 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 12/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - difference_func: 179.1299 - loss: 179.1299 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 13/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 179.3872 - loss: 179.3872 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 14/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 179.0116 - loss: 179.0116 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 15/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - difference_func: 178.4972 - loss: 178.4972 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 16/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 179.9332 - loss: 179.9332 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 17/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 179.5665 - loss: 179.5665 - val_difference_func: 180.3605 - val_loss: 180.3605\n",
      "Epoch 18/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - difference_func: 177.8130 - loss: 177.8130 - val_difference_func: 180.3605 - val_loss: 180.3605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x715e797a7f40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_reg = np.array([(time[0]*60+time[1]) for time in train_labels])\n",
    "test_labels_reg = np.array([(time[0]*60+time[1]) for time in test_labels])\n",
    "val_labels_reg = np.array([(time[0]*60+time[1]) for time in val_labels])\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides = (2,2),input_shape=(75, 75, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "model.compile(loss=difference_func, optimizer=\"adam\", metrics=[difference_func])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, train_labels_reg, epochs=40, batch_size = 512, validation_data = (val_imgs, val_labels_reg), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "0.7222222222222222 %\n"
     ]
    }
   ],
   "source": [
    "reg_preds = model.predict(test_imgs)\n",
    "accuracy = np.mean(np.abs(reg_preds - test_labels_reg) < 5)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Headed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hours = train_labels[:, 0]\n",
    "train_minutes = train_labels[:, 1]\n",
    "\n",
    "val_hours = val_labels[:, 0]\n",
    "val_minutes = val_labels[:, 1]\n",
    "\n",
    "test_hours = test_labels[:, 0]\n",
    "test_minutes = test_labels[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - hour_accuracy: 0.0808 - hour_loss: 2.4887 - loss: 838.4274 - minute_loss: 835.5597 - minute_mae: 23.9306 - val_hour_accuracy: 0.0839 - val_hour_loss: 2.4879 - val_loss: 318.8836 - val_minute_loss: 316.8258 - val_minute_mae: 15.3285\n",
      "Epoch 2/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0845 - hour_loss: 2.4889 - loss: 322.3623 - minute_loss: 319.8416 - minute_mae: 15.2535 - val_hour_accuracy: 0.0861 - val_hour_loss: 2.4912 - val_loss: 308.0358 - val_minute_loss: 305.8560 - val_minute_mae: 15.1308\n",
      "Epoch 3/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0859 - hour_loss: 2.4869 - loss: 303.3432 - minute_loss: 300.8137 - minute_mae: 14.9939 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4906 - val_loss: 303.1655 - val_minute_loss: 300.7621 - val_minute_mae: 15.0053\n",
      "Epoch 4/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0851 - hour_loss: 2.4860 - loss: 308.8290 - minute_loss: 306.3998 - minute_mae: 15.0812 - val_hour_accuracy: 0.0861 - val_hour_loss: 2.4855 - val_loss: 307.2587 - val_minute_loss: 304.7551 - val_minute_mae: 15.0586\n",
      "Epoch 5/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0800 - hour_loss: 2.4849 - loss: 308.0735 - minute_loss: 305.5131 - minute_mae: 15.0964 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4855 - val_loss: 304.4749 - val_minute_loss: 302.2079 - val_minute_mae: 15.0546\n",
      "Epoch 6/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0859 - hour_loss: 2.4849 - loss: 307.2395 - minute_loss: 304.7410 - minute_mae: 15.0913 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 304.9265 - val_minute_loss: 302.6581 - val_minute_mae: 15.0636\n",
      "Epoch 7/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0847 - hour_loss: 2.4850 - loss: 305.2268 - minute_loss: 302.7821 - minute_mae: 15.0287 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4858 - val_loss: 310.6407 - val_minute_loss: 308.4510 - val_minute_mae: 15.1744\n",
      "Epoch 8/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0832 - hour_loss: 2.4850 - loss: 304.0051 - minute_loss: 301.5880 - minute_mae: 14.9766 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 304.2296 - val_minute_loss: 301.9323 - val_minute_mae: 15.0450\n",
      "Epoch 9/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0835 - hour_loss: 2.4849 - loss: 304.1098 - minute_loss: 301.5475 - minute_mae: 14.9583 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 322.4780 - val_minute_loss: 320.3845 - val_minute_mae: 15.3852\n",
      "Epoch 10/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0833 - hour_loss: 2.4849 - loss: 305.1005 - minute_loss: 302.6041 - minute_mae: 14.9573 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 305.9532 - val_minute_loss: 303.6636 - val_minute_mae: 15.0787\n",
      "Epoch 11/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0868 - hour_loss: 2.4848 - loss: 303.1096 - minute_loss: 300.6066 - minute_mae: 14.9735 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 307.2397 - val_minute_loss: 304.6186 - val_minute_mae: 15.0418\n",
      "Epoch 12/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0863 - hour_loss: 2.4848 - loss: 306.4479 - minute_loss: 303.8913 - minute_mae: 15.0536 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 302.1205 - val_minute_loss: 299.7341 - val_minute_mae: 14.9868\n",
      "Epoch 13/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0856 - hour_loss: 2.4847 - loss: 302.9499 - minute_loss: 300.5273 - minute_mae: 14.9932 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 313.6602 - val_minute_loss: 311.4506 - val_minute_mae: 15.2067\n",
      "Epoch 14/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0863 - hour_loss: 2.4848 - loss: 306.8985 - minute_loss: 304.4621 - minute_mae: 15.0560 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 300.6724 - val_minute_loss: 298.1796 - val_minute_mae: 14.9378\n",
      "Epoch 15/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0876 - hour_loss: 2.4848 - loss: 305.8167 - minute_loss: 303.3109 - minute_mae: 15.0096 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 309.0322 - val_minute_loss: 306.7843 - val_minute_mae: 15.1099\n",
      "Epoch 16/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0859 - hour_loss: 2.4848 - loss: 301.7711 - minute_loss: 299.2598 - minute_mae: 14.9462 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4858 - val_loss: 299.6266 - val_minute_loss: 297.1164 - val_minute_mae: 14.9030\n",
      "Epoch 17/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0864 - hour_loss: 2.4849 - loss: 306.9128 - minute_loss: 304.4610 - minute_mae: 15.0409 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 314.9013 - val_minute_loss: 312.1386 - val_minute_mae: 15.1350\n",
      "Epoch 18/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0853 - hour_loss: 2.4849 - loss: 305.4062 - minute_loss: 302.9399 - minute_mae: 14.9640 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 298.4180 - val_minute_loss: 295.9067 - val_minute_mae: 14.8662\n",
      "Epoch 19/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0836 - hour_loss: 2.4849 - loss: 298.3048 - minute_loss: 295.7913 - minute_mae: 14.7812 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4858 - val_loss: 297.7803 - val_minute_loss: 295.3216 - val_minute_mae: 14.8277\n",
      "Epoch 20/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0867 - hour_loss: 2.4848 - loss: 299.2306 - minute_loss: 296.7489 - minute_mae: 14.7869 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 308.6993 - val_minute_loss: 306.0054 - val_minute_mae: 14.9913\n",
      "Epoch 21/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4849 - loss: 301.9097 - minute_loss: 299.3268 - minute_mae: 14.8503 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 308.4829 - val_minute_loss: 305.7278 - val_minute_mae: 14.9356\n",
      "Epoch 22/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0872 - hour_loss: 2.4847 - loss: 301.1676 - minute_loss: 298.7786 - minute_mae: 14.7660 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 297.2985 - val_minute_loss: 294.5486 - val_minute_mae: 14.6891\n",
      "Epoch 23/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0833 - hour_loss: 2.4849 - loss: 293.2609 - minute_loss: 290.8000 - minute_mae: 14.5408 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 290.1761 - val_minute_loss: 287.5262 - val_minute_mae: 14.4693\n",
      "Epoch 24/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - hour_accuracy: 0.0880 - hour_loss: 2.4848 - loss: 287.7433 - minute_loss: 285.2914 - minute_mae: 14.2831 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 322.2050 - val_minute_loss: 319.7963 - val_minute_mae: 15.0085\n",
      "Epoch 25/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0842 - hour_loss: 2.4850 - loss: 302.3041 - minute_loss: 299.9163 - minute_mae: 14.6422 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 297.5887 - val_minute_loss: 294.1196 - val_minute_mae: 14.5099\n",
      "Epoch 26/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0831 - hour_loss: 2.4850 - loss: 288.0562 - minute_loss: 285.5314 - minute_mae: 14.2317 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 278.5552 - val_minute_loss: 275.7726 - val_minute_mae: 14.0054\n",
      "Epoch 27/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0831 - hour_loss: 2.4850 - loss: 276.4994 - minute_loss: 274.0420 - minute_mae: 13.8703 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 283.6315 - val_minute_loss: 281.1789 - val_minute_mae: 13.8874\n",
      "Epoch 28/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0883 - hour_loss: 2.4848 - loss: 271.9418 - minute_loss: 269.4579 - minute_mae: 13.5834 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 263.0416 - val_minute_loss: 260.3309 - val_minute_mae: 13.2219\n",
      "Epoch 29/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0833 - hour_loss: 2.4849 - loss: 257.1381 - minute_loss: 254.7710 - minute_mae: 12.9842 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 286.2864 - val_minute_loss: 283.3994 - val_minute_mae: 13.7271\n",
      "Epoch 30/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0869 - hour_loss: 2.4849 - loss: 263.4276 - minute_loss: 261.0231 - minute_mae: 13.0866 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 252.8348 - val_minute_loss: 249.7550 - val_minute_mae: 12.6005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x715e43f670a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = keras.layers.Input(shape = (75,75,1))\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (5,5), strides= (2,2), activation = \"relu\")(inp)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (1,1),activation = \"relu\")(model)\n",
    "model = keras.layers.Flatten()(model)\n",
    "\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(model)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "d = keras.layers.Dropout(0.1)(d)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "\n",
    "hour = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "hour = keras.layers.Dense(128,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(64,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(32,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(16,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(12,activation= \"softmax\", name= \"hour\")(hour)\n",
    "\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(128,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(64,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(32,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(16,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(1, activation = \"softplus\", name = \"minute\")(minute)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=[hour, minute])\n",
    "optim = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=['sparse_categorical_crossentropy', 'mse'], optimizer=optim, metrics=['accuracy',\"mae\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, [train_hours, train_minutes], epochs=30, batch_size = 512, validation_data = (val_imgs, [val_hours, val_minutes]), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "1.363423353909465 %\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_imgs)\n",
    "hour_p = np.argmax(predictions[0], axis = 1)\n",
    "minutes_p = predictions[1]\n",
    "\n",
    "accuracy = np.mean(np.abs(hour_p - test_hours) < 1) * np.mean(np.abs(minutes_p - test_minutes) < 5)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Transformation using Periodic Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_time_train = (train_hours*60 + train_minutes) \n",
    "sine_time_test = (test_hours*60 + test_minutes)  \n",
    "sine_time_valid = (val_hours*60 + val_minutes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(719)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sine_time_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_angle_test = (sine_time_test/720)*2*np.pi\n",
    "sine_angle_train = (sine_time_train/720)*2*np.pi\n",
    "sine_angle_valid = (sine_time_valid/720)*2*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.1435 - mae: 0.2371 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 2/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7896e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 3/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 3.7661e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 4/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7713e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 5/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7717e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 6/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8013e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 7/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7782e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 8/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7938e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 9/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 3.7552e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 10/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8153e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 11/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8028e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x715e14082a10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sine Regression CNN\n",
    "\n",
    "sin_reg = keras.models.Sequential()\n",
    "sin_reg.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides = (2,2),input_shape=(75, 75, 1)))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "sin_reg.add(keras.layers.Flatten())\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "sin_reg.compile(loss='mse', optimizer= optimizer, metrics=['mae'])\n",
    "sin_reg.fit(train_imgs, sine_angle_train, epochs=45, batch_size = 512, validation_data = (val_imgs, sine_angle_valid), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "predictions = sin_reg.predict(test_imgs)\n",
    "\n",
    "def difference_func(pred,y):\n",
    "  pred = np.transpose(pred)\n",
    "  diff_one = np.maximum(pred,y) - np.minimum(pred,y)\n",
    "  diff_two = np.minimum(pred,y) + 1 - np.maximum(pred,y)\n",
    "  return np.minimum(diff_one,diff_two)\n",
    "\n",
    "result = difference_func(predictions,sine_angle_test).reshape(-1)\n",
    "\n",
    "accuracy = np.mean(result < np.pi/6)\n",
    "print(accuracy*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
