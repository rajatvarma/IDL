{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting these as global variables so that they can be shuffled to ensure an even distribution- many times I wasn't getting all 24/720 labels in the validation set\n",
    "\n",
    "images = np.load('75/images.npy')\n",
    "images = images.astype('float32')\n",
    "\n",
    "# Function that shuffles the images and labels into training, validation, and test sets\n",
    "def initalize():\n",
    "    global imgs, train_imgs, val_imgs, test_imgs, train_labels, val_labels, test_labels, distributed\n",
    "    indices = np.random.permutation(images.shape[0])\n",
    "    imgs = images[indices]\n",
    "\n",
    "    split_1 = int(18000*0.8)\n",
    "    split_2 = int(18000*0.9)\n",
    "\n",
    "    train_imgs = imgs[:split_1]\n",
    "    val_imgs = imgs[split_1:split_2]\n",
    "    test_imgs = imgs[split_2:]\n",
    "\n",
    "    # Normalizing the images\n",
    "    train_imgs = train_imgs / 255.0\n",
    "    test_imgs = test_imgs / 255.0\n",
    "    val_imgs = val_imgs / 255.0\n",
    "\n",
    "    labels = np.load('75/labels.npy')\n",
    "    labels = labels.astype('int32')\n",
    "    labels = labels[indices]\n",
    "    train_labels = labels[:split_1]\n",
    "    val_labels = labels[split_1:split_2]\n",
    "    test_labels = labels[split_2:]\n",
    "\n",
    "    train_imgs = train_imgs.reshape((train_imgs.shape[0], 75, 75, 1))\n",
    "    val_imgs = val_imgs.reshape((val_imgs.shape[0], 75, 75, 1))\n",
    "    test_imgs = test_imgs.reshape((test_imgs.shape[0], 75, 75, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.3529412 ],\n",
       "         [0.3529412 ],\n",
       "         [0.3372549 ],\n",
       "         ...,\n",
       "         [0.4627451 ],\n",
       "         [0.5411765 ],\n",
       "         [0.47058824]],\n",
       "\n",
       "        [[0.39215687],\n",
       "         [0.42352942],\n",
       "         [0.3882353 ],\n",
       "         ...,\n",
       "         [0.49803922],\n",
       "         [0.49803922],\n",
       "         [0.47843137]],\n",
       "\n",
       "        [[0.34901962],\n",
       "         [0.36078432],\n",
       "         [0.34509805],\n",
       "         ...,\n",
       "         [0.49411765],\n",
       "         [0.47843137],\n",
       "         [0.47058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.49019608],\n",
       "         [0.5176471 ],\n",
       "         [0.5137255 ],\n",
       "         ...,\n",
       "         [0.6039216 ],\n",
       "         [0.6156863 ],\n",
       "         [0.58431375]],\n",
       "\n",
       "        [[0.41568628],\n",
       "         [0.43529412],\n",
       "         [0.39607844],\n",
       "         ...,\n",
       "         [0.47843137],\n",
       "         [0.4862745 ],\n",
       "         [0.4745098 ]],\n",
       "\n",
       "        [[0.5294118 ],\n",
       "         [0.5058824 ],\n",
       "         [0.53333336],\n",
       "         ...,\n",
       "         [0.47058824],\n",
       "         [0.47843137],\n",
       "         [0.5137255 ]]],\n",
       "\n",
       "\n",
       "       [[[0.58431375],\n",
       "         [0.5882353 ],\n",
       "         [0.5921569 ],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.59607846],\n",
       "         [0.59607846]],\n",
       "\n",
       "        [[0.6156863 ],\n",
       "         [0.60784316],\n",
       "         [0.5764706 ],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.5921569 ],\n",
       "         [0.6039216 ]],\n",
       "\n",
       "        [[0.6039216 ],\n",
       "         [0.6       ],\n",
       "         [0.6745098 ],\n",
       "         ...,\n",
       "         [0.60784316],\n",
       "         [0.59607846],\n",
       "         [0.5764706 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627452],\n",
       "         [0.28627452],\n",
       "         [0.44313726],\n",
       "         ...,\n",
       "         [0.36078432],\n",
       "         [0.39215687],\n",
       "         [0.34509805]],\n",
       "\n",
       "        [[0.26666668],\n",
       "         [0.3764706 ],\n",
       "         [0.2784314 ],\n",
       "         ...,\n",
       "         [0.39607844],\n",
       "         [0.36078432],\n",
       "         [0.3529412 ]],\n",
       "\n",
       "        [[0.3647059 ],\n",
       "         [0.4627451 ],\n",
       "         [0.29411766],\n",
       "         ...,\n",
       "         [0.38039216],\n",
       "         [0.35686275],\n",
       "         [0.27058825]]],\n",
       "\n",
       "\n",
       "       [[[0.5764706 ],\n",
       "         [0.5529412 ],\n",
       "         [0.6       ],\n",
       "         ...,\n",
       "         [0.53333336],\n",
       "         [0.3254902 ],\n",
       "         [0.4117647 ]],\n",
       "\n",
       "        [[0.5921569 ],\n",
       "         [0.5882353 ],\n",
       "         [0.5019608 ],\n",
       "         ...,\n",
       "         [0.4117647 ],\n",
       "         [0.3764706 ],\n",
       "         [0.4627451 ]],\n",
       "\n",
       "        [[0.57254905],\n",
       "         [0.53333336],\n",
       "         [0.5568628 ],\n",
       "         ...,\n",
       "         [0.32156864],\n",
       "         [0.42352942],\n",
       "         [0.49019608]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.47058824],\n",
       "         [0.5372549 ],\n",
       "         [0.44313726],\n",
       "         ...,\n",
       "         [0.30980393],\n",
       "         [0.3019608 ],\n",
       "         [0.3372549 ]],\n",
       "\n",
       "        [[0.5647059 ],\n",
       "         [0.4       ],\n",
       "         [0.5137255 ],\n",
       "         ...,\n",
       "         [0.27058825],\n",
       "         [0.28235295],\n",
       "         [0.34117648]],\n",
       "\n",
       "        [[0.5176471 ],\n",
       "         [0.49803922],\n",
       "         [0.54509807],\n",
       "         ...,\n",
       "         [0.29411766],\n",
       "         [0.34901962],\n",
       "         [0.30588236]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.5529412 ],\n",
       "         [0.36862746],\n",
       "         [0.3529412 ],\n",
       "         ...,\n",
       "         [0.27058825],\n",
       "         [0.41960785],\n",
       "         [0.59607846]],\n",
       "\n",
       "        [[0.42745098],\n",
       "         [0.35686275],\n",
       "         [0.47058824],\n",
       "         ...,\n",
       "         [0.36078432],\n",
       "         [0.4862745 ],\n",
       "         [0.6       ]],\n",
       "\n",
       "        [[0.3647059 ],\n",
       "         [0.39607844],\n",
       "         [0.5372549 ],\n",
       "         ...,\n",
       "         [0.3764706 ],\n",
       "         [0.5372549 ],\n",
       "         [0.4392157 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5058824 ],\n",
       "         [0.46666667],\n",
       "         [0.3372549 ],\n",
       "         ...,\n",
       "         [0.26666668],\n",
       "         [0.25490198],\n",
       "         [0.17254902]],\n",
       "\n",
       "        [[0.4862745 ],\n",
       "         [0.4509804 ],\n",
       "         [0.40784314],\n",
       "         ...,\n",
       "         [0.29803923],\n",
       "         [0.16078432],\n",
       "         [0.18039216]],\n",
       "\n",
       "        [[0.43529412],\n",
       "         [0.31764707],\n",
       "         [0.50980395],\n",
       "         ...,\n",
       "         [0.24705882],\n",
       "         [0.16078432],\n",
       "         [0.17254902]]],\n",
       "\n",
       "\n",
       "       [[[0.47058824],\n",
       "         [0.3882353 ],\n",
       "         [0.41960785],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.60784316],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        [[0.49411765],\n",
       "         [0.3882353 ],\n",
       "         [0.49803922],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.6117647 ],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        [[0.43529412],\n",
       "         [0.3882353 ],\n",
       "         [0.49411765],\n",
       "         ...,\n",
       "         [0.59607846],\n",
       "         [0.5882353 ],\n",
       "         [0.60784316]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3372549 ],\n",
       "         [0.44705883],\n",
       "         [0.43137255],\n",
       "         ...,\n",
       "         [0.48235294],\n",
       "         [0.5176471 ],\n",
       "         [0.4627451 ]],\n",
       "\n",
       "        [[0.2627451 ],\n",
       "         [0.39607844],\n",
       "         [0.32941177],\n",
       "         ...,\n",
       "         [0.4627451 ],\n",
       "         [0.47843137],\n",
       "         [0.4745098 ]],\n",
       "\n",
       "        [[0.3019608 ],\n",
       "         [0.3882353 ],\n",
       "         [0.41960785],\n",
       "         ...,\n",
       "         [0.5019608 ],\n",
       "         [0.5058824 ],\n",
       "         [0.49803922]]],\n",
       "\n",
       "\n",
       "       [[[0.57254905],\n",
       "         [0.5882353 ],\n",
       "         [0.6       ],\n",
       "         ...,\n",
       "         [0.6745098 ],\n",
       "         [0.67058825],\n",
       "         [0.65882355]],\n",
       "\n",
       "        [[0.5882353 ],\n",
       "         [0.6117647 ],\n",
       "         [0.6392157 ],\n",
       "         ...,\n",
       "         [0.627451  ],\n",
       "         [0.6431373 ],\n",
       "         [0.627451  ]],\n",
       "\n",
       "        [[0.6156863 ],\n",
       "         [0.6117647 ],\n",
       "         [0.60784316],\n",
       "         ...,\n",
       "         [0.63529414],\n",
       "         [0.627451  ],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3529412 ],\n",
       "         [0.33333334],\n",
       "         [0.37254903],\n",
       "         ...,\n",
       "         [0.3372549 ],\n",
       "         [0.40784314],\n",
       "         [0.43529412]],\n",
       "\n",
       "        [[0.4       ],\n",
       "         [0.4117647 ],\n",
       "         [0.4509804 ],\n",
       "         ...,\n",
       "         [0.41568628],\n",
       "         [0.4627451 ],\n",
       "         [0.5529412 ]],\n",
       "\n",
       "        [[0.38039216],\n",
       "         [0.39607844],\n",
       "         [0.40784314],\n",
       "         ...,\n",
       "         [0.4627451 ],\n",
       "         [0.43137255],\n",
       "         [0.4745098 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initalize()\n",
    "train_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 12 11 ... 12 18 20]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the time into 24 separate labels\n",
    "def conv_time_24(time):\n",
    "    ntime = 0\n",
    "    if time[1] > 30:\n",
    "        ntime = (time[0] + 0.5)\n",
    "    else:\n",
    "        ntime = time[0]\n",
    "    return ntime\n",
    "\n",
    "# Convert the time into 720 separate labels \n",
    "def conv_time_720(time):\n",
    "    return time[0]*60 + time[1]\n",
    "\n",
    "conv_time = conv_time_24\n",
    "while True:\n",
    "    initalize()\n",
    "    train_labels_converted = np.array([conv_time(time) for time in train_labels])\n",
    "    test_labels_converted = np.array([conv_time(time) for time in test_labels])\n",
    "    val_labels_converted = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    test_labels_encoded = encoder.fit_transform(test_labels_converted.reshape(-1))\n",
    "    train_labels_encoded = encoder.fit_transform(train_labels_converted.reshape(-1))\n",
    "    val_labels_encoded = encoder.fit_transform(val_labels_converted.reshape(-1))\n",
    "\n",
    "    OHencoder = OneHotEncoder(sparse_output=False)\n",
    "    train_labels_oh = OHencoder.fit_transform(train_labels_encoded.reshape(-1, 1))\n",
    "    val_labels_oh = OHencoder.fit_transform(val_labels_encoded.reshape(-1, 1))\n",
    "    print(val_labels_encoded)\n",
    "    print(val_labels_oh)\n",
    "    \n",
    "    # Check if all labels are present in the validation set, if not, reshuffle\n",
    "    try:\n",
    "        val_labels_oh = val_labels_oh.reshape((val_labels_oh.shape[0], 24))\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common sense error function- checks the smaller of the differences by converting to military time\n",
    "def common_sense_error(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff1 = K.abs(pred-true)\n",
    "    diff2 = K.abs(pred+12-true)\n",
    "    return K.minimum(diff1, diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 75, 75, 1) (14400, 24)\n",
      "Epoch 1/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - common_sense_error: 0.0799 - loss: 3.1781 - val_common_sense_error: 0.0799 - val_loss: 3.1781\n",
      "Epoch 2/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - common_sense_error: 0.0799 - loss: 3.1780 - val_common_sense_error: 0.0799 - val_loss: 3.1781\n",
      "Epoch 3/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - common_sense_error: 0.0799 - loss: 3.1779 - val_common_sense_error: 0.0799 - val_loss: 3.1781\n",
      "Epoch 4/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - common_sense_error: 0.0799 - loss: 3.1778 - val_common_sense_error: 0.0799 - val_loss: 3.1781\n",
      "Epoch 5/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - common_sense_error: 0.0799 - loss: 3.1776 - val_common_sense_error: 0.0799 - val_loss: 3.1781\n",
      "Epoch 6/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - common_sense_error: 0.0799 - loss: 3.1777 - val_common_sense_error: 0.0799 - val_loss: 3.1780\n",
      "Epoch 7/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - common_sense_error: 0.0799 - loss: 3.1763 - val_common_sense_error: 0.0798 - val_loss: 3.1683\n",
      "Epoch 8/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - common_sense_error: 0.0797 - loss: 3.1544 - val_common_sense_error: 0.0795 - val_loss: 3.1229\n",
      "Epoch 9/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - common_sense_error: 0.0794 - loss: 3.1107 - val_common_sense_error: 0.0792 - val_loss: 3.0734\n",
      "Epoch 10/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - common_sense_error: 0.0791 - loss: 3.0681 - val_common_sense_error: 0.0784 - val_loss: 2.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x73bc39aa2c80>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (75, 75, 1)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), strides = (2,2), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "# First layer - one neuron for each pixel\n",
    "model.add(keras.layers.Dense(units=625, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=24, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[common_sense_error])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.fit(train_imgs, train_labels_oh, epochs=10, batch_size=256, validation_data=(val_imgs, val_labels_oh), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "8.166666666666666 %\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_imgs)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "\n",
    "results = encoder.inverse_transform(preds)\n",
    "accuracy = np.sum(results == test_labels_converted) / len(test_labels_converted)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#returning the common sense difference between two times\n",
    "def common_sense_error(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff_1 = K.abs(true - pred)\n",
    "    diff_2 = K.abs(true - (pred + 12))\n",
    "\n",
    "    return K.minimum(diff_1, diff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - common_sense_error: 3.0834 - loss: 19.0580 - val_common_sense_error: 3.0621 - val_loss: 12.8423\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - common_sense_error: 3.0335 - loss: 12.6101 - val_common_sense_error: 2.9572 - val_loss: 11.6659\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 257ms/step - common_sense_error: 3.0004 - loss: 12.2394 - val_common_sense_error: 2.9553 - val_loss: 12.1154\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - common_sense_error: 3.0051 - loss: 12.0379 - val_common_sense_error: 3.0384 - val_loss: 11.6103\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 257ms/step - common_sense_error: 3.0441 - loss: 11.8143 - val_common_sense_error: 2.9587 - val_loss: 11.4221\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 261ms/step - common_sense_error: 3.0263 - loss: 10.8949 - val_common_sense_error: 3.0077 - val_loss: 10.6288\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 263ms/step - common_sense_error: 3.1190 - loss: 10.6135 - val_common_sense_error: 3.1383 - val_loss: 9.8279\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - common_sense_error: 3.1161 - loss: 9.9503 - val_common_sense_error: 3.3231 - val_loss: 10.6376\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 257ms/step - common_sense_error: 3.1678 - loss: 9.8118 - val_common_sense_error: 3.1528 - val_loss: 9.0458\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - common_sense_error: 3.1764 - loss: 8.8242 - val_common_sense_error: 3.0832 - val_loss: 8.5128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x73bc383cb010>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initalize()\n",
    "\n",
    "def conv_time(time):\n",
    "    return round(time[0] + time[1]/60, 3)\n",
    "\n",
    "train_labels_reg = np.array([conv_time(time) for time in train_labels])\n",
    "test_labels_reg = np.array([conv_time(time) for time in test_labels])\n",
    "val_labels_reg = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), input_shape=(75, 75, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[common_sense_error])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, train_labels_reg, epochs=10, batch_size = 512, validation_data = (val_imgs, val_labels_reg), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "2.6464506172839504 %\n"
     ]
    }
   ],
   "source": [
    "reg_preds = model.predict(test_imgs)\n",
    "# for i in range(len(reg_preds)):\n",
    "#     print(reg_preds[i], test_labels_reg[i])\n",
    "accuracy = np.mean(abs(reg_preds - test_labels_reg) < 0.16)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Headed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hours = train_labels[:, 0]\n",
    "train_minutes = train_labels[:, 1]\n",
    "\n",
    "val_hours = val_labels[:, 0]\n",
    "val_minutes = val_labels[:, 1]\n",
    "\n",
    "test_hours = test_labels[:, 0]\n",
    "test_minutes = test_labels[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - hour_accuracy: 0.0841 - hour_loss: 2.4895 - loss: 829.4688 - minute_loss: 826.4379 - minute_mae: 23.7829 - val_hour_accuracy: 0.0750 - val_hour_loss: 2.4848 - val_loss: 378.0327 - val_minute_loss: 376.9552 - val_minute_mae: 16.3143\n",
      "Epoch 2/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4860 - loss: 325.5216 - minute_loss: 323.0148 - minute_mae: 15.3859 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4858 - val_loss: 307.5529 - val_minute_loss: 305.6083 - val_minute_mae: 15.1643\n",
      "Epoch 3/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - hour_accuracy: 0.0877 - hour_loss: 2.4849 - loss: 302.8543 - minute_loss: 300.3875 - minute_mae: 14.9173 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 308.9561 - val_minute_loss: 307.1851 - val_minute_mae: 15.1973\n",
      "Epoch 4/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4850 - loss: 304.8977 - minute_loss: 302.4233 - minute_mae: 15.0504 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 307.5492 - val_minute_loss: 305.7039 - val_minute_mae: 15.1693\n",
      "Epoch 5/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - hour_accuracy: 0.0869 - hour_loss: 2.4849 - loss: 307.7698 - minute_loss: 305.3444 - minute_mae: 15.1228 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 310.3996 - val_minute_loss: 308.6734 - val_minute_mae: 15.2246\n",
      "Epoch 6/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0908 - hour_loss: 2.4848 - loss: 301.9066 - minute_loss: 299.4661 - minute_mae: 14.9081 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 312.4124 - val_minute_loss: 310.7340 - val_minute_mae: 15.2593\n",
      "Epoch 7/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0837 - hour_loss: 2.4849 - loss: 303.1441 - minute_loss: 300.7387 - minute_mae: 15.0162 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 307.2387 - val_minute_loss: 305.3678 - val_minute_mae: 15.1627\n",
      "Epoch 8/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0857 - hour_loss: 2.4848 - loss: 306.2672 - minute_loss: 303.8863 - minute_mae: 15.0918 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 307.0891 - val_minute_loss: 305.1805 - val_minute_mae: 15.1586\n",
      "Epoch 9/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0814 - hour_loss: 2.4846 - loss: 302.4586 - minute_loss: 299.9069 - minute_mae: 14.9688 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 308.9388 - val_minute_loss: 307.1643 - val_minute_mae: 15.1971\n",
      "Epoch 10/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0840 - hour_loss: 2.4849 - loss: 304.2012 - minute_loss: 301.6515 - minute_mae: 15.0303 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 307.1815 - val_minute_loss: 305.2278 - val_minute_mae: 15.1585\n",
      "Epoch 11/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0863 - hour_loss: 2.4849 - loss: 306.1272 - minute_loss: 303.6411 - minute_mae: 15.0212 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 311.3133 - val_minute_loss: 309.1958 - val_minute_mae: 15.2168\n",
      "Epoch 12/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0818 - hour_loss: 2.4850 - loss: 305.1154 - minute_loss: 302.4674 - minute_mae: 15.0042 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4858 - val_loss: 307.5606 - val_minute_loss: 305.7234 - val_minute_mae: 15.1713\n",
      "Epoch 13/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - hour_accuracy: 0.0829 - hour_loss: 2.4849 - loss: 305.0788 - minute_loss: 302.5595 - minute_mae: 15.0200 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4858 - val_loss: 333.2896 - val_minute_loss: 331.8762 - val_minute_mae: 15.5989\n",
      "Epoch 14/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0874 - hour_loss: 2.4846 - loss: 311.1877 - minute_loss: 308.7715 - minute_mae: 15.1312 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 329.8145 - val_minute_loss: 328.3634 - val_minute_mae: 15.5437\n",
      "Epoch 15/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - hour_accuracy: 0.0842 - hour_loss: 2.4849 - loss: 310.5639 - minute_loss: 307.9851 - minute_mae: 15.1363 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 332.4966 - val_minute_loss: 331.0694 - val_minute_mae: 15.5858\n",
      "Epoch 16/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0797 - hour_loss: 2.4850 - loss: 308.0009 - minute_loss: 305.5806 - minute_mae: 15.0280 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 307.3638 - val_minute_loss: 305.5168 - val_minute_mae: 15.1676\n",
      "Epoch 17/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0846 - hour_loss: 2.4849 - loss: 301.4080 - minute_loss: 298.9267 - minute_mae: 14.9162 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 308.1247 - val_minute_loss: 306.3045 - val_minute_mae: 15.1820\n",
      "Epoch 18/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4849 - loss: 304.8048 - minute_loss: 302.2126 - minute_mae: 15.0063 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 309.6288 - val_minute_loss: 307.4865 - val_minute_mae: 15.1872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x73bc775b10c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = keras.layers.Input(shape = (75,75,1))\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (5,5), strides= (2,2), activation = \"relu\")(inp)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (1,1),activation = \"relu\")(model)\n",
    "model = keras.layers.Flatten()(model)\n",
    "\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(model)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "d = keras.layers.Dropout(0.1)(d)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "\n",
    "hour = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "hour = keras.layers.Dense(128,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(64,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(32,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(16,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(12,activation= \"softmax\", name= \"hour\")(hour)\n",
    "\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(128,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(64,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(32,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(16,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(1, activation = \"softplus\", name = \"minute\")(minute)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=[hour, minute])\n",
    "optim = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=['sparse_categorical_crossentropy', 'mse'], optimizer=optim, metrics=['accuracy',\"mae\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, [train_hours, train_minutes], epochs=30, batch_size = 512, validation_data = (val_imgs, [val_hours, val_minutes]), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_imgs)\n\u001b[0;32m----> 2\u001b[0m hour_p \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m minutes_p \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(hour_p \u001b[38;5;241m-\u001b[39m test_hours) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(minutes_p \u001b[38;5;241m-\u001b[39m test_minutes) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:1298\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_imgs)\n",
    "hour_p = np.argmax(predictions[0], axis = 1)\n",
    "minutes_p = predictions[1]\n",
    "\n",
    "accuracy = np.mean(np.abs(hour_p - test_hours) < 1) * np.mean(np.abs(minutes_p - test_minutes) < 5)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Transformation using Periodic Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_time_train = (train_hours*60 + train_minutes) \n",
    "sine_time_test = (test_hours*60 + test_minutes)  \n",
    "sine_time_valid = (val_hours*60 + val_minutes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(719)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sine_time_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_angle_test = (sine_time_test/720)*2*np.pi\n",
    "sine_angle_train = (sine_time_train/720)*2*np.pi\n",
    "sine_angle_valid = (sine_time_valid/720)*2*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sine_angle_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     28\u001b[0m sin_reg\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m optimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 29\u001b[0m sin_reg\u001b[38;5;241m.\u001b[39mfit(train_imgs, \u001b[43msine_angle_train\u001b[49m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (val_imgs, sine_angle_valid), callbacks \u001b[38;5;241m=\u001b[39m [early_stop])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sine_angle_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Sine Regression CNN\n",
    "\n",
    "sin_reg = keras.models.Sequential()\n",
    "sin_reg.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides = (2,2),input_shape=(75, 75, 1)))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "sin_reg.add(keras.layers.Flatten())\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "sin_reg.compile(loss='mse', optimizer= optimizer, metrics=['mae'])\n",
    "sin_reg.fit(train_imgs, sine_angle_train, epochs=45, batch_size = 512, validation_data = (val_imgs, sine_angle_valid), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "predictions = sin_reg.predict(test_imgs)\n",
    "\n",
    "def difference_func(pred,y):\n",
    "  pred = np.transpose(pred)\n",
    "  diff_one = np.maximum(pred,y) - np.minimum(pred,y)\n",
    "  diff_two = np.minimum(pred,y) + 1 - np.maximum(pred,y)\n",
    "  return np.minimum(diff_one,diff_two)\n",
    "\n",
    "result = difference_func(predictions,sine_angle_test).reshape(-1)\n",
    "\n",
    "accuracy = np.mean(result < np.pi/6)\n",
    "print(accuracy*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
