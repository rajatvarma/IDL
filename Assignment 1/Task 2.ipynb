{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 17:26:44.607266: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-01 17:26:44.806621: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-01 17:26:47.875816: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-01 17:26:49.945123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730478411.723891   47856 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730478412.148336   47856 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-01 17:26:56.758439: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = np.load('75/images.npy')\n",
    "imgs = imgs.astype('float32')\n",
    "indices = np.random.permutation(imgs.shape[0])\n",
    "imgs = imgs[indices]\n",
    "\n",
    "split_1 = int(18000*0.8)\n",
    "split_2 = int(18000*0.9)\n",
    "\n",
    "train_imgs = imgs[:split_1]\n",
    "val_imgs = imgs[split_1:split_2]\n",
    "test_imgs = imgs[split_2:]\n",
    "\n",
    "train_imgs = train_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0\n",
    "val_imgs = val_imgs / 255.0\n",
    "\n",
    "labels = np.load('75/labels.npy')\n",
    "labels = labels.astype('int32')\n",
    "labels = labels[indices]\n",
    "train_labels = labels[:split_1]\n",
    "val_labels = labels[split_1:split_2]\n",
    "test_labels = labels[split_2:]\n",
    "\n",
    "train_imgs = train_imgs.reshape((train_imgs.shape[0], 75, 75, 1))\n",
    "val_imgs = val_imgs.reshape((val_imgs.shape[0], 75, 75, 1))\n",
    "test_imgs = test_imgs.reshape((test_imgs.shape[0], 75, 75, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_time(time):\n",
    "    ntime = 0\n",
    "    if time[1] > 30:\n",
    "        ntime = (time[0] + 0.5)\n",
    "    else:\n",
    "        ntime = time[0]\n",
    "    return ntime\n",
    "\n",
    "train_labels_converted = np.array([conv_time(time) for time in train_labels])\n",
    "test_labels_converted = np.array([conv_time(time) for time in test_labels])\n",
    "val_labels_converted = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "test_labels_encoded = encoder.fit_transform(test_labels_converted.reshape(-1))\n",
    "train_labels_encoded = encoder.fit_transform(train_labels_converted.reshape(-1))\n",
    "val_labels_encoded = encoder.fit_transform(val_labels_converted.reshape(-1))\n",
    "\n",
    "OHencoder = OneHotEncoder(sparse_output=False)\n",
    "train_labels_oh = OHencoder.fit_transform(train_labels_encoded.reshape(-1, 1))\n",
    "val_labels_oh = OHencoder.fit_transform(val_labels_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 75, 75, 1) (14400, 24)\n",
      "Epoch 1/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.0445 - loss: 3.1780 - val_accuracy: 0.0489 - val_loss: 3.1780\n",
      "Epoch 2/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.0440 - loss: 3.1779 - val_accuracy: 0.0489 - val_loss: 3.1779\n",
      "Epoch 3/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.0396 - loss: 3.1779 - val_accuracy: 0.0489 - val_loss: 3.1780\n",
      "Epoch 4/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.0428 - loss: 3.1778 - val_accuracy: 0.0489 - val_loss: 3.1777\n",
      "Epoch 5/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.0422 - loss: 3.1776 - val_accuracy: 0.0506 - val_loss: 3.1765\n",
      "Epoch 6/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.0492 - loss: 3.1745 - val_accuracy: 0.0561 - val_loss: 3.1620\n",
      "Epoch 7/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.0595 - loss: 3.1476 - val_accuracy: 0.0772 - val_loss: 3.0729\n",
      "Epoch 8/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.0714 - loss: 3.0603 - val_accuracy: 0.0850 - val_loss: 3.0024\n",
      "Epoch 9/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.0882 - loss: 2.9954 - val_accuracy: 0.0939 - val_loss: 2.9366\n",
      "Epoch 10/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.0894 - loss: 2.9552 - val_accuracy: 0.0972 - val_loss: 2.9353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7da3f1817b80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (75, 75, 1)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(kernel_size=(5,5), strides = (2,2), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=24, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "print(train_imgs.shape, train_labels_oh.shape)\n",
    "val_labels_oh = val_labels_oh.reshape((val_labels_oh.shape[0], 24))\n",
    "\n",
    "model.fit(train_imgs, train_labels_oh, epochs=10, batch_size=256, validation_data=(val_imgs, val_labels_oh), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "9.555555555555555 %\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_imgs)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "\n",
    "results = encoder.inverse_transform(preds)\n",
    "\n",
    "accuracy = np.sum(results == test_labels_converted) / len(test_labels_converted)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#returning the common sense difference between two times\n",
    "def difference_func(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff_1 = K.abs(true - pred)\n",
    "    diff_2 = K.abs(true - (pred + 12*60))\n",
    "\n",
    "    return K.minimum(diff_1, diff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - difference_func: 180.9812 - loss: 180.9812 - val_difference_func: 182.6678 - val_loss: 182.6678\n",
      "Epoch 2/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 179.9021 - loss: 179.9021 - val_difference_func: 182.6679 - val_loss: 182.6679\n",
      "Epoch 3/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 180.5134 - loss: 180.5133 - val_difference_func: 182.6681 - val_loss: 182.6681\n",
      "Epoch 4/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - difference_func: 180.2920 - loss: 180.2920 - val_difference_func: 182.6682 - val_loss: 182.6682\n",
      "Epoch 5/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 180.8344 - loss: 180.8343 - val_difference_func: 182.6682 - val_loss: 182.6682\n",
      "Epoch 6/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - difference_func: 180.2010 - loss: 180.2010 - val_difference_func: 182.6681 - val_loss: 182.6681\n",
      "Epoch 7/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - difference_func: 181.4108 - loss: 181.4108 - val_difference_func: 182.6683 - val_loss: 182.6683\n",
      "Epoch 8/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - difference_func: 181.2081 - loss: 181.2081 - val_difference_func: 182.6685 - val_loss: 182.6685\n",
      "Epoch 9/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - difference_func: 179.1715 - loss: 179.1715 - val_difference_func: 182.6685 - val_loss: 182.6684\n",
      "Epoch 10/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - difference_func: 180.4306 - loss: 180.4306 - val_difference_func: 182.6685 - val_loss: 182.6685\n",
      "Epoch 11/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - difference_func: 179.7157 - loss: 179.7156 - val_difference_func: 182.6685 - val_loss: 182.6685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7da354196ec0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_reg = np.array([(time[0]*60+time[1]) for time in train_labels])\n",
    "test_labels_reg = np.array([(time[0]*60+time[1]) for time in test_labels])\n",
    "val_labels_reg = np.array([(time[0]*60+time[1]) for time in val_labels])\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides = (2,2),input_shape=(75, 75, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "model.compile(loss=difference_func, optimizer=\"adam\", metrics=[difference_func])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, train_labels_reg, epochs=40, batch_size = 512, validation_data = (val_imgs, val_labels_reg), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "1.0555555555555556 %\n"
     ]
    }
   ],
   "source": [
    "reg_preds = model.predict(test_imgs)\n",
    "accuracy = np.mean(np.abs(reg_preds - test_labels_reg) < 5)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Headed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1938266)\n",
    "\n",
    "inp = layers.Input(shape = (150,150,1))\n",
    "model = layers.Convolution2D(32,kernel_size = (5,5), strides= (2,2), activation = \"relu\")(inp)\n",
    "model = layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = layers.Convolution2D(64,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = layers.Convolution2D(64,kernel_size = (1,1),activation = \"relu\")(model)\n",
    "model = layers.Flatten()(model)\n",
    "\n",
    "dense = layers.Dense(256,activation = \"relu\")(model)\n",
    "dense = layers.Dense(256,activation = \"relu\")(dense)\n",
    "dense = layers.Dropout(0.1)(dense)\n",
    "dense = layers.Dense(256,activation = \"relu\")(dense)\n",
    "\n",
    "hour = layers.Dense(256,activation = \"relu\")(dense)\n",
    "hour = layers.Dense(128,activation = \"relu\")(hour)\n",
    "hour = layers.Dense(64,activation = \"relu\")(hour)\n",
    "hour = layers.Dense(32,activation = \"relu\")(hour)\n",
    "hour = layers.Dense(16,activation = \"relu\")(hour)\n",
    "hour = layers.Dense(12,activation= \"softmax\", name= \"hour\")(hour)\n",
    "\n",
    "minute = layers.Dense(256,activation = \"relu\")(dense)\n",
    "minute = layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = layers.Dense(128,activation = \"relu\")(minute)\n",
    "minute = layers.Dense(64,activation = \"relu\")(minute)\n",
    "minute = layers.Dense(32,activation = \"relu\")(minute)\n",
    "minute = layers.Dense(16,activation = \"relu\")(minute)\n",
    "minute = layers.Dense(1, activation = \"softplus\", name = \"minute\")(minute)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=[hour, minute])\n",
    "optim = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=['sparse_categorical_crossentropy', 'mse'], optimizer=optim, metrics=['accuracy',\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1938266)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_images, [train_hours,train_minutes], epochs=30, batch_size = 512,\n",
    "         validation_data = (valid_images, [valid_hours,valid_minutes]), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "hour_p = np.argmax(predictions[0], axis = 1)\n",
    "minutes_p = predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic function CNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make everything in minutes\n",
    "sine_time_train = (train_hours  + train_minutes) \n",
    "sine_time_test = (test_hours  + test_minutes)  \n",
    "sine_time_valid = (valid_hours + valid_minutes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.983334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.max(sine_time_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make everything in the support of the sine function.\n",
    "def sine_transform(data, max):\n",
    "  tmp = data / max # to normalize\n",
    "  return np.sin(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_angle_train = np.empty(13900, dtype=float)\n",
    "sine_angle_test = np.empty(3600, dtype=float)\n",
    "sine_angle_valid = np.empty(500, dtype=float)\n",
    "\n",
    "for i in np.arange(len(sine_angle_train)):\n",
    "  sine_angle_train[i] = sine_transform(sine_time_train[i], np.max(sine_time_train))\n",
    "\n",
    "for i in np.arange(len(sine_angle_test)):\n",
    "  sine_angle_test[i] = sine_transform(sine_time_test[i], np.max(sine_time_test))\n",
    "\n",
    "for i in np.arange(len(sine_angle_valid)):\n",
    "  sine_angle_valid[i] = sine_transform(sine_time_valid[i], np.max(sine_time_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "28/28 [==============================] - 6s 184ms/step - loss: 0.0755 - mae: 0.2307 - val_loss: 0.0611 - val_mae: 0.2144\n",
      "Epoch 2/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0622 - mae: 0.2163 - val_loss: 0.0614 - val_mae: 0.2162\n",
      "Epoch 3/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0620 - mae: 0.2162 - val_loss: 0.0615 - val_mae: 0.2164\n",
      "Epoch 4/45\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.0621 - mae: 0.2162 - val_loss: 0.0611 - val_mae: 0.2147\n",
      "Epoch 5/45\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.0621 - mae: 0.2163 - val_loss: 0.0614 - val_mae: 0.2163\n",
      "Epoch 6/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0622 - mae: 0.2164 - val_loss: 0.0611 - val_mae: 0.2135\n",
      "Epoch 7/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0620 - mae: 0.2159 - val_loss: 0.0611 - val_mae: 0.2135\n",
      "Epoch 8/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0617 - mae: 0.2158 - val_loss: 0.0610 - val_mae: 0.2137\n",
      "Epoch 9/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0622 - mae: 0.2164 - val_loss: 0.0612 - val_mae: 0.2131\n",
      "Epoch 10/45\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.0617 - mae: 0.2157 - val_loss: 0.0610 - val_mae: 0.2151\n",
      "Epoch 11/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0609 - mae: 0.2138 - val_loss: 0.0650 - val_mae: 0.2116\n",
      "Epoch 12/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0568 - mae: 0.2012 - val_loss: 0.0587 - val_mae: 0.2036\n",
      "Epoch 13/45\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.0501 - mae: 0.1817 - val_loss: 0.0446 - val_mae: 0.1648\n",
      "Epoch 14/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0391 - mae: 0.1528 - val_loss: 0.0333 - val_mae: 0.1353\n",
      "Epoch 15/45\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.0286 - mae: 0.1244 - val_loss: 0.0300 - val_mae: 0.1211\n",
      "Epoch 16/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0215 - mae: 0.1028 - val_loss: 0.0221 - val_mae: 0.1042\n",
      "Epoch 17/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0162 - mae: 0.0876 - val_loss: 0.0141 - val_mae: 0.0797\n",
      "Epoch 18/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0116 - mae: 0.0698 - val_loss: 0.0157 - val_mae: 0.0786\n",
      "Epoch 19/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0100 - mae: 0.0638 - val_loss: 0.0117 - val_mae: 0.0679\n",
      "Epoch 20/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0076 - mae: 0.0552 - val_loss: 0.0095 - val_mae: 0.0604\n",
      "Epoch 21/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0057 - mae: 0.0485 - val_loss: 0.0086 - val_mae: 0.0545\n",
      "Epoch 22/45\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.0067 - mae: 0.0521 - val_loss: 0.0078 - val_mae: 0.0523\n",
      "Epoch 23/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0056 - mae: 0.0456 - val_loss: 0.0203 - val_mae: 0.0856\n",
      "Epoch 24/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0109 - mae: 0.0663 - val_loss: 0.0096 - val_mae: 0.0596\n",
      "Epoch 25/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0042 - mae: 0.0419 - val_loss: 0.0077 - val_mae: 0.0497\n",
      "Epoch 26/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0038 - mae: 0.0389 - val_loss: 0.0057 - val_mae: 0.0417\n",
      "Epoch 27/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0036 - val_mae: 0.0355\n",
      "Epoch 28/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0046 - val_mae: 0.0358\n",
      "Epoch 29/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0043 - val_mae: 0.0335\n",
      "Epoch 30/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0034 - mae: 0.0340 - val_loss: 0.0077 - val_mae: 0.0465\n",
      "Epoch 31/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0023 - mae: 0.0315 - val_loss: 0.0074 - val_mae: 0.0375\n",
      "Epoch 32/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.0057 - val_mae: 0.0343\n",
      "Epoch 33/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0026 - mae: 0.0310 - val_loss: 0.0071 - val_mae: 0.0420\n",
      "Epoch 34/45\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.0045 - mae: 0.0390 - val_loss: 0.0067 - val_mae: 0.0400\n",
      "Epoch 35/45\n",
      "28/28 [==============================] - 5s 173ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0055 - val_mae: 0.0345\n",
      "Epoch 36/45\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0070 - val_mae: 0.0357\n",
      "Epoch 37/45\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.0015 - mae: 0.0243 - val_loss: 0.0077 - val_mae: 0.0370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde0d9afb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1938266)\n",
    "\n",
    "# Sin Regression CNN\n",
    "\n",
    "input_shape=(images.shape[1], images.shape[2], 1)\n",
    "\n",
    "sin_reg = keras.models.Sequential()\n",
    "sin_reg.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides = (2,2),input_shape=input_shape))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "sin_reg.add(keras.layers.Flatten())\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "sin_reg.compile(loss='mse', optimizer= optimizer, metrics=['mae'])\n",
    "sin_reg.fit(train_images, sine_angle_train, epochs=45, batch_size = 512, validation_data = (valid_images,sine_angle_valid), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sin_reg.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_func(pred,y):\n",
    "  pred = np.transpose(pred)\n",
    "  diff_one = np.maximum(pred,y) - np.minimum(pred,y)\n",
    "  diff_two = np.minimum(pred,y) + 1 - np.maximum(pred,y)\n",
    "  return np.minimum(diff_one,diff_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = difference_func(predictions,sine_angle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_back(data, max):\n",
    "  out = np.empty(3600, dtype=float)\n",
    "  for i in np.arange(len(data)):\n",
    "    out[i] = np.arcsin(data[i]) * max\n",
    "\n",
    "  return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_back = go_back(result, np.max(sine_time_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.882693734323716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.mean(go_back) * 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
