{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting these as global variables so that they can be shuffled to ensure an even distribution- many times I wasn't getting all 24/720 labels in the validation set\n",
    "\n",
    "images = np.load('75/images.npy')\n",
    "images = images.astype('float32')\n",
    "\n",
    "# Function that shuffles the images and labels into training, validation, and test sets\n",
    "def initalize():\n",
    "    global imgs, train_imgs, val_imgs, test_imgs, train_labels, val_labels, test_labels, distributed\n",
    "    indices = np.random.permutation(images.shape[0])\n",
    "    imgs = images[indices]\n",
    "\n",
    "    split_1 = int(18000*0.8)\n",
    "    split_2 = int(18000*0.9)\n",
    "\n",
    "    train_imgs = imgs[:split_1]\n",
    "    val_imgs = imgs[split_1:split_2]\n",
    "    test_imgs = imgs[split_2:]\n",
    "\n",
    "    # Normalizing the images\n",
    "    train_imgs = train_imgs / 255.0\n",
    "    test_imgs = test_imgs / 255.0\n",
    "    val_imgs = val_imgs / 255.0\n",
    "\n",
    "    labels = np.load('75/labels.npy')\n",
    "    labels = labels.astype('int32')\n",
    "    labels = labels[indices]\n",
    "    train_labels = labels[:split_1]\n",
    "    val_labels = labels[split_1:split_2]\n",
    "    test_labels = labels[split_2:]\n",
    "\n",
    "    train_imgs = train_imgs.reshape((train_imgs.shape[0], 75, 75, 1))\n",
    "    val_imgs = val_imgs.reshape((val_imgs.shape[0], 75, 75, 1))\n",
    "    test_imgs = test_imgs.reshape((test_imgs.shape[0], 75, 75, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.3529412 ],\n",
       "         [0.3529412 ],\n",
       "         [0.3372549 ],\n",
       "         ...,\n",
       "         [0.4627451 ],\n",
       "         [0.5411765 ],\n",
       "         [0.47058824]],\n",
       "\n",
       "        [[0.39215687],\n",
       "         [0.42352942],\n",
       "         [0.3882353 ],\n",
       "         ...,\n",
       "         [0.49803922],\n",
       "         [0.49803922],\n",
       "         [0.47843137]],\n",
       "\n",
       "        [[0.34901962],\n",
       "         [0.36078432],\n",
       "         [0.34509805],\n",
       "         ...,\n",
       "         [0.49411765],\n",
       "         [0.47843137],\n",
       "         [0.47058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.49019608],\n",
       "         [0.5176471 ],\n",
       "         [0.5137255 ],\n",
       "         ...,\n",
       "         [0.6039216 ],\n",
       "         [0.6156863 ],\n",
       "         [0.58431375]],\n",
       "\n",
       "        [[0.41568628],\n",
       "         [0.43529412],\n",
       "         [0.39607844],\n",
       "         ...,\n",
       "         [0.47843137],\n",
       "         [0.4862745 ],\n",
       "         [0.4745098 ]],\n",
       "\n",
       "        [[0.5294118 ],\n",
       "         [0.5058824 ],\n",
       "         [0.53333336],\n",
       "         ...,\n",
       "         [0.47058824],\n",
       "         [0.47843137],\n",
       "         [0.5137255 ]]],\n",
       "\n",
       "\n",
       "       [[[0.58431375],\n",
       "         [0.5882353 ],\n",
       "         [0.5921569 ],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.59607846],\n",
       "         [0.59607846]],\n",
       "\n",
       "        [[0.6156863 ],\n",
       "         [0.60784316],\n",
       "         [0.5764706 ],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.5921569 ],\n",
       "         [0.6039216 ]],\n",
       "\n",
       "        [[0.6039216 ],\n",
       "         [0.6       ],\n",
       "         [0.6745098 ],\n",
       "         ...,\n",
       "         [0.60784316],\n",
       "         [0.59607846],\n",
       "         [0.5764706 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627452],\n",
       "         [0.28627452],\n",
       "         [0.44313726],\n",
       "         ...,\n",
       "         [0.36078432],\n",
       "         [0.39215687],\n",
       "         [0.34509805]],\n",
       "\n",
       "        [[0.26666668],\n",
       "         [0.3764706 ],\n",
       "         [0.2784314 ],\n",
       "         ...,\n",
       "         [0.39607844],\n",
       "         [0.36078432],\n",
       "         [0.3529412 ]],\n",
       "\n",
       "        [[0.3647059 ],\n",
       "         [0.4627451 ],\n",
       "         [0.29411766],\n",
       "         ...,\n",
       "         [0.38039216],\n",
       "         [0.35686275],\n",
       "         [0.27058825]]],\n",
       "\n",
       "\n",
       "       [[[0.5764706 ],\n",
       "         [0.5529412 ],\n",
       "         [0.6       ],\n",
       "         ...,\n",
       "         [0.53333336],\n",
       "         [0.3254902 ],\n",
       "         [0.4117647 ]],\n",
       "\n",
       "        [[0.5921569 ],\n",
       "         [0.5882353 ],\n",
       "         [0.5019608 ],\n",
       "         ...,\n",
       "         [0.4117647 ],\n",
       "         [0.3764706 ],\n",
       "         [0.4627451 ]],\n",
       "\n",
       "        [[0.57254905],\n",
       "         [0.53333336],\n",
       "         [0.5568628 ],\n",
       "         ...,\n",
       "         [0.32156864],\n",
       "         [0.42352942],\n",
       "         [0.49019608]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.47058824],\n",
       "         [0.5372549 ],\n",
       "         [0.44313726],\n",
       "         ...,\n",
       "         [0.30980393],\n",
       "         [0.3019608 ],\n",
       "         [0.3372549 ]],\n",
       "\n",
       "        [[0.5647059 ],\n",
       "         [0.4       ],\n",
       "         [0.5137255 ],\n",
       "         ...,\n",
       "         [0.27058825],\n",
       "         [0.28235295],\n",
       "         [0.34117648]],\n",
       "\n",
       "        [[0.5176471 ],\n",
       "         [0.49803922],\n",
       "         [0.54509807],\n",
       "         ...,\n",
       "         [0.29411766],\n",
       "         [0.34901962],\n",
       "         [0.30588236]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.5529412 ],\n",
       "         [0.36862746],\n",
       "         [0.3529412 ],\n",
       "         ...,\n",
       "         [0.27058825],\n",
       "         [0.41960785],\n",
       "         [0.59607846]],\n",
       "\n",
       "        [[0.42745098],\n",
       "         [0.35686275],\n",
       "         [0.47058824],\n",
       "         ...,\n",
       "         [0.36078432],\n",
       "         [0.4862745 ],\n",
       "         [0.6       ]],\n",
       "\n",
       "        [[0.3647059 ],\n",
       "         [0.39607844],\n",
       "         [0.5372549 ],\n",
       "         ...,\n",
       "         [0.3764706 ],\n",
       "         [0.5372549 ],\n",
       "         [0.4392157 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5058824 ],\n",
       "         [0.46666667],\n",
       "         [0.3372549 ],\n",
       "         ...,\n",
       "         [0.26666668],\n",
       "         [0.25490198],\n",
       "         [0.17254902]],\n",
       "\n",
       "        [[0.4862745 ],\n",
       "         [0.4509804 ],\n",
       "         [0.40784314],\n",
       "         ...,\n",
       "         [0.29803923],\n",
       "         [0.16078432],\n",
       "         [0.18039216]],\n",
       "\n",
       "        [[0.43529412],\n",
       "         [0.31764707],\n",
       "         [0.50980395],\n",
       "         ...,\n",
       "         [0.24705882],\n",
       "         [0.16078432],\n",
       "         [0.17254902]]],\n",
       "\n",
       "\n",
       "       [[[0.47058824],\n",
       "         [0.3882353 ],\n",
       "         [0.41960785],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.60784316],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        [[0.49411765],\n",
       "         [0.3882353 ],\n",
       "         [0.49803922],\n",
       "         ...,\n",
       "         [0.6156863 ],\n",
       "         [0.6117647 ],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        [[0.43529412],\n",
       "         [0.3882353 ],\n",
       "         [0.49411765],\n",
       "         ...,\n",
       "         [0.59607846],\n",
       "         [0.5882353 ],\n",
       "         [0.60784316]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3372549 ],\n",
       "         [0.44705883],\n",
       "         [0.43137255],\n",
       "         ...,\n",
       "         [0.48235294],\n",
       "         [0.5176471 ],\n",
       "         [0.4627451 ]],\n",
       "\n",
       "        [[0.2627451 ],\n",
       "         [0.39607844],\n",
       "         [0.32941177],\n",
       "         ...,\n",
       "         [0.4627451 ],\n",
       "         [0.47843137],\n",
       "         [0.4745098 ]],\n",
       "\n",
       "        [[0.3019608 ],\n",
       "         [0.3882353 ],\n",
       "         [0.41960785],\n",
       "         ...,\n",
       "         [0.5019608 ],\n",
       "         [0.5058824 ],\n",
       "         [0.49803922]]],\n",
       "\n",
       "\n",
       "       [[[0.57254905],\n",
       "         [0.5882353 ],\n",
       "         [0.6       ],\n",
       "         ...,\n",
       "         [0.6745098 ],\n",
       "         [0.67058825],\n",
       "         [0.65882355]],\n",
       "\n",
       "        [[0.5882353 ],\n",
       "         [0.6117647 ],\n",
       "         [0.6392157 ],\n",
       "         ...,\n",
       "         [0.627451  ],\n",
       "         [0.6431373 ],\n",
       "         [0.627451  ]],\n",
       "\n",
       "        [[0.6156863 ],\n",
       "         [0.6117647 ],\n",
       "         [0.60784316],\n",
       "         ...,\n",
       "         [0.63529414],\n",
       "         [0.627451  ],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3529412 ],\n",
       "         [0.33333334],\n",
       "         [0.37254903],\n",
       "         ...,\n",
       "         [0.3372549 ],\n",
       "         [0.40784314],\n",
       "         [0.43529412]],\n",
       "\n",
       "        [[0.4       ],\n",
       "         [0.4117647 ],\n",
       "         [0.4509804 ],\n",
       "         ...,\n",
       "         [0.41568628],\n",
       "         [0.4627451 ],\n",
       "         [0.5529412 ]],\n",
       "\n",
       "        [[0.38039216],\n",
       "         [0.39607844],\n",
       "         [0.40784314],\n",
       "         ...,\n",
       "         [0.4627451 ],\n",
       "         [0.43137255],\n",
       "         [0.4745098 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initalize()\n",
    "train_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time into 24 separate labels\n",
    "def conv_time_24(time):\n",
    "    ntime = 0\n",
    "    if time[1] > 30:\n",
    "        ntime = (time[0] + 0.5)\n",
    "    else:\n",
    "        ntime = time[0]\n",
    "    return ntime\n",
    "\n",
    "# Convert the time into 720 separate labels \n",
    "def conv_time_720(time):\n",
    "    return time[0]*60 + time[1]\n",
    "\n",
    "conv_time = conv_time_24\n",
    "while True:\n",
    "    initalize()\n",
    "    train_labels_converted = np.array([conv_time(time) for time in train_labels])\n",
    "    test_labels_converted = np.array([conv_time(time) for time in test_labels])\n",
    "    val_labels_converted = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    test_labels_encoded = encoder.fit_transform(test_labels_converted.reshape(-1))\n",
    "    train_labels_encoded = encoder.fit_transform(train_labels_converted.reshape(-1))\n",
    "    val_labels_encoded = encoder.fit_transform(val_labels_converted.reshape(-1))\n",
    "\n",
    "    OHencoder = OneHotEncoder(sparse_output=False)\n",
    "    train_labels_oh = OHencoder.fit_transform(train_labels_encoded.reshape(-1, 1))\n",
    "    val_labels_oh = OHencoder.fit_transform(val_labels_encoded.reshape(-1, 1))\n",
    "\n",
    "    # Check if all labels are present in the validation set, if not, reshuffle\n",
    "    try:\n",
    "        val_labels_oh = val_labels_oh.reshape((val_labels_oh.shape[0], 24))\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_error(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 75, 75, 1) (14400, 24)\n",
      "Epoch 1/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.0373 - loss: 3.1781 - val_accuracy: 0.0344 - val_loss: 3.1782\n",
      "Epoch 2/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0454 - loss: 3.1780 - val_accuracy: 0.0344 - val_loss: 3.1785\n",
      "Epoch 3/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0446 - loss: 3.1777 - val_accuracy: 0.0344 - val_loss: 3.1787\n",
      "Epoch 4/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0447 - loss: 3.1775 - val_accuracy: 0.0344 - val_loss: 3.1793\n",
      "Epoch 5/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.0487 - loss: 3.1767 - val_accuracy: 0.0406 - val_loss: 3.1775\n",
      "Epoch 6/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.0553 - loss: 3.1687 - val_accuracy: 0.0550 - val_loss: 3.1381\n",
      "Epoch 7/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.0706 - loss: 3.0941 - val_accuracy: 0.0733 - val_loss: 2.9684\n",
      "Epoch 8/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.0985 - loss: 2.8838 - val_accuracy: 0.0917 - val_loss: 2.7450\n",
      "Epoch 9/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.1198 - loss: 2.6995 - val_accuracy: 0.1122 - val_loss: 2.7849\n",
      "Epoch 10/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.1247 - loss: 2.6564 - val_accuracy: 0.1228 - val_loss: 2.5796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x73bce6419720>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (75, 75, 1)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(kernel_size=(5,5), strides = (2,2), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "# First layer - one neuron for each pixel\n",
    "model.add(keras.layers.Dense(units=5625, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=1125, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=24, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "print(train_imgs.shape, train_labels_oh.shape)\n",
    "\n",
    "\n",
    "model.fit(train_imgs, train_labels_oh, epochs=10, batch_size=256, validation_data=(val_imgs, val_labels_oh), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "4.277777777777778 %\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_imgs)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "\n",
    "results = encoder.inverse_transform(preds)\n",
    "accuracy = np.sum(results == test_labels_converted) / len(test_labels_converted)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#returning the common sense difference between two times\n",
    "def common_sense_error(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff_1 = K.abs(true - pred)\n",
    "    diff_2 = K.abs(true - (pred + 12))\n",
    "\n",
    "    return K.minimum(diff_1, diff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/29\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 197ms/step - common_sense_error: 3.7582 - loss: 37.7162"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[common_sense_error])\n\u001b[1;32m     26\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels_reg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initalize()\n",
    "\n",
    "def conv_time(time):\n",
    "    return round(time[0] + time[1]/60, 3)\n",
    "\n",
    "train_labels_reg = np.array([conv_time(time) for time in train_labels])\n",
    "test_labels_reg = np.array([conv_time(time) for time in test_labels])\n",
    "val_labels_reg = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), input_shape=(75, 75, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=5625, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[common_sense_error])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, train_labels_reg, epochs=40, batch_size = 512, validation_data = (val_imgs, val_labels_reg), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "0.1696604938271605 %\n"
     ]
    }
   ],
   "source": [
    "reg_preds = model.predict(test_imgs)\n",
    "# for i in range(len(reg_preds)):\n",
    "#     print(reg_preds[i], test_labels_reg[i])\n",
    "accuracy = np.mean(abs(reg_preds - test_labels_reg) < 0.01)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Headed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hours = train_labels[:, 0]\n",
    "train_minutes = train_labels[:, 1]\n",
    "\n",
    "val_hours = val_labels[:, 0]\n",
    "val_minutes = val_labels[:, 1]\n",
    "\n",
    "test_hours = test_labels[:, 0]\n",
    "test_minutes = test_labels[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - hour_accuracy: 0.0841 - hour_loss: 2.4895 - loss: 829.4688 - minute_loss: 826.4379 - minute_mae: 23.7829 - val_hour_accuracy: 0.0750 - val_hour_loss: 2.4848 - val_loss: 378.0327 - val_minute_loss: 376.9552 - val_minute_mae: 16.3143\n",
      "Epoch 2/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4860 - loss: 325.5216 - minute_loss: 323.0148 - minute_mae: 15.3859 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4858 - val_loss: 307.5529 - val_minute_loss: 305.6083 - val_minute_mae: 15.1643\n",
      "Epoch 3/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - hour_accuracy: 0.0877 - hour_loss: 2.4849 - loss: 302.8543 - minute_loss: 300.3875 - minute_mae: 14.9173 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 308.9561 - val_minute_loss: 307.1851 - val_minute_mae: 15.1973\n",
      "Epoch 4/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4850 - loss: 304.8977 - minute_loss: 302.4233 - minute_mae: 15.0504 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 307.5492 - val_minute_loss: 305.7039 - val_minute_mae: 15.1693\n",
      "Epoch 5/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - hour_accuracy: 0.0869 - hour_loss: 2.4849 - loss: 307.7698 - minute_loss: 305.3444 - minute_mae: 15.1228 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 310.3996 - val_minute_loss: 308.6734 - val_minute_mae: 15.2246\n",
      "Epoch 6/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0908 - hour_loss: 2.4848 - loss: 301.9066 - minute_loss: 299.4661 - minute_mae: 14.9081 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 312.4124 - val_minute_loss: 310.7340 - val_minute_mae: 15.2593\n",
      "Epoch 7/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0837 - hour_loss: 2.4849 - loss: 303.1441 - minute_loss: 300.7387 - minute_mae: 15.0162 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 307.2387 - val_minute_loss: 305.3678 - val_minute_mae: 15.1627\n",
      "Epoch 8/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0857 - hour_loss: 2.4848 - loss: 306.2672 - minute_loss: 303.8863 - minute_mae: 15.0918 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 307.0891 - val_minute_loss: 305.1805 - val_minute_mae: 15.1586\n",
      "Epoch 9/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0814 - hour_loss: 2.4846 - loss: 302.4586 - minute_loss: 299.9069 - minute_mae: 14.9688 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 308.9388 - val_minute_loss: 307.1643 - val_minute_mae: 15.1971\n",
      "Epoch 10/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0840 - hour_loss: 2.4849 - loss: 304.2012 - minute_loss: 301.6515 - minute_mae: 15.0303 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 307.1815 - val_minute_loss: 305.2278 - val_minute_mae: 15.1585\n",
      "Epoch 11/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0863 - hour_loss: 2.4849 - loss: 306.1272 - minute_loss: 303.6411 - minute_mae: 15.0212 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4857 - val_loss: 311.3133 - val_minute_loss: 309.1958 - val_minute_mae: 15.2168\n",
      "Epoch 12/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0818 - hour_loss: 2.4850 - loss: 305.1154 - minute_loss: 302.4674 - minute_mae: 15.0042 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4858 - val_loss: 307.5606 - val_minute_loss: 305.7234 - val_minute_mae: 15.1713\n",
      "Epoch 13/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - hour_accuracy: 0.0829 - hour_loss: 2.4849 - loss: 305.0788 - minute_loss: 302.5595 - minute_mae: 15.0200 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4858 - val_loss: 333.2896 - val_minute_loss: 331.8762 - val_minute_mae: 15.5989\n",
      "Epoch 14/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0874 - hour_loss: 2.4846 - loss: 311.1877 - minute_loss: 308.7715 - minute_mae: 15.1312 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 329.8145 - val_minute_loss: 328.3634 - val_minute_mae: 15.5437\n",
      "Epoch 15/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - hour_accuracy: 0.0842 - hour_loss: 2.4849 - loss: 310.5639 - minute_loss: 307.9851 - minute_mae: 15.1363 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 332.4966 - val_minute_loss: 331.0694 - val_minute_mae: 15.5858\n",
      "Epoch 16/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0797 - hour_loss: 2.4850 - loss: 308.0009 - minute_loss: 305.5806 - minute_mae: 15.0280 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 307.3638 - val_minute_loss: 305.5168 - val_minute_mae: 15.1676\n",
      "Epoch 17/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0846 - hour_loss: 2.4849 - loss: 301.4080 - minute_loss: 298.9267 - minute_mae: 14.9162 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 308.1247 - val_minute_loss: 306.3045 - val_minute_mae: 15.1820\n",
      "Epoch 18/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4849 - loss: 304.8048 - minute_loss: 302.2126 - minute_mae: 15.0063 - val_hour_accuracy: 0.0789 - val_hour_loss: 2.4859 - val_loss: 309.6288 - val_minute_loss: 307.4865 - val_minute_mae: 15.1872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x73bc775b10c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = keras.layers.Input(shape = (75,75,1))\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (5,5), strides= (2,2), activation = \"relu\")(inp)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (1,1),activation = \"relu\")(model)\n",
    "model = keras.layers.Flatten()(model)\n",
    "\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(model)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "d = keras.layers.Dropout(0.1)(d)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "\n",
    "hour = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "hour = keras.layers.Dense(128,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(64,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(32,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(16,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(12,activation= \"softmax\", name= \"hour\")(hour)\n",
    "\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(128,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(64,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(32,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(16,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(1, activation = \"softplus\", name = \"minute\")(minute)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=[hour, minute])\n",
    "optim = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=['sparse_categorical_crossentropy', 'mse'], optimizer=optim, metrics=['accuracy',\"mae\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, [train_hours, train_minutes], epochs=30, batch_size = 512, validation_data = (val_imgs, [val_hours, val_minutes]), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "1.363423353909465 %\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_imgs)\n",
    "hour_p = np.argmax(predictions[0], axis = 1)\n",
    "minutes_p = predictions[1]\n",
    "\n",
    "accuracy = np.mean(np.abs(hour_p - test_hours) < 1) * np.mean(np.abs(minutes_p - test_minutes) < 5)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Transformation using Periodic Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_time_train = (train_hours*60 + train_minutes) \n",
    "sine_time_test = (test_hours*60 + test_minutes)  \n",
    "sine_time_valid = (val_hours*60 + val_minutes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(719)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sine_time_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_angle_test = (sine_time_test/720)*2*np.pi\n",
    "sine_angle_train = (sine_time_train/720)*2*np.pi\n",
    "sine_angle_valid = (sine_time_valid/720)*2*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.1435 - mae: 0.2371 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 2/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7896e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 3/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 3.7661e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 4/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7713e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 5/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7717e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 6/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8013e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 7/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7782e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 8/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7938e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 9/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 3.7552e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 10/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8153e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 11/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8028e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x715e14082a10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sine Regression CNN\n",
    "\n",
    "sin_reg = keras.models.Sequential()\n",
    "sin_reg.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides = (2,2),input_shape=(75, 75, 1)))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "sin_reg.add(keras.layers.Flatten())\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "sin_reg.compile(loss='mse', optimizer= optimizer, metrics=['mae'])\n",
    "sin_reg.fit(train_imgs, sine_angle_train, epochs=45, batch_size = 512, validation_data = (val_imgs, sine_angle_valid), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "predictions = sin_reg.predict(test_imgs)\n",
    "\n",
    "def difference_func(pred,y):\n",
    "  pred = np.transpose(pred)\n",
    "  diff_one = np.maximum(pred,y) - np.minimum(pred,y)\n",
    "  diff_two = np.minimum(pred,y) + 1 - np.maximum(pred,y)\n",
    "  return np.minimum(diff_one,diff_two)\n",
    "\n",
    "result = difference_func(predictions,sine_angle_test).reshape(-1)\n",
    "\n",
    "accuracy = np.mean(result < np.pi/6)\n",
    "print(accuracy*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
