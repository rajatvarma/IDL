{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:54:35.719846: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-04 13:54:35.863060: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-04 13:54:38.945641: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-04 13:54:40.711384: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730724882.449223 3491538 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730724882.885913 3491538 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 13:54:46.889141: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting these as global variables so that they can be shuffled to ensure an even distribution- many times I wasn't getting all 24/720 labels in the validation set\n",
    "global imgs, train_imgs, val_imgs, test_imgs, train_labels, val_labels, test_labels, distributed\n",
    "\n",
    "images = np.load('75/images.npy')\n",
    "images = images.astype('float32')\n",
    "\n",
    "# Function that shuffles the images and labels into training, validation, and test sets\n",
    "def initalize():\n",
    "    indices = np.random.permutation(images.shape[0])\n",
    "    imgs = images[indices]\n",
    "\n",
    "    split_1 = int(18000*0.8)\n",
    "    split_2 = int(18000*0.9)\n",
    "\n",
    "    train_imgs = imgs[:split_1]\n",
    "    val_imgs = imgs[split_1:split_2]\n",
    "    test_imgs = imgs[split_2:]\n",
    "\n",
    "    # Normalizing the images\n",
    "    train_imgs = train_imgs / 255.0\n",
    "    test_imgs = test_imgs / 255.0\n",
    "    val_imgs = val_imgs / 255.0\n",
    "\n",
    "    labels = np.load('75/labels.npy')\n",
    "    labels = labels.astype('int32')\n",
    "    labels = labels[indices]\n",
    "    train_labels = labels[:split_1]\n",
    "    val_labels = labels[split_1:split_2]\n",
    "    test_labels = labels[split_2:]\n",
    "\n",
    "    train_imgs = train_imgs.reshape((train_imgs.shape[0], 75, 75, 1))\n",
    "    val_imgs = val_imgs.reshape((val_imgs.shape[0], 75, 75, 1))\n",
    "    test_imgs = test_imgs.reshape((test_imgs.shape[0], 75, 75, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time into 24 separate labels\n",
    "def conv_time_24(time):\n",
    "    ntime = 0\n",
    "    if time[1] > 30:\n",
    "        ntime = (time[0] + 0.5)\n",
    "    else:\n",
    "        ntime = time[0]\n",
    "    return ntime\n",
    "\n",
    "# Convert the time into 720 separate labels \n",
    "def conv_time_720(time):\n",
    "    return time[0]*60 + time[1]\n",
    "\n",
    "conv_time = conv_time_24\n",
    "while True:\n",
    "    initalize()\n",
    "    train_labels_converted = np.array([conv_time(time) for time in train_labels])\n",
    "    test_labels_converted = np.array([conv_time(time) for time in test_labels])\n",
    "    val_labels_converted = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    test_labels_encoded = encoder.fit_transform(test_labels_converted.reshape(-1))\n",
    "    train_labels_encoded = encoder.fit_transform(train_labels_converted.reshape(-1))\n",
    "    val_labels_encoded = encoder.fit_transform(val_labels_converted.reshape(-1))\n",
    "\n",
    "    OHencoder = OneHotEncoder(sparse_output=False)\n",
    "    train_labels_oh = OHencoder.fit_transform(train_labels_encoded.reshape(-1, 1))\n",
    "    val_labels_oh = OHencoder.fit_transform(val_labels_encoded.reshape(-1, 1))\n",
    "\n",
    "    # Check if all labels are present in the validation set, if not, reshuffle\n",
    "    try:\n",
    "        val_labels_oh = val_labels_oh.reshape((val_labels_oh.shape[0], 24))\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 75, 75, 1) (14400, 24)\n",
      "Epoch 1/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.0423 - loss: 3.1781 - val_accuracy: 0.0361 - val_loss: 3.1782\n",
      "Epoch 2/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.0428 - loss: 3.1779 - val_accuracy: 0.0356 - val_loss: 3.1784\n",
      "Epoch 3/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.0435 - loss: 3.1778 - val_accuracy: 0.0361 - val_loss: 3.1784\n",
      "Epoch 4/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.0442 - loss: 3.1779 - val_accuracy: 0.0361 - val_loss: 3.1787\n",
      "Epoch 5/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.0418 - loss: 3.1778 - val_accuracy: 0.0361 - val_loss: 3.1789\n",
      "Epoch 6/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.0432 - loss: 3.1776 - val_accuracy: 0.0361 - val_loss: 3.1788\n",
      "Epoch 7/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.0430 - loss: 3.1776 - val_accuracy: 0.0361 - val_loss: 3.1790\n",
      "Epoch 8/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.0424 - loss: 3.1780 - val_accuracy: 0.0361 - val_loss: 3.1796\n",
      "Epoch 9/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.0436 - loss: 3.1776 - val_accuracy: 0.0361 - val_loss: 3.1791\n",
      "Epoch 10/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.0454 - loss: 3.1773 - val_accuracy: 0.0361 - val_loss: 3.1791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f66bcd62530>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (75, 75, 1)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(kernel_size=(5,5), strides = (2,2), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=32))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "model.add(keras.layers.Conv2D(kernel_size=(3,3), activation=\"relu\", filters=64))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "# First layer - one neuron for each pixel\n",
    "model.add(keras.layers.Dense(units=5625, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=1125, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=24, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "print(train_imgs.shape, train_labels_oh.shape)\n",
    "\n",
    "\n",
    "model.fit(train_imgs, train_labels_oh, epochs=10, batch_size=256, validation_data=(val_imgs, val_labels_oh), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "5.111111111111112 %\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_imgs)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "\n",
    "results = encoder.inverse_transform(preds)\n",
    "accuracy = np.sum(results == test_labels_converted) / len(test_labels_converted)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#returning the common sense difference between two times\n",
    "def difference_func(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "    diff_1 = K.abs(true - pred)\n",
    "    diff_2 = K.abs(true - (pred + 12*60))\n",
    "\n",
    "    return K.minimum(diff_1, diff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4201388/Documents/Leiden/IDL/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - difference_func: 4.0812 - loss: 4.0826 - val_difference_func: 3.0844 - val_loss: 3.0844\n",
      "Epoch 2/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - difference_func: 3.0233 - loss: 3.0273 - val_difference_func: 3.0645 - val_loss: 3.0648\n",
      "Epoch 3/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - difference_func: 3.0027 - loss: 3.0040 - val_difference_func: 3.0845 - val_loss: 3.0849\n",
      "Epoch 4/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - difference_func: 3.0454 - loss: 3.0440 - val_difference_func: 3.0875 - val_loss: 3.0880\n",
      "Epoch 5/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - difference_func: 3.0463 - loss: 3.0454 - val_difference_func: 3.1041 - val_loss: 3.1049\n",
      "Epoch 6/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - difference_func: 2.9913 - loss: 2.9910 - val_difference_func: 3.2082 - val_loss: 3.2088\n",
      "Epoch 7/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - difference_func: 3.0908 - loss: 3.0882 - val_difference_func: 3.0730 - val_loss: 3.0736\n",
      "Epoch 8/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - difference_func: 3.0405 - loss: 3.0389 - val_difference_func: 3.1330 - val_loss: 3.1335\n",
      "Epoch 9/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - difference_func: 3.0292 - loss: 3.0286 - val_difference_func: 3.0808 - val_loss: 3.0816\n",
      "Epoch 10/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - difference_func: 3.0076 - loss: 3.0129 - val_difference_func: 3.0584 - val_loss: 3.0590\n",
      "Epoch 11/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - difference_func: 3.0059 - loss: 3.0048 - val_difference_func: 3.1033 - val_loss: 3.1042\n",
      "Epoch 12/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - difference_func: 3.0265 - loss: 3.0253 - val_difference_func: 3.1362 - val_loss: 3.1368\n",
      "Epoch 13/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - difference_func: 3.0223 - loss: 3.0226 - val_difference_func: 3.0736 - val_loss: 3.0743\n",
      "Epoch 14/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - difference_func: 3.0488 - loss: 3.0475 - val_difference_func: 3.2058 - val_loss: 3.2066\n",
      "Epoch 15/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - difference_func: 3.0213 - loss: 3.0220 - val_difference_func: 3.0843 - val_loss: 3.0851\n",
      "Epoch 16/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - difference_func: 3.0176 - loss: 3.0221 - val_difference_func: 3.1108 - val_loss: 3.1120\n",
      "Epoch 17/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - difference_func: 3.0270 - loss: 3.0279 - val_difference_func: 3.0737 - val_loss: 3.0745\n",
      "Epoch 18/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - difference_func: 3.0201 - loss: 3.0213 - val_difference_func: 3.0772 - val_loss: 3.0781\n",
      "Epoch 19/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - difference_func: 3.0580 - loss: 3.0579 - val_difference_func: 3.0721 - val_loss: 3.0727\n",
      "Epoch 20/40\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - difference_func: 3.0097 - loss: 3.0131 - val_difference_func: 3.0595 - val_loss: 3.0604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f66cb013550>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initalize()\n",
    "\n",
    "def conv_time(time):\n",
    "    return round(time[0] + time[1]/60, 3)\n",
    "\n",
    "train_labels_reg = np.array([conv_time(time) for time in train_labels])\n",
    "test_labels_reg = np.array([conv_time(time) for time in test_labels])\n",
    "val_labels_reg = np.array([conv_time(time) for time in val_labels])\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides=(2,2),input_shape=(75, 75, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "model.compile(loss=difference_func, optimizer=\"adam\", metrics=[difference_func])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, train_labels_reg, epochs=40, batch_size = 512, validation_data = (val_imgs, val_labels_reg), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[5.71604] 8.033\n",
      "[5.6474957] 6.817\n",
      "[5.639689] 10.383\n",
      "[5.6338997] 9.133\n",
      "[5.6161847] 5.233\n",
      "[5.702291] 5.017\n",
      "[5.6282105] 2.45\n",
      "[5.587209] 4.017\n",
      "[5.6159406] 6.917\n",
      "[5.7096915] 11.133\n",
      "[5.6929803] 1.6\n",
      "[5.646908] 8.067\n",
      "[5.61418] 11.1\n",
      "[5.6245203] 3.05\n",
      "[5.650396] 3.533\n",
      "[5.6066213] 0.167\n",
      "[5.6142445] 0.167\n",
      "[5.7441306] 1.783\n",
      "[5.6395707] 0.2\n",
      "[5.6673965] 6.65\n",
      "[5.6935906] 7.383\n",
      "[5.68261] 6.633\n",
      "[5.707229] 0.783\n",
      "[5.7158217] 10.983\n",
      "[5.623289] 5.017\n",
      "[5.6584697] 2.933\n",
      "[5.7342534] 4.483\n",
      "[5.560532] 1.033\n",
      "[5.6740646] 8.5\n",
      "[5.671574] 7.267\n",
      "[5.661425] 2.217\n",
      "[5.6307955] 7.45\n",
      "[5.6232233] 9.883\n",
      "[5.6495075] 4.167\n",
      "[5.6040087] 9.483\n",
      "[5.6861367] 1.833\n",
      "[5.632621] 2.467\n",
      "[5.611585] 4.517\n",
      "[5.69044] 8.333\n",
      "[5.6951957] 7.25\n",
      "[5.7013354] 3.25\n",
      "[5.6980634] 0.083\n",
      "[5.6691236] 4.45\n",
      "[5.638679] 6.733\n",
      "[5.6636944] 10.833\n",
      "[5.680578] 4.317\n",
      "[5.706926] 6.567\n",
      "[5.6353083] 7.183\n",
      "[5.5832253] 0.933\n",
      "[5.617577] 1.667\n",
      "[5.6277084] 6.783\n",
      "[5.684453] 9.1\n",
      "[5.631188] 7.033\n",
      "[5.6630063] 5.333\n",
      "[5.623227] 7.583\n",
      "[5.5570865] 6.983\n",
      "[5.630659] 2.017\n",
      "[5.658069] 3.55\n",
      "[5.6966677] 8.883\n",
      "[5.605014] 7.467\n",
      "[5.6464868] 6.533\n",
      "[5.6979737] 1.617\n",
      "[5.674505] 2.683\n",
      "[5.696318] 3.033\n",
      "[5.665292] 4.133\n",
      "[5.650361] 2.4\n",
      "[5.618859] 2.717\n",
      "[5.722312] 10.783\n",
      "[5.6834207] 5.183\n",
      "[5.6061335] 3.3\n",
      "[5.6658497] 5.783\n",
      "[5.7130384] 1.917\n",
      "[5.639707] 8.217\n",
      "[5.6470275] 10.1\n",
      "[5.6524625] 0.667\n",
      "[5.6634398] 8.233\n",
      "[5.6084466] 10.95\n",
      "[5.6246386] 5.933\n",
      "[5.695993] 5.95\n",
      "[5.6882734] 1.95\n",
      "[5.7165213] 5.783\n",
      "[5.69112] 4.5\n",
      "[5.6112924] 10.383\n",
      "[5.6945243] 2.567\n",
      "[5.6492443] 6.283\n",
      "[5.630105] 7.467\n",
      "[5.7222877] 10.133\n",
      "[5.6842694] 3.267\n",
      "[5.6646] 6.9\n",
      "[5.7234507] 4.083\n",
      "[5.620048] 3.95\n",
      "[5.638082] 6.333\n",
      "[5.6172194] 4.133\n",
      "[5.636083] 5.65\n",
      "[5.6320214] 4.233\n",
      "[5.672758] 9.45\n",
      "[5.60524] 11.25\n",
      "[5.730999] 10.433\n",
      "[5.668108] 7.683\n",
      "[5.708802] 3.183\n",
      "[5.6328807] 5.15\n",
      "[5.6330338] 9.467\n",
      "[5.6659555] 11.983\n",
      "[5.709273] 11.7\n",
      "[5.645242] 2.067\n",
      "[5.6653833] 6.4\n",
      "[5.656142] 8.067\n",
      "[5.6404314] 9.683\n",
      "[5.697857] 6.9\n",
      "[5.59699] 6.1\n",
      "[5.6620207] 1.45\n",
      "[5.6219425] 3.9\n",
      "[5.62879] 8.25\n",
      "[5.665248] 9.6\n",
      "[5.6124716] 5.8\n",
      "[5.6889195] 8.033\n",
      "[5.655948] 1.95\n",
      "[5.738776] 6.55\n",
      "[5.638819] 2.917\n",
      "[5.6689186] 7.817\n",
      "[5.6287994] 6.167\n",
      "[5.706232] 9.75\n",
      "[5.632277] 9.05\n",
      "[5.622073] 3.75\n",
      "[5.6205893] 4.9\n",
      "[5.6243854] 8.0\n",
      "[5.6643724] 10.717\n",
      "[5.674391] 11.2\n",
      "[5.7336717] 5.483\n",
      "[5.713893] 5.8\n",
      "[5.652362] 6.783\n",
      "[5.6915536] 8.2\n",
      "[5.6787663] 2.567\n",
      "[5.6982536] 4.833\n",
      "[5.648116] 6.5\n",
      "[5.630329] 5.5\n",
      "[5.6302114] 3.533\n",
      "[5.6201873] 5.467\n",
      "[5.677538] 6.667\n",
      "[5.6803393] 4.833\n",
      "[5.6014156] 4.467\n",
      "[5.634167] 8.333\n",
      "[5.6624875] 1.967\n",
      "[5.7424216] 8.15\n",
      "[5.6885123] 7.917\n",
      "[5.6984653] 2.95\n",
      "[5.560408] 5.217\n",
      "[5.5994673] 8.933\n",
      "[5.6909623] 2.517\n",
      "[5.6639156] 3.767\n",
      "[5.65508] 3.817\n",
      "[5.6875625] 5.15\n",
      "[5.659292] 9.6\n",
      "[5.650399] 0.367\n",
      "[5.676521] 5.967\n",
      "[5.6916547] 11.217\n",
      "[5.6458564] 10.467\n",
      "[5.6334863] 11.45\n",
      "[5.6452117] 7.917\n",
      "[5.6502805] 6.133\n",
      "[5.6688747] 4.717\n",
      "[5.657233] 5.317\n",
      "[5.622259] 3.933\n",
      "[5.6321664] 10.283\n",
      "[5.6456714] 8.217\n",
      "[5.6954308] 7.417\n",
      "[5.6734443] 2.95\n",
      "[5.598732] 2.4\n",
      "[5.638143] 1.733\n",
      "[5.654979] 7.933\n",
      "[5.596684] 6.333\n",
      "[5.644254] 4.067\n",
      "[5.6557913] 0.367\n",
      "[5.6397243] 2.25\n",
      "[5.6018047] 0.033\n",
      "[5.7065167] 2.05\n",
      "[5.670579] 10.083\n",
      "[5.635038] 4.933\n",
      "[5.7120004] 5.85\n",
      "[5.63859] 7.833\n",
      "[5.686698] 8.85\n",
      "[5.656942] 2.133\n",
      "[5.687634] 11.75\n",
      "[5.7009406] 9.083\n",
      "[5.628422] 0.75\n",
      "[5.6869063] 0.033\n",
      "[5.6544003] 3.317\n",
      "[5.5685515] 2.583\n",
      "[5.5988755] 1.417\n",
      "[5.6882167] 0.483\n",
      "[5.640242] 10.55\n",
      "[5.638681] 1.25\n",
      "[5.695983] 2.083\n",
      "[5.561034] 5.517\n",
      "[5.685683] 1.95\n",
      "[5.6373916] 5.1\n",
      "[5.7008276] 6.383\n",
      "[5.708795] 6.433\n",
      "[5.642947] 3.083\n",
      "[5.6296306] 5.967\n",
      "[5.687523] 1.683\n",
      "[5.687135] 9.85\n",
      "[5.6610737] 0.683\n",
      "[5.6990027] 2.883\n",
      "[5.6005764] 4.333\n",
      "[5.690336] 1.917\n",
      "[5.6843095] 1.733\n",
      "[5.61846] 2.45\n",
      "[5.633995] 0.667\n",
      "[5.619005] 2.267\n",
      "[5.6147075] 9.183\n",
      "[5.6863613] 8.517\n",
      "[5.6678095] 5.717\n",
      "[5.6651025] 6.383\n",
      "[5.642183] 5.333\n",
      "[5.6242924] 1.8\n",
      "[5.6920624] 9.517\n",
      "[5.6958675] 6.317\n",
      "[5.6328077] 8.55\n",
      "[5.6642694] 11.4\n",
      "[5.7107434] 8.6\n",
      "[5.6389203] 10.967\n",
      "[5.5298343] 6.733\n",
      "[5.676895] 7.667\n",
      "[5.6368465] 9.6\n",
      "[5.6380496] 10.15\n",
      "[5.6939883] 0.85\n",
      "[5.6227026] 3.1\n",
      "[5.6573873] 6.133\n",
      "[5.629488] 3.483\n",
      "[5.7321196] 5.867\n",
      "[5.67289] 0.617\n",
      "[5.679225] 3.283\n",
      "[5.6435094] 9.433\n",
      "[5.6798263] 11.083\n",
      "[5.6016755] 5.933\n",
      "[5.696466] 6.4\n",
      "[5.653196] 1.783\n",
      "[5.6821985] 0.55\n",
      "[5.6596055] 9.683\n",
      "[5.614727] 6.317\n",
      "[5.685434] 10.917\n",
      "[5.644357] 2.833\n",
      "[5.6700854] 10.7\n",
      "[5.6814375] 1.117\n",
      "[5.630864] 3.167\n",
      "[5.676217] 10.517\n",
      "[5.656606] 5.85\n",
      "[5.642565] 5.6\n",
      "[5.650824] 2.65\n",
      "[5.663347] 11.95\n",
      "[5.634861] 8.883\n",
      "[5.6511564] 0.25\n",
      "[5.699528] 5.667\n",
      "[5.678055] 9.0\n",
      "[5.6629457] 1.717\n",
      "[5.6471376] 4.183\n",
      "[5.635578] 0.5\n",
      "[5.7260766] 4.517\n",
      "[5.668143] 9.3\n",
      "[5.6379476] 5.9\n",
      "[5.7236447] 1.883\n",
      "[5.62155] 10.317\n",
      "[5.636875] 11.117\n",
      "[5.6894097] 8.283\n",
      "[5.654716] 5.95\n",
      "[5.624273] 5.3\n",
      "[5.647754] 1.333\n",
      "[5.6661596] 10.217\n",
      "[5.639456] 0.283\n",
      "[5.6694765] 4.717\n",
      "[5.6213007] 3.9\n",
      "[5.6799197] 8.05\n",
      "[5.67932] 6.483\n",
      "[5.669077] 11.933\n",
      "[5.650454] 7.783\n",
      "[5.6286063] 9.65\n",
      "[5.6757355] 6.883\n",
      "[5.7345824] 2.767\n",
      "[5.6505637] 4.7\n",
      "[5.5776825] 7.967\n",
      "[5.6328807] 0.017\n",
      "[5.676028] 10.3\n",
      "[5.660528] 2.467\n",
      "[5.6829743] 10.0\n",
      "[5.6269436] 5.217\n",
      "[5.6664324] 2.217\n",
      "[5.63701] 7.317\n",
      "[5.666519] 0.667\n",
      "[5.6429896] 3.417\n",
      "[5.6033897] 4.917\n",
      "[5.6221333] 1.083\n",
      "[5.7048945] 4.633\n",
      "[5.727708] 2.367\n",
      "[5.635107] 3.217\n",
      "[5.638475] 8.983\n",
      "[5.6018457] 6.7\n",
      "[5.6851354] 9.117\n",
      "[5.6765146] 11.2\n",
      "[5.632738] 0.383\n",
      "[5.67644] 10.317\n",
      "[5.6617627] 8.267\n",
      "[5.640475] 10.15\n",
      "[5.6522007] 11.117\n",
      "[5.6684995] 5.167\n",
      "[5.6313925] 4.283\n",
      "[5.643347] 7.417\n",
      "[5.6310463] 2.483\n",
      "[5.623833] 1.217\n",
      "[5.6251087] 6.783\n",
      "[5.651919] 9.9\n",
      "[5.7091975] 8.783\n",
      "[5.69727] 2.817\n",
      "[5.626369] 0.683\n",
      "[5.705064] 9.9\n",
      "[5.675415] 11.6\n",
      "[5.6985703] 4.65\n",
      "[5.5984592] 3.25\n",
      "[5.685524] 9.5\n",
      "[5.690297] 6.25\n",
      "[5.6454234] 9.583\n",
      "[5.627469] 2.8\n",
      "[5.6202803] 11.15\n",
      "[5.659303] 1.183\n",
      "[5.623066] 9.6\n",
      "[5.69587] 2.1\n",
      "[5.5903697] 6.383\n",
      "[5.642313] 4.717\n",
      "[5.6212583] 9.917\n",
      "[5.6957026] 3.6\n",
      "[5.628192] 4.8\n",
      "[5.6773863] 10.483\n",
      "[5.666934] 6.717\n",
      "[5.6900144] 9.583\n",
      "[5.6238065] 0.833\n",
      "[5.679256] 10.55\n",
      "[5.702916] 3.45\n",
      "[5.7211776] 3.517\n",
      "[5.7423453] 0.383\n",
      "[5.6272] 7.55\n",
      "[5.6812167] 1.283\n",
      "[5.645219] 7.95\n",
      "[5.675973] 0.683\n",
      "[5.6049857] 11.467\n",
      "[5.6623554] 5.617\n",
      "[5.645391] 3.433\n",
      "[5.6413007] 0.0\n",
      "[5.586845] 9.767\n",
      "[5.625302] 2.517\n",
      "[5.698534] 5.517\n",
      "[5.722122] 2.7\n",
      "[5.630006] 9.6\n",
      "[5.609662] 0.9\n",
      "[5.6838274] 4.75\n",
      "[5.7171254] 7.5\n",
      "[5.62433] 5.55\n",
      "[5.664389] 3.533\n",
      "[5.6722674] 3.967\n",
      "[5.6449347] 3.617\n",
      "[5.6842175] 2.983\n",
      "[5.7072415] 7.35\n",
      "[5.670537] 5.083\n",
      "[5.6805744] 7.0\n",
      "[5.6480293] 11.9\n",
      "[5.6012697] 0.55\n",
      "[5.612109] 1.283\n",
      "[5.6194277] 6.667\n",
      "[5.6666718] 1.133\n",
      "[5.726413] 0.4\n",
      "[5.704192] 4.633\n",
      "[5.620825] 0.95\n",
      "[5.677382] 3.35\n",
      "[5.7182293] 0.267\n",
      "[5.665618] 0.933\n",
      "[5.533693] 9.233\n",
      "[5.622387] 9.117\n",
      "[5.660604] 10.317\n",
      "[5.6071687] 5.833\n",
      "[5.6428046] 3.55\n",
      "[5.672513] 11.9\n",
      "[5.6820555] 4.383\n",
      "[5.676421] 7.9\n",
      "[5.704196] 5.5\n",
      "[5.659363] 1.7\n",
      "[5.5810947] 3.233\n",
      "[5.6728673] 8.783\n",
      "[5.6945386] 5.817\n",
      "[5.703376] 7.817\n",
      "[5.6954165] 11.1\n",
      "[5.663643] 2.55\n",
      "[5.581851] 0.317\n",
      "[5.6496615] 10.05\n",
      "[5.62431] 4.417\n",
      "[5.6162753] 6.95\n",
      "[5.673637] 6.217\n",
      "[5.6732183] 5.5\n",
      "[5.669278] 4.767\n",
      "[5.720304] 1.05\n",
      "[5.6200533] 6.917\n",
      "[5.698969] 11.0\n",
      "[5.5478263] 0.217\n",
      "[5.6458716] 8.25\n",
      "[5.6416526] 4.017\n",
      "[5.6375914] 2.567\n",
      "[5.651074] 8.033\n",
      "[5.6454353] 1.133\n",
      "[5.710154] 6.333\n",
      "[5.612864] 0.6\n",
      "[5.613087] 6.417\n",
      "[5.6801763] 7.267\n",
      "[5.642134] 1.55\n",
      "[5.676342] 2.283\n",
      "[5.706442] 5.5\n",
      "[5.717037] 9.617\n",
      "[5.7175975] 1.6\n",
      "[5.657702] 6.883\n",
      "[5.6423426] 1.783\n",
      "[5.6253858] 0.467\n",
      "[5.706663] 6.683\n",
      "[5.6975513] 11.8\n",
      "[5.64025] 6.0\n",
      "[5.569324] 11.567\n",
      "[5.653923] 3.967\n",
      "[5.657024] 7.0\n",
      "[5.6875296] 3.717\n",
      "[5.5924835] 2.433\n",
      "[5.6872425] 4.867\n",
      "[5.697758] 2.1\n",
      "[5.6606812] 0.017\n",
      "[5.6223297] 0.617\n",
      "[5.6824393] 8.183\n",
      "[5.6371436] 0.483\n",
      "[5.6307216] 5.117\n",
      "[5.6629577] 3.967\n",
      "[5.622042] 10.717\n",
      "[5.641586] 8.517\n",
      "[5.605158] 4.883\n",
      "[5.6532493] 9.5\n",
      "[5.5753284] 2.033\n",
      "[5.7097955] 8.817\n",
      "[5.644851] 1.483\n",
      "[5.669031] 3.0\n",
      "[5.7004523] 1.85\n",
      "[5.718105] 0.867\n",
      "[5.6594043] 2.967\n",
      "[5.6634917] 9.65\n",
      "[5.6564155] 8.4\n",
      "[5.6574287] 10.067\n",
      "[5.619086] 8.25\n",
      "[5.581373] 2.417\n",
      "[5.6665444] 1.833\n",
      "[5.575629] 4.75\n",
      "[5.535959] 6.1\n",
      "[5.5818553] 11.95\n",
      "[5.717921] 7.433\n",
      "[5.6020904] 0.633\n",
      "[5.634544] 6.883\n",
      "[5.5787935] 2.217\n",
      "[5.643973] 5.767\n",
      "[5.71659] 3.317\n",
      "[5.632094] 9.167\n",
      "[5.6516314] 6.317\n",
      "[5.6578717] 11.55\n",
      "[5.643684] 10.183\n",
      "[5.619298] 4.95\n",
      "[5.673401] 4.217\n",
      "[5.657972] 11.683\n",
      "[5.6016707] 8.783\n",
      "[5.644078] 8.017\n",
      "[5.6158886] 9.017\n",
      "[5.621434] 3.917\n",
      "[5.5969033] 8.65\n",
      "[5.6352835] 10.95\n",
      "[5.6297455] 10.65\n",
      "[5.6302786] 4.333\n",
      "[5.6982174] 4.95\n",
      "[5.6723213] 10.917\n",
      "[5.6371517] 2.367\n",
      "[5.7037635] 0.283\n",
      "[5.653774] 2.25\n",
      "[5.638437] 5.317\n",
      "[5.719346] 6.583\n",
      "[5.622173] 1.517\n",
      "[5.6823072] 5.233\n",
      "[5.647232] 7.283\n",
      "[5.6272426] 8.85\n",
      "[5.6539207] 5.35\n",
      "[5.64528] 7.467\n",
      "[5.611725] 8.95\n",
      "[5.7021265] 6.5\n",
      "[5.638167] 10.85\n",
      "[5.6886706] 11.1\n",
      "[5.684407] 7.3\n",
      "[5.6230354] 1.2\n",
      "[5.660795] 4.333\n",
      "[5.615862] 4.95\n",
      "[5.670328] 4.567\n",
      "[5.64163] 2.517\n",
      "[5.689747] 5.933\n",
      "[5.660297] 5.183\n",
      "[5.6365266] 5.4\n",
      "[5.6824] 7.267\n",
      "[5.612283] 11.5\n",
      "[5.6624293] 2.967\n",
      "[5.660091] 11.567\n",
      "[5.7192645] 8.917\n",
      "[5.632765] 1.517\n",
      "[5.66352] 2.633\n",
      "[5.6704955] 0.767\n",
      "[5.6597614] 7.017\n",
      "[5.6531553] 8.95\n",
      "[5.6576366] 1.45\n",
      "[5.6726904] 4.45\n",
      "[5.6411657] 10.033\n",
      "[5.6610727] 3.1\n",
      "[5.6821747] 10.967\n",
      "[5.610574] 5.167\n",
      "[5.6931853] 3.733\n",
      "[5.6959486] 11.717\n",
      "[5.662319] 3.133\n",
      "[5.699173] 1.317\n",
      "[5.7175446] 2.933\n",
      "[5.5998707] 4.8\n",
      "[5.662633] 0.517\n",
      "[5.578604] 2.667\n",
      "[5.64241] 9.383\n",
      "[5.6653323] 1.283\n",
      "[5.6207023] 3.95\n",
      "[5.640401] 0.283\n",
      "[5.6871715] 3.9\n",
      "[5.6114573] 4.417\n",
      "[5.650466] 7.833\n",
      "[5.6890564] 3.3\n",
      "[5.68559] 7.2\n",
      "[5.6226244] 2.4\n",
      "[5.6442256] 1.867\n",
      "[5.5568566] 6.15\n",
      "[5.671827] 0.367\n",
      "[5.6433954] 10.633\n",
      "[5.658602] 4.55\n",
      "[5.7018213] 0.233\n",
      "[5.6927238] 2.7\n",
      "[5.6575594] 11.117\n",
      "[5.631722] 4.6\n",
      "[5.654991] 11.767\n",
      "[5.63679] 4.267\n",
      "[5.662655] 4.117\n",
      "[5.6970143] 8.367\n",
      "[5.608021] 6.05\n",
      "[5.548751] 7.2\n",
      "[5.694877] 9.833\n",
      "[5.6633453] 6.267\n",
      "[5.6703877] 5.517\n",
      "[5.6652985] 4.917\n",
      "[5.684193] 3.65\n",
      "[5.5924044] 1.6\n",
      "[5.654906] 0.217\n",
      "[5.700556] 0.533\n",
      "[5.589656] 8.117\n",
      "[5.6644692] 9.433\n",
      "[5.71597] 5.183\n",
      "[5.6118007] 5.5\n",
      "[5.6493306] 7.367\n",
      "[5.6835985] 6.283\n",
      "[5.608281] 3.333\n",
      "[5.6115713] 4.983\n",
      "[5.6968756] 3.817\n",
      "[5.7081966] 4.083\n",
      "[5.6458917] 8.667\n",
      "[5.647026] 5.5\n",
      "[5.659027] 11.65\n",
      "[5.6661806] 6.6\n",
      "[5.625309] 7.833\n",
      "[5.6366243] 6.583\n",
      "[5.6965256] 6.933\n",
      "[5.6390076] 4.517\n",
      "[5.677555] 1.15\n",
      "[5.634893] 1.2\n",
      "[5.627833] 6.85\n",
      "[5.6677523] 6.4\n",
      "[5.6319585] 7.95\n",
      "[5.5094624] 1.7\n",
      "[5.686644] 4.867\n",
      "[5.665387] 8.4\n",
      "[5.741469] 11.233\n",
      "[5.6199737] 2.433\n",
      "[5.7032733] 9.017\n",
      "[5.629196] 1.217\n",
      "[5.634253] 4.3\n",
      "[5.6395493] 11.933\n",
      "[5.645177] 9.4\n",
      "[5.6160383] 4.917\n",
      "[5.718643] 6.583\n",
      "[5.729966] 11.467\n",
      "[5.6632075] 1.417\n",
      "[5.670666] 8.333\n",
      "[5.694472] 3.4\n",
      "[5.6921363] 3.3\n",
      "[5.628214] 7.183\n",
      "[5.661278] 4.55\n",
      "[5.6218276] 5.633\n",
      "[5.694252] 9.483\n",
      "[5.6934443] 0.067\n",
      "[5.636316] 3.15\n",
      "[5.617586] 10.367\n",
      "[5.612827] 0.217\n",
      "[5.6241207] 6.9\n",
      "[5.6945043] 8.083\n",
      "[5.688523] 2.967\n",
      "[5.660583] 2.75\n",
      "[5.6231976] 5.5\n",
      "[5.6855135] 11.867\n",
      "[5.636914] 5.917\n",
      "[5.649147] 6.067\n",
      "[5.683343] 11.283\n",
      "[5.6408367] 6.017\n",
      "[5.6247106] 8.35\n",
      "[5.6362333] 5.6\n",
      "[5.64324] 2.95\n",
      "[5.6276226] 10.233\n",
      "[5.6581993] 2.783\n",
      "[5.654565] 11.617\n",
      "[5.658627] 0.817\n",
      "[5.654746] 6.217\n",
      "[5.664029] 9.333\n",
      "[5.676408] 6.967\n",
      "[5.6093397] 5.0\n",
      "[5.698934] 6.3\n",
      "[5.6830873] 5.6\n",
      "[5.6278296] 6.817\n",
      "[5.609408] 0.267\n",
      "[5.6268034] 7.917\n",
      "[5.6824975] 10.917\n",
      "[5.664353] 6.717\n",
      "[5.6319346] 7.833\n",
      "[5.671781] 6.55\n",
      "[5.644895] 7.633\n",
      "[5.6934223] 1.95\n",
      "[5.6470766] 5.6\n",
      "[5.6876874] 5.35\n",
      "[5.695908] 4.967\n",
      "[5.6019845] 10.9\n",
      "[5.6612487] 8.8\n",
      "[5.7015705] 5.983\n",
      "[5.6658072] 0.6\n",
      "[5.6449876] 10.65\n",
      "[5.6452885] 6.95\n",
      "[5.7090783] 11.583\n",
      "[5.7139096] 10.567\n",
      "[5.620512] 4.283\n",
      "[5.604255] 11.45\n",
      "[5.7062054] 3.233\n",
      "[5.680266] 10.533\n",
      "[5.6762114] 9.117\n",
      "[5.6756644] 8.033\n",
      "[5.637336] 8.917\n",
      "[5.702377] 6.517\n",
      "[5.6607475] 11.45\n",
      "[5.687585] 10.217\n",
      "[5.657608] 0.633\n",
      "[5.6971607] 4.8\n",
      "[5.7033873] 8.483\n",
      "[5.600603] 7.417\n",
      "[5.678765] 5.95\n",
      "[5.6590815] 6.167\n",
      "[5.6781077] 0.433\n",
      "[5.643741] 9.017\n",
      "[5.695535] 0.283\n",
      "[5.7105985] 5.167\n",
      "[5.625982] 10.233\n",
      "[5.6603036] 11.067\n",
      "[5.690773] 5.083\n",
      "[5.6165185] 3.517\n",
      "[5.6166515] 4.8\n",
      "[5.65001] 4.85\n",
      "[5.64649] 1.65\n",
      "[5.6487045] 4.083\n",
      "[5.696439] 5.133\n",
      "[5.626261] 11.833\n",
      "[5.649848] 3.867\n",
      "[5.6755705] 6.75\n",
      "[5.6781797] 5.167\n",
      "[5.738814] 7.6\n",
      "[5.6302814] 9.4\n",
      "[5.6739044] 4.6\n",
      "[5.6921678] 10.45\n",
      "[5.6267605] 1.55\n",
      "[5.5458484] 1.317\n",
      "[5.6066217] 9.15\n",
      "[5.6729226] 2.383\n",
      "[5.702924] 8.7\n",
      "[5.580724] 7.533\n",
      "[5.6526628] 2.583\n",
      "[5.6380377] 8.017\n",
      "[5.6461816] 9.817\n",
      "[5.641673] 4.75\n",
      "[5.639182] 1.1\n",
      "[5.670764] 8.167\n",
      "[5.6589947] 8.1\n",
      "[5.638479] 0.633\n",
      "[5.6494827] 2.833\n",
      "[5.6423335] 11.6\n",
      "[5.698519] 10.333\n",
      "[5.6489697] 0.183\n",
      "[5.6424837] 2.083\n",
      "[5.676674] 1.9\n",
      "[5.634377] 3.05\n",
      "[5.641036] 4.933\n",
      "[5.6300673] 8.7\n",
      "[5.649184] 3.45\n",
      "[5.7094126] 3.767\n",
      "[5.6014028] 2.433\n",
      "[5.680049] 3.033\n",
      "[5.6584663] 8.317\n",
      "[5.6847286] 11.167\n",
      "[5.650295] 10.317\n",
      "[5.6862636] 9.817\n",
      "[5.625197] 10.567\n",
      "[5.6811085] 6.7\n",
      "[5.6607184] 3.283\n",
      "[5.6343603] 1.067\n",
      "[5.701179] 5.8\n",
      "[5.6332765] 8.2\n",
      "[5.7227116] 10.2\n",
      "[5.6152563] 0.95\n",
      "[5.7237024] 11.1\n",
      "[5.689675] 0.867\n",
      "[5.668965] 1.0\n",
      "[5.5577393] 3.467\n",
      "[5.660408] 11.783\n",
      "[5.6858516] 3.8\n",
      "[5.603434] 11.217\n",
      "[5.662445] 2.483\n",
      "[5.6897273] 1.267\n",
      "[5.7189374] 0.05\n",
      "[5.590623] 8.733\n",
      "[5.580458] 8.6\n",
      "[5.530154] 1.717\n",
      "[5.604924] 2.233\n",
      "[5.6745806] 6.267\n",
      "[5.669467] 7.433\n",
      "[5.706248] 5.683\n",
      "[5.61906] 5.6\n",
      "[5.679938] 1.183\n",
      "[5.627899] 11.117\n",
      "[5.6629496] 11.35\n",
      "[5.630656] 10.8\n",
      "[5.608406] 10.017\n",
      "[5.701083] 4.467\n",
      "[5.673296] 11.217\n",
      "[5.6754622] 2.217\n",
      "[5.6401043] 10.217\n",
      "[5.697422] 6.033\n",
      "[5.694932] 6.333\n",
      "[5.6558537] 1.283\n",
      "[5.6484] 7.383\n",
      "[5.690835] 8.917\n",
      "[5.740348] 7.5\n",
      "[5.6534705] 8.183\n",
      "[5.714261] 11.517\n",
      "[5.7308574] 0.8\n",
      "[5.6561027] 2.067\n",
      "[5.621621] 0.433\n",
      "[5.666393] 10.933\n",
      "[5.647174] 5.033\n",
      "[5.666573] 2.467\n",
      "[5.6998534] 6.717\n",
      "[5.6676273] 7.383\n",
      "[5.7139754] 11.65\n",
      "[5.673165] 9.383\n",
      "[5.696508] 10.0\n",
      "[5.669303] 7.833\n",
      "[5.660215] 11.267\n",
      "[5.661415] 11.85\n",
      "[5.646115] 11.983\n",
      "[5.642555] 11.65\n",
      "[5.6412582] 3.15\n",
      "[5.647134] 2.183\n",
      "[5.6569643] 2.25\n",
      "[5.617295] 2.1\n",
      "[5.6284366] 10.033\n",
      "[5.616519] 6.117\n",
      "[5.709755] 0.067\n",
      "[5.6574035] 10.033\n",
      "[5.600638] 7.883\n",
      "[5.643445] 9.483\n",
      "[5.665006] 5.017\n",
      "[5.626425] 5.183\n",
      "[5.6447716] 3.267\n",
      "[5.611907] 7.35\n",
      "[5.6393614] 5.767\n",
      "[5.656491] 1.333\n",
      "[5.6962132] 4.683\n",
      "[5.688232] 6.233\n",
      "[5.71706] 5.683\n",
      "[5.685358] 11.867\n",
      "[5.600936] 0.25\n",
      "[5.612886] 8.25\n",
      "[5.681468] 2.717\n",
      "[5.6710415] 0.317\n",
      "[5.708584] 6.8\n",
      "[5.666677] 10.867\n",
      "[5.7234454] 1.517\n",
      "[5.62155] 4.9\n",
      "[5.695781] 7.383\n",
      "[5.6891313] 11.567\n",
      "[5.6510463] 10.7\n",
      "[5.6382384] 10.317\n",
      "[5.576394] 9.15\n",
      "[5.6980896] 9.417\n",
      "[5.6471725] 10.917\n",
      "[5.6453295] 10.067\n",
      "[5.6818166] 8.867\n",
      "[5.635755] 10.483\n",
      "[5.7116413] 2.217\n",
      "[5.6020474] 0.933\n",
      "[5.58645] 4.983\n",
      "[5.6592684] 0.15\n",
      "[5.5635023] 11.217\n",
      "[5.6700573] 2.233\n",
      "[5.660225] 11.667\n",
      "[5.628913] 2.05\n",
      "[5.6994987] 7.983\n",
      "[5.640337] 10.983\n",
      "[5.641242] 2.233\n",
      "[5.5730433] 4.783\n",
      "[5.701149] 10.95\n",
      "[5.6394553] 11.333\n",
      "[5.6400776] 8.567\n",
      "[5.5687776] 9.2\n",
      "[5.661225] 3.0\n",
      "[5.6504903] 5.317\n",
      "[5.644073] 11.2\n",
      "[5.6861563] 1.2\n",
      "[5.6282763] 5.867\n",
      "[5.7429695] 5.0\n",
      "[5.729404] 11.217\n",
      "[5.67496] 7.0\n",
      "[5.6363916] 7.233\n",
      "[5.604389] 8.3\n",
      "[5.6657667] 9.65\n",
      "[5.6489964] 2.883\n",
      "[5.6939864] 4.567\n",
      "[5.66439] 2.617\n",
      "[5.624847] 11.017\n",
      "[5.670594] 10.333\n",
      "[5.663237] 2.633\n",
      "[5.6960864] 2.7\n",
      "[5.7008514] 1.983\n",
      "[5.6424108] 9.817\n",
      "[5.6906304] 10.75\n",
      "[5.6888356] 0.85\n",
      "[5.672928] 7.683\n",
      "[5.709172] 4.867\n",
      "[5.5677543] 2.95\n",
      "[5.577526] 0.217\n",
      "[5.6592684] 3.567\n",
      "[5.6781363] 7.1\n",
      "[5.705947] 2.6\n",
      "[5.662363] 5.75\n",
      "[5.6596775] 5.067\n",
      "[5.710528] 6.6\n",
      "[5.6222024] 7.333\n",
      "[5.5822597] 2.117\n",
      "[5.628] 3.8\n",
      "[5.637503] 2.117\n",
      "[5.6536016] 6.667\n",
      "[5.663988] 7.883\n",
      "[5.6581926] 9.833\n",
      "[5.6248045] 2.367\n",
      "[5.6434345] 8.917\n",
      "[5.6579046] 6.55\n",
      "[5.592797] 10.617\n",
      "[5.634421] 11.1\n",
      "[5.644103] 0.017\n",
      "[5.650658] 10.15\n",
      "[5.602423] 3.95\n",
      "[5.664582] 4.3\n",
      "[5.656692] 2.517\n",
      "[5.6547546] 9.4\n",
      "[5.704487] 7.917\n",
      "[5.6745043] 7.3\n",
      "[5.6573563] 0.533\n",
      "[5.6881814] 6.0\n",
      "[5.7137547] 11.167\n",
      "[5.7284207] 8.483\n",
      "[5.665756] 8.933\n",
      "[5.5670986] 7.633\n",
      "[5.648351] 0.983\n",
      "[5.6031704] 7.25\n",
      "[5.6701574] 1.767\n",
      "[5.5980144] 1.483\n",
      "[5.637686] 7.033\n",
      "[5.730258] 7.25\n",
      "[5.6456523] 0.083\n",
      "[5.691787] 5.067\n",
      "[5.665258] 10.75\n",
      "[5.642861] 1.25\n",
      "[5.617393] 5.45\n",
      "[5.722937] 1.617\n",
      "[5.651877] 10.9\n",
      "[5.6438017] 10.4\n",
      "[5.6838455] 1.2\n",
      "[5.6739945] 3.517\n",
      "[5.619567] 0.35\n",
      "[5.6261225] 5.217\n",
      "[5.68697] 3.683\n",
      "[5.6235604] 7.05\n",
      "[5.600557] 0.15\n",
      "[5.625115] 5.1\n",
      "[5.7244635] 10.05\n",
      "[5.6172514] 5.633\n",
      "[5.6349015] 1.983\n",
      "[5.6647615] 8.567\n",
      "[5.6889243] 9.4\n",
      "[5.6725736] 11.617\n",
      "[5.6181974] 9.233\n",
      "[5.6474123] 0.017\n",
      "[5.6633434] 0.1\n",
      "[5.690891] 0.067\n",
      "[5.656164] 11.417\n",
      "[5.655281] 6.417\n",
      "[5.646378] 0.833\n",
      "[5.6100454] 1.85\n",
      "[5.672638] 10.917\n",
      "[5.604958] 8.733\n",
      "[5.6874814] 8.417\n",
      "[5.7036858] 10.633\n",
      "[5.7047377] 5.883\n",
      "[5.635287] 8.85\n",
      "[5.698071] 3.967\n",
      "[5.710685] 11.883\n",
      "[5.684276] 6.6\n",
      "[5.7068624] 0.083\n",
      "[5.6511354] 1.783\n",
      "[5.698552] 10.317\n",
      "[5.559227] 2.75\n",
      "[5.706129] 7.783\n",
      "[5.6311326] 4.3\n",
      "[5.6432276] 3.183\n",
      "[5.6754723] 3.417\n",
      "[5.6892347] 1.133\n",
      "[5.6876593] 10.85\n",
      "[5.6854677] 5.3\n",
      "[5.641846] 6.217\n",
      "[5.702078] 6.233\n",
      "[5.691146] 6.917\n",
      "[5.6374917] 6.95\n",
      "[5.662767] 1.7\n",
      "[5.598051] 11.6\n",
      "[5.7049704] 7.933\n",
      "[5.6562543] 4.717\n",
      "[5.638457] 6.1\n",
      "[5.7251296] 7.5\n",
      "[5.7487617] 3.7\n",
      "[5.6609564] 6.15\n",
      "[5.7243814] 11.8\n",
      "[5.658875] 4.933\n",
      "[5.57842] 11.183\n",
      "[5.689518] 6.6\n",
      "[5.6656365] 7.15\n",
      "[5.70246] 7.167\n",
      "[5.665695] 10.367\n",
      "[5.632589] 10.283\n",
      "[5.621018] 5.833\n",
      "[5.616423] 1.25\n",
      "[5.6328344] 4.583\n",
      "[5.6903243] 5.25\n",
      "[5.716486] 3.05\n",
      "[5.6706266] 1.85\n",
      "[5.7218494] 3.967\n",
      "[5.6806064] 8.7\n",
      "[5.637791] 11.45\n",
      "[5.6987143] 6.417\n",
      "[5.692216] 0.35\n",
      "[5.6597753] 0.033\n",
      "[5.617916] 11.817\n",
      "[5.689245] 6.3\n",
      "[5.6529484] 5.517\n",
      "[5.6367326] 6.267\n",
      "[5.667712] 11.1\n",
      "[5.6661377] 10.7\n",
      "[5.695971] 1.433\n",
      "[5.6797385] 3.917\n",
      "[5.658022] 3.567\n",
      "[5.6728883] 7.333\n",
      "[5.6367736] 1.033\n",
      "[5.6733494] 2.317\n",
      "[5.635494] 0.1\n",
      "[5.722998] 10.117\n",
      "[5.628134] 2.85\n",
      "[5.7038145] 8.25\n",
      "[5.680678] 10.233\n",
      "[5.609648] 10.967\n",
      "[5.6627755] 2.333\n",
      "[5.666205] 11.2\n",
      "[5.6955643] 10.883\n",
      "[5.642397] 1.133\n",
      "[5.6068144] 4.8\n",
      "[5.616692] 0.517\n",
      "[5.6797986] 10.15\n",
      "[5.5756426] 5.4\n",
      "[5.6484456] 0.617\n",
      "[5.6001873] 3.983\n",
      "[5.692107] 3.333\n",
      "[5.5937753] 0.25\n",
      "[5.627481] 11.383\n",
      "[5.7349424] 6.05\n",
      "[5.653217] 3.25\n",
      "[5.680836] 6.667\n",
      "[5.6809454] 9.267\n",
      "[5.6257033] 9.133\n",
      "[5.638708] 8.867\n",
      "[5.6227565] 0.667\n",
      "[5.66399] 7.0\n",
      "[5.6966996] 0.817\n",
      "[5.700128] 2.0\n",
      "[5.6499987] 8.1\n",
      "[5.619711] 3.283\n",
      "[5.668213] 5.817\n",
      "[5.626225] 4.267\n",
      "[5.690325] 6.75\n",
      "[5.6805916] 4.4\n",
      "[5.544102] 7.817\n",
      "[5.7010503] 6.467\n",
      "[5.6487894] 10.167\n",
      "[5.693376] 9.4\n",
      "[5.660192] 4.683\n",
      "[5.650221] 3.217\n",
      "[5.6941323] 3.383\n",
      "[5.6596327] 10.083\n",
      "[5.6540623] 9.75\n",
      "[5.603807] 4.667\n",
      "[5.6835175] 11.55\n",
      "[5.7217727] 9.433\n",
      "[5.688189] 10.8\n",
      "[5.662879] 1.3\n",
      "[5.6747427] 5.0\n",
      "[5.655555] 4.35\n",
      "[5.6966124] 4.4\n",
      "[5.69043] 5.8\n",
      "[5.65754] 11.383\n",
      "[5.6289096] 3.083\n",
      "[5.6582127] 9.817\n",
      "[5.635218] 5.533\n",
      "[5.6861877] 0.333\n",
      "[5.69491] 6.467\n",
      "[5.6023436] 6.7\n",
      "[5.652584] 0.95\n",
      "[5.6059403] 5.633\n",
      "[5.7191997] 4.817\n",
      "[5.6238017] 3.133\n",
      "[5.666157] 11.45\n",
      "[5.6407614] 1.167\n",
      "[5.617406] 4.267\n",
      "[5.6890817] 11.867\n",
      "[5.636107] 3.9\n",
      "[5.653527] 9.833\n",
      "[5.6894197] 0.883\n",
      "[5.6376567] 7.583\n",
      "[5.609029] 11.05\n",
      "[5.726584] 4.333\n",
      "[5.604775] 3.733\n",
      "[5.6069717] 0.317\n",
      "[5.7013483] 9.367\n",
      "[5.6675243] 7.15\n",
      "[5.629992] 7.067\n",
      "[5.585216] 11.033\n",
      "[5.676492] 0.25\n",
      "[5.689352] 11.95\n",
      "[5.612707] 1.983\n",
      "[5.610343] 6.617\n",
      "[5.588789] 5.067\n",
      "[5.6650853] 0.683\n",
      "[5.616828] 6.383\n",
      "[5.6201735] 6.35\n",
      "[5.7019577] 2.6\n",
      "[5.716542] 7.517\n",
      "[5.6460524] 3.45\n",
      "[5.7123356] 8.317\n",
      "[5.627233] 5.0\n",
      "[5.690993] 7.75\n",
      "[5.613787] 10.2\n",
      "[5.66718] 7.017\n",
      "[5.635941] 2.15\n",
      "[5.6422257] 3.467\n",
      "[5.6243258] 10.683\n",
      "[5.5844274] 0.517\n",
      "[5.6365285] 4.2\n",
      "[5.640725] 9.75\n",
      "[5.652367] 9.633\n",
      "[5.6989636] 8.433\n",
      "[5.5946026] 5.967\n",
      "[5.69398] 8.833\n",
      "[5.6376357] 3.05\n",
      "[5.676167] 0.317\n",
      "[5.6755095] 3.95\n",
      "[5.6831927] 3.45\n",
      "[5.707671] 2.367\n",
      "[5.690904] 9.583\n",
      "[5.624825] 5.767\n",
      "[5.704024] 11.5\n",
      "[5.6933727] 1.367\n",
      "[5.6753573] 7.3\n",
      "[5.5912356] 11.35\n",
      "[5.7070403] 11.533\n",
      "[5.6744204] 2.6\n",
      "[5.6963415] 10.483\n",
      "[5.6627727] 4.8\n",
      "[5.640381] 7.083\n",
      "[5.692539] 4.1\n",
      "[5.6517267] 2.8\n",
      "[5.704108] 7.067\n",
      "[5.700097] 8.917\n",
      "[5.6055737] 2.4\n",
      "[5.686413] 9.933\n",
      "[5.631995] 4.833\n",
      "[5.665085] 9.717\n",
      "[5.6554484] 7.35\n",
      "[5.684174] 10.0\n",
      "[5.6424565] 6.333\n",
      "[5.6722755] 3.85\n",
      "[5.7227693] 5.05\n",
      "[5.676834] 0.183\n",
      "[5.6139984] 1.55\n",
      "[5.599518] 4.9\n",
      "[5.657861] 6.317\n",
      "[5.6431227] 2.25\n",
      "[5.656237] 7.633\n",
      "[5.6343684] 7.083\n",
      "[5.7082624] 7.1\n",
      "[5.6659155] 9.2\n",
      "[5.652605] 11.233\n",
      "[5.6910625] 7.917\n",
      "[5.6367173] 7.15\n",
      "[5.6327558] 6.067\n",
      "[5.689] 11.317\n",
      "[5.6270523] 1.3\n",
      "[5.6326647] 1.45\n",
      "[5.640407] 6.833\n",
      "[5.595656] 2.133\n",
      "[5.73416] 9.183\n",
      "[5.543411] 4.317\n",
      "[5.67369] 5.55\n",
      "[5.603682] 10.883\n",
      "[5.6961846] 11.05\n",
      "[5.675247] 11.25\n",
      "[5.644985] 1.617\n",
      "[5.6985064] 2.85\n",
      "[5.687349] 9.233\n",
      "[5.687387] 8.017\n",
      "[5.641746] 2.383\n",
      "[5.6269054] 8.933\n",
      "[5.6321993] 2.617\n",
      "[5.7004795] 10.4\n",
      "[5.6548324] 5.05\n",
      "[5.707908] 4.35\n",
      "[5.5841947] 4.983\n",
      "[5.618494] 11.183\n",
      "[5.6699257] 3.067\n",
      "[5.6568274] 7.533\n",
      "[5.609083] 2.667\n",
      "[5.6960835] 7.4\n",
      "[5.643704] 9.433\n",
      "[5.709421] 0.283\n",
      "[5.663181] 9.017\n",
      "[5.655103] 11.4\n",
      "[5.637167] 5.383\n",
      "[5.563955] 4.833\n",
      "[5.6415977] 1.417\n",
      "[5.699073] 10.533\n",
      "[5.7100224] 11.267\n",
      "[5.6078405] 1.983\n",
      "[5.670368] 5.35\n",
      "[5.6044893] 0.1\n",
      "[5.6370254] 4.983\n",
      "[5.682305] 7.733\n",
      "[5.6321936] 7.2\n",
      "[5.6290436] 3.883\n",
      "[5.6944942] 7.95\n",
      "[5.633011] 2.5\n",
      "[5.6469736] 9.133\n",
      "[5.6666713] 9.0\n",
      "[5.6811576] 7.533\n",
      "[5.747887] 9.517\n",
      "[5.6392965] 9.383\n",
      "[5.6599035] 0.8\n",
      "[5.6425624] 2.333\n",
      "[5.6254697] 4.733\n",
      "[5.6565366] 0.617\n",
      "[5.668479] 11.35\n",
      "[5.6528263] 0.467\n",
      "[5.6871347] 9.283\n",
      "[5.6200724] 2.833\n",
      "[5.736403] 11.75\n",
      "[5.648234] 0.167\n",
      "[5.628507] 2.1\n",
      "[5.7017384] 11.167\n",
      "[5.6861715] 11.067\n",
      "[5.7145743] 1.883\n",
      "[5.704275] 10.217\n",
      "[5.6377625] 11.167\n",
      "[5.664659] 8.6\n",
      "[5.700656] 1.367\n",
      "[5.6165876] 0.983\n",
      "[5.662472] 1.0\n",
      "[5.6454954] 8.45\n",
      "[5.5904875] 6.183\n",
      "[5.6672435] 9.85\n",
      "[5.5764313] 10.617\n",
      "[5.6621256] 10.6\n",
      "[5.6109195] 4.633\n",
      "[5.635986] 8.65\n",
      "[5.6309953] 6.033\n",
      "[5.6340866] 7.133\n",
      "[5.7109523] 11.633\n",
      "[5.6197395] 4.5\n",
      "[5.6625805] 1.65\n",
      "[5.7040353] 1.233\n",
      "[5.668935] 0.883\n",
      "[5.6009765] 9.533\n",
      "[5.674847] 1.65\n",
      "[5.6754007] 5.717\n",
      "[5.698285] 2.583\n",
      "[5.610981] 7.45\n",
      "[5.6235366] 3.517\n",
      "[5.6525583] 0.25\n",
      "[5.594844] 3.083\n",
      "[5.6362934] 10.317\n",
      "[5.612567] 4.3\n",
      "[5.5989394] 11.633\n",
      "[5.67078] 11.25\n",
      "[5.6087937] 7.517\n",
      "[5.6724777] 0.2\n",
      "[5.627811] 2.8\n",
      "[5.714251] 2.883\n",
      "[5.632881] 5.883\n",
      "[5.6367908] 2.417\n",
      "[5.71225] 6.85\n",
      "[5.647436] 11.15\n",
      "[5.6506505] 1.7\n",
      "[5.646702] 3.55\n",
      "[5.7384677] 11.233\n",
      "[5.7191243] 0.233\n",
      "[5.652407] 5.75\n",
      "[5.686833] 5.717\n",
      "[5.673065] 1.45\n",
      "[5.6410713] 8.3\n",
      "[5.620708] 8.55\n",
      "[5.649916] 0.7\n",
      "[5.5762753] 2.433\n",
      "[5.7140417] 11.667\n",
      "[5.702526] 6.733\n",
      "[5.713398] 10.333\n",
      "[5.6792493] 5.667\n",
      "[5.6540513] 2.933\n",
      "[5.606557] 0.067\n",
      "[5.6684747] 7.4\n",
      "[5.7088313] 1.433\n",
      "[5.6436934] 10.367\n",
      "[5.7005506] 5.033\n",
      "[5.6688876] 5.017\n",
      "[5.686851] 3.35\n",
      "[5.6125774] 4.617\n",
      "[5.669124] 7.55\n",
      "[5.6629133] 4.15\n",
      "[5.6775136] 2.2\n",
      "[5.68541] 3.9\n",
      "[5.70335] 6.25\n",
      "[5.6633863] 1.167\n",
      "[5.5834274] 3.617\n",
      "[5.6597676] 1.75\n",
      "[5.7071877] 0.417\n",
      "[5.666181] 9.733\n",
      "[5.712369] 10.85\n",
      "[5.5997825] 11.7\n",
      "[5.6539187] 9.817\n",
      "[5.638284] 10.383\n",
      "[5.739383] 4.283\n",
      "[5.6016483] 2.65\n",
      "[5.623761] 4.583\n",
      "[5.6400137] 0.967\n",
      "[5.6882463] 0.017\n",
      "[5.640559] 2.35\n",
      "[5.6938143] 9.05\n",
      "[5.673609] 2.417\n",
      "[5.7361073] 3.45\n",
      "[5.645741] 3.55\n",
      "[5.691068] 3.433\n",
      "[5.6106186] 1.85\n",
      "[5.6990614] 11.717\n",
      "[5.670582] 5.017\n",
      "[5.6702805] 0.967\n",
      "[5.688325] 10.9\n",
      "[5.6781435] 1.433\n",
      "[5.6523185] 3.35\n",
      "[5.6463213] 6.783\n",
      "[5.6529555] 3.2\n",
      "[5.6957345] 11.883\n",
      "[5.5352025] 6.767\n",
      "[5.692982] 9.367\n",
      "[5.636746] 9.95\n",
      "[5.6809497] 6.417\n",
      "[5.6373243] 11.1\n",
      "[5.6388607] 5.417\n",
      "[5.7139] 11.267\n",
      "[5.658243] 9.383\n",
      "[5.6573324] 1.517\n",
      "[5.657005] 10.383\n",
      "[5.670352] 1.383\n",
      "[5.6908803] 0.2\n",
      "[5.6623316] 5.733\n",
      "[5.6161532] 10.9\n",
      "[5.616382] 7.733\n",
      "[5.703891] 4.683\n",
      "[5.6476564] 6.333\n",
      "[5.6520834] 9.333\n",
      "[5.7080235] 9.767\n",
      "[5.7131443] 0.0\n",
      "[5.710001] 7.933\n",
      "[5.6344967] 0.733\n",
      "[5.640083] 7.683\n",
      "[5.6971583] 1.95\n",
      "[5.6345987] 5.3\n",
      "[5.690294] 5.833\n",
      "[5.6478724] 6.583\n",
      "[5.646663] 9.0\n",
      "[5.635051] 2.517\n",
      "[5.6729255] 9.433\n",
      "[5.670106] 3.983\n",
      "[5.648695] 5.85\n",
      "[5.727352] 4.517\n",
      "[5.6263547] 4.483\n",
      "[5.677602] 10.45\n",
      "[5.7084174] 3.267\n",
      "[5.6491413] 11.767\n",
      "[5.6583014] 3.267\n",
      "[5.686552] 9.083\n",
      "[5.644282] 2.467\n",
      "[5.6500373] 1.967\n",
      "[5.574418] 0.5\n",
      "[5.600974] 7.233\n",
      "[5.7015376] 11.367\n",
      "[5.635426] 2.083\n",
      "[5.595773] 6.317\n",
      "[5.700608] 3.85\n",
      "[5.704469] 7.533\n",
      "[5.6168513] 0.383\n",
      "[5.635376] 3.983\n",
      "[5.6292057] 6.867\n",
      "[5.6398234] 10.067\n",
      "[5.600191] 9.933\n",
      "[5.6361322] 8.117\n",
      "[5.595666] 7.817\n",
      "[5.6310887] 5.133\n",
      "[5.6160135] 6.5\n",
      "[5.644302] 3.917\n",
      "[5.653023] 7.467\n",
      "[5.6532617] 2.633\n",
      "[5.6372905] 6.483\n",
      "[5.6213984] 0.533\n",
      "[5.5746694] 5.533\n",
      "[5.6722164] 6.95\n",
      "[5.6165004] 2.783\n",
      "[5.646934] 11.367\n",
      "[5.641156] 5.817\n",
      "[5.6352034] 9.033\n",
      "[5.652659] 5.983\n",
      "[5.676034] 9.6\n",
      "[5.6603823] 7.3\n",
      "[5.6242313] 1.417\n",
      "[5.5811644] 5.933\n",
      "[5.693512] 10.733\n",
      "[5.5972853] 1.483\n",
      "[5.6059194] 1.233\n",
      "[5.706289] 10.75\n",
      "[5.6353426] 11.917\n",
      "[5.6604896] 2.9\n",
      "[5.6279845] 5.117\n",
      "[5.690693] 0.5\n",
      "[5.6306305] 8.617\n",
      "[5.6701226] 10.167\n",
      "[5.670958] 2.233\n",
      "[5.604511] 1.867\n",
      "[5.7317834] 3.75\n",
      "[5.62459] 4.2\n",
      "[5.667233] 4.617\n",
      "[5.6245184] 8.067\n",
      "[5.5604224] 1.75\n",
      "[5.7176785] 0.833\n",
      "[5.6264057] 5.767\n",
      "[5.563897] 10.083\n",
      "[5.6773806] 5.367\n",
      "[5.6047835] 7.367\n",
      "[5.6753063] 6.7\n",
      "[5.6489725] 7.817\n",
      "[5.6720085] 2.583\n",
      "[5.6800447] 11.367\n",
      "[5.617793] 0.383\n",
      "[5.6220293] 8.717\n",
      "[5.632075] 0.033\n",
      "[5.7308927] 4.85\n",
      "[5.6390224] 7.467\n",
      "[5.607435] 3.65\n",
      "[5.592509] 4.067\n",
      "[5.6139493] 3.283\n",
      "[5.6881127] 7.7\n",
      "[5.6431623] 9.683\n",
      "[5.649273] 9.067\n",
      "[5.613059] 1.05\n",
      "[5.690638] 0.483\n",
      "[5.7381563] 0.9\n",
      "[5.73177] 8.95\n",
      "[5.6348424] 9.267\n",
      "[5.6870775] 8.1\n",
      "[5.660807] 2.017\n",
      "[5.617542] 6.317\n",
      "[5.685692] 1.2\n",
      "[5.6713014] 11.117\n",
      "[5.676207] 1.0\n",
      "[5.6645026] 0.8\n",
      "[5.607078] 2.367\n",
      "[5.7115273] 9.233\n",
      "[5.6304097] 6.717\n",
      "[5.686234] 8.717\n",
      "[5.636885] 6.85\n",
      "[5.644834] 9.383\n",
      "[5.654684] 6.9\n",
      "[5.679567] 6.15\n",
      "[5.6524734] 11.667\n",
      "[5.7063875] 1.2\n",
      "[5.60973] 11.483\n",
      "[5.686786] 3.5\n",
      "[5.613683] 5.867\n",
      "[5.6346235] 3.117\n",
      "[5.557349] 8.183\n",
      "[5.624258] 4.95\n",
      "[5.686741] 1.383\n",
      "[5.698542] 9.817\n",
      "[5.6536446] 7.917\n",
      "[5.6494207] 1.0\n",
      "[5.6815705] 1.3\n",
      "[5.66304] 3.767\n",
      "[5.658405] 6.883\n",
      "[5.7124023] 4.1\n",
      "[5.604477] 3.983\n",
      "[5.706496] 7.533\n",
      "[5.673625] 9.417\n",
      "[5.679007] 7.05\n",
      "[5.665783] 4.133\n",
      "[5.666613] 8.9\n",
      "[5.600027] 5.933\n",
      "[5.7248974] 10.983\n",
      "[5.6825266] 0.7\n",
      "[5.6137066] 5.617\n",
      "[5.6877456] 0.317\n",
      "[5.6609225] 11.633\n",
      "[5.634998] 9.25\n",
      "[5.638265] 2.467\n",
      "[5.68499] 10.883\n",
      "[5.5588946] 6.567\n",
      "[5.675346] 7.0\n",
      "[5.635948] 2.45\n",
      "[5.682909] 8.583\n",
      "[5.72048] 0.683\n",
      "[5.711351] 0.517\n",
      "[5.6565256] 0.333\n",
      "[5.5744314] 9.167\n",
      "[5.650403] 6.8\n",
      "[5.642857] 4.9\n",
      "[5.687346] 0.683\n",
      "[5.6051774] 11.267\n",
      "[5.650856] 4.55\n",
      "[5.633848] 11.817\n",
      "[5.666486] 4.417\n",
      "[5.6697564] 6.867\n",
      "[5.6260715] 0.533\n",
      "[5.733459] 11.033\n",
      "[5.7069774] 2.233\n",
      "[5.7065086] 11.767\n",
      "[5.616871] 10.033\n",
      "[5.6827326] 9.117\n",
      "[5.698977] 3.25\n",
      "[5.6443715] 11.833\n",
      "[5.5906262] 3.3\n",
      "[5.627615] 5.717\n",
      "[5.5826306] 11.433\n",
      "[5.6898003] 1.267\n",
      "[5.628303] 7.017\n",
      "[5.6673408] 8.05\n",
      "[5.6315856] 9.85\n",
      "[5.700661] 5.583\n",
      "[5.6769333] 6.95\n",
      "[5.6961126] 1.067\n",
      "[5.657561] 7.7\n",
      "[5.6619983] 10.017\n",
      "[5.7019615] 2.75\n",
      "[5.707369] 3.133\n",
      "[5.637667] 5.333\n",
      "[5.6865335] 1.067\n",
      "[5.6251] 1.7\n",
      "[5.7000256] 4.05\n",
      "[5.619413] 7.8\n",
      "[5.6548185] 10.517\n",
      "[5.5745225] 4.367\n",
      "[5.7235856] 8.483\n",
      "[5.7024317] 4.8\n",
      "[5.7013288] 1.3\n",
      "[5.702088] 11.1\n",
      "[5.6752605] 2.1\n",
      "[5.658547] 10.067\n",
      "[5.6682057] 8.3\n",
      "[5.65923] 7.65\n",
      "[5.6490035] 5.033\n",
      "[5.5951843] 2.45\n",
      "[5.6714745] 9.233\n",
      "[5.6644635] 7.95\n",
      "[5.649171] 11.767\n",
      "[5.606446] 8.85\n",
      "[5.707318] 11.933\n",
      "[5.6345406] 8.833\n",
      "[5.6908045] 6.05\n",
      "[5.600781] 0.067\n",
      "[5.6053805] 0.117\n",
      "[5.6878986] 3.45\n",
      "[5.6755805] 5.9\n",
      "[5.676715] 10.117\n",
      "[5.651916] 1.133\n",
      "[5.676324] 9.917\n",
      "[5.645226] 6.783\n",
      "[5.6505] 3.2\n",
      "[5.6593037] 6.783\n",
      "[5.5996366] 0.567\n",
      "[5.6937103] 1.3\n",
      "[5.699319] 11.783\n",
      "[5.667057] 6.633\n",
      "[5.6264405] 11.367\n",
      "[5.6560035] 7.717\n",
      "[5.6288323] 0.117\n",
      "[5.643586] 8.45\n",
      "[5.69187] 5.067\n",
      "[5.6497936] 5.2\n",
      "[5.61863] 5.667\n",
      "[5.649782] 8.217\n",
      "[5.6487093] 7.95\n",
      "[5.675133] 1.533\n",
      "[5.6935377] 6.983\n",
      "[5.6711783] 4.667\n",
      "[5.603313] 1.8\n",
      "[5.6327] 4.35\n",
      "[5.5417194] 2.75\n",
      "[5.6211247] 3.517\n",
      "[5.5576177] 7.4\n",
      "[5.6593127] 11.067\n",
      "[5.7130647] 3.017\n",
      "[5.584981] 5.667\n",
      "[5.6935344] 6.817\n",
      "[5.66013] 6.933\n",
      "[5.657267] 8.733\n",
      "[5.6488113] 4.667\n",
      "[5.6397443] 6.783\n",
      "[5.6809916] 10.683\n",
      "[5.568194] 4.217\n",
      "[5.7312264] 9.117\n",
      "[5.724871] 9.883\n",
      "[5.67963] 8.317\n",
      "[5.6737056] 9.267\n",
      "[5.670662] 0.4\n",
      "[5.66862] 11.217\n",
      "[5.6686354] 7.533\n",
      "[5.6771607] 1.05\n",
      "[5.645982] 1.75\n",
      "[5.631362] 10.333\n",
      "[5.6273556] 2.117\n",
      "[5.697077] 5.033\n",
      "[5.6675067] 9.45\n",
      "[5.6593356] 4.217\n",
      "[5.636633] 4.867\n",
      "[5.666767] 11.183\n",
      "[5.676209] 3.6\n",
      "[5.651197] 3.483\n",
      "[5.6793065] 0.833\n",
      "[5.688241] 5.533\n",
      "[5.677302] 5.233\n",
      "[5.729852] 3.283\n",
      "[5.6334233] 2.35\n",
      "[5.5871854] 5.567\n",
      "[5.728269] 5.617\n",
      "[5.5988336] 7.633\n",
      "[5.6344695] 7.85\n",
      "[5.6665535] 6.083\n",
      "[5.731677] 11.983\n",
      "[5.652249] 4.0\n",
      "[5.721127] 8.567\n",
      "[5.6449676] 2.583\n",
      "[5.631866] 4.483\n",
      "[5.6684113] 5.233\n",
      "[5.6200933] 1.517\n",
      "[5.6421676] 11.467\n",
      "[5.6335816] 7.8\n",
      "[5.6989455] 9.9\n",
      "[5.6842012] 2.35\n",
      "[5.6770377] 0.433\n",
      "[5.6611037] 9.95\n",
      "[5.660987] 4.583\n",
      "[5.621834] 6.583\n",
      "[5.69343] 1.533\n",
      "[5.6886234] 8.1\n",
      "[5.606291] 4.95\n",
      "[5.639327] 2.667\n",
      "[5.6999106] 10.367\n",
      "[5.6435723] 0.483\n",
      "[5.6011353] 6.367\n",
      "[5.593795] 7.833\n",
      "[5.6413703] 8.35\n",
      "[5.6883836] 0.617\n",
      "[5.7172995] 8.55\n",
      "[5.6757417] 3.133\n",
      "[5.6333995] 8.717\n",
      "[5.687063] 3.85\n",
      "[5.711921] 4.033\n",
      "[5.6717567] 9.067\n",
      "[5.710558] 6.183\n",
      "[5.6222715] 5.883\n",
      "[5.640502] 3.0\n",
      "[5.693804] 6.667\n",
      "[5.656658] 7.9\n",
      "[5.727426] 4.317\n",
      "[5.630887] 0.1\n",
      "[5.5923653] 0.383\n",
      "[5.603744] 9.067\n",
      "[5.6493955] 1.25\n",
      "[5.686009] 1.883\n",
      "[5.6887283] 3.867\n",
      "[5.6687407] 3.55\n",
      "[5.695831] 0.583\n",
      "[5.6877985] 2.5\n",
      "[5.695359] 5.45\n",
      "[5.665655] 9.867\n",
      "[5.7255454] 0.383\n",
      "[5.6667566] 9.917\n",
      "[5.6374254] 9.05\n",
      "[5.620945] 1.5\n",
      "[5.605799] 4.3\n",
      "[5.6262417] 4.733\n",
      "[5.6516347] 9.967\n",
      "[5.6595054] 5.933\n",
      "[5.670177] 3.7\n",
      "[5.61692] 10.783\n",
      "[5.6398864] 9.15\n",
      "[5.6712813] 3.35\n",
      "[5.640392] 8.25\n",
      "[5.6288414] 1.967\n",
      "[5.6803656] 7.767\n",
      "[5.6089525] 8.55\n",
      "[5.6959615] 10.65\n",
      "[5.6940966] 2.417\n",
      "[5.643305] 8.05\n",
      "[5.606456] 2.917\n",
      "[5.6565924] 6.983\n",
      "[5.6893106] 11.2\n",
      "[5.62016] 2.817\n",
      "[5.6062284] 11.25\n",
      "[5.6829624] 6.817\n",
      "[5.603857] 8.117\n",
      "[5.619374] 8.2\n",
      "[5.7228565] 7.767\n",
      "[5.640977] 4.4\n",
      "[5.6232715] 6.317\n",
      "[5.6893134] 10.75\n",
      "[5.6754003] 9.15\n",
      "[5.69033] 10.267\n",
      "[5.626383] 10.7\n",
      "[5.6443257] 11.4\n",
      "[5.6612425] 7.6\n",
      "[5.6615977] 2.633\n",
      "[5.64084] 0.3\n",
      "[5.6752834] 0.717\n",
      "[5.6477466] 0.75\n",
      "[5.632319] 5.883\n",
      "[5.678142] 6.35\n",
      "[5.6485143] 11.783\n",
      "[5.6133466] 9.517\n",
      "[5.605791] 8.783\n",
      "[5.669813] 5.883\n",
      "[5.6699715] 4.85\n",
      "[5.7148013] 7.5\n",
      "[5.6951537] 9.1\n",
      "[5.662559] 1.417\n",
      "[5.7016916] 3.85\n",
      "[5.6527643] 3.4\n",
      "[5.6267285] 0.933\n",
      "[5.6700335] 3.967\n",
      "[5.714681] 10.417\n",
      "[5.668794] 10.583\n",
      "[5.6456766] 0.483\n",
      "[5.67236] 8.033\n",
      "[5.620779] 10.65\n",
      "[5.5960865] 0.233\n",
      "[5.685137] 2.383\n",
      "[5.67466] 0.183\n",
      "[5.6868443] 3.15\n",
      "[5.6018353] 1.367\n",
      "[5.703187] 11.533\n",
      "[5.6497493] 2.567\n",
      "[5.6818094] 4.833\n",
      "[5.6606703] 1.883\n",
      "[5.669617] 5.383\n",
      "[5.673735] 9.9\n",
      "[5.608783] 9.6\n",
      "[5.6420045] 3.817\n",
      "[5.658087] 11.4\n",
      "[5.581194] 10.8\n",
      "[5.6757503] 6.55\n",
      "[5.617749] 9.7\n",
      "[5.6540694] 2.117\n",
      "[5.662058] 9.033\n",
      "[5.63002] 8.55\n",
      "[5.6697206] 10.967\n",
      "[5.6424413] 6.833\n",
      "[5.6235948] 11.833\n",
      "[5.5999465] 4.133\n",
      "[5.7321277] 0.767\n",
      "[5.643939] 1.5\n",
      "[5.720856] 1.5\n",
      "[5.6566725] 6.183\n",
      "[5.724143] 8.783\n",
      "[5.703422] 6.167\n",
      "[5.7052565] 1.217\n",
      "[5.666822] 11.25\n",
      "[5.6648498] 7.733\n",
      "[5.627299] 7.317\n",
      "[5.681189] 2.733\n",
      "[5.6202416] 10.5\n",
      "[5.705532] 5.4\n",
      "[5.641852] 7.167\n",
      "[5.657918] 3.6\n",
      "[5.625802] 8.367\n",
      "[5.7127557] 0.567\n",
      "[5.6953897] 6.833\n",
      "[5.6517544] 10.483\n",
      "[5.6300917] 8.467\n",
      "[5.6502523] 1.25\n",
      "[5.6362915] 9.0\n",
      "[5.6792097] 9.483\n",
      "[5.647515] 8.283\n",
      "[5.688694] 3.167\n",
      "[5.673548] 2.05\n",
      "[5.590025] 1.317\n",
      "[5.660485] 9.583\n",
      "[5.6912317] 6.75\n",
      "[5.7051024] 4.117\n",
      "[5.707018] 10.75\n",
      "[5.6728168] 1.85\n",
      "[5.6830955] 5.717\n",
      "[5.707416] 10.25\n",
      "[5.6913514] 10.267\n",
      "[5.632146] 7.25\n",
      "[5.6777945] 8.25\n",
      "[5.655497] 10.267\n",
      "[5.661056] 7.9\n",
      "[5.6680536] 1.1\n",
      "[5.5946417] 9.117\n",
      "[5.6520243] 3.717\n",
      "[5.6495457] 11.55\n",
      "[5.6405473] 6.2\n",
      "[5.671545] 5.333\n",
      "[5.6320767] 7.7\n",
      "[5.703569] 11.583\n",
      "[5.6639566] 0.8\n",
      "[5.6828003] 4.217\n",
      "[5.717837] 5.833\n",
      "[5.6527643] 5.533\n",
      "[5.652837] 2.117\n",
      "[5.647474] 5.667\n",
      "[5.6949873] 0.733\n",
      "[5.6521] 5.717\n",
      "[5.633126] 2.167\n",
      "[5.6906624] 8.267\n",
      "[5.7147837] 10.667\n",
      "[5.678177] 6.233\n",
      "[5.649713] 2.9\n",
      "[5.6363096] 7.017\n",
      "[5.6720757] 3.15\n",
      "[5.7127357] 3.367\n",
      "[5.6300154] 8.75\n",
      "[5.670474] 0.133\n",
      "[5.628838] 11.983\n",
      "[5.6654496] 5.517\n",
      "[5.664986] 3.0\n",
      "[5.6415586] 0.6\n",
      "[5.6732173] 5.733\n",
      "[5.6350303] 1.05\n",
      "[5.6284823] 10.4\n",
      "[5.6319427] 1.817\n",
      "[5.6452594] 11.7\n",
      "[5.638966] 11.7\n",
      "[5.622792] 11.833\n",
      "[5.6362133] 2.0\n",
      "[5.6865172] 6.983\n",
      "0.18200617283950618 %\n"
     ]
    }
   ],
   "source": [
    "reg_preds = model.predict(test_imgs)\n",
    "for i in range(len(reg_preds)):\n",
    "    print(reg_preds[i], test_labels_reg[i])\n",
    "accuracy = np.mean(abs(reg_preds - test_labels_reg) < 0.01)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Headed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hours = train_labels[:, 0]\n",
    "train_minutes = train_labels[:, 1]\n",
    "\n",
    "val_hours = val_labels[:, 0]\n",
    "val_minutes = val_labels[:, 1]\n",
    "\n",
    "test_hours = test_labels[:, 0]\n",
    "test_minutes = test_labels[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - hour_accuracy: 0.0808 - hour_loss: 2.4887 - loss: 838.4274 - minute_loss: 835.5597 - minute_mae: 23.9306 - val_hour_accuracy: 0.0839 - val_hour_loss: 2.4879 - val_loss: 318.8836 - val_minute_loss: 316.8258 - val_minute_mae: 15.3285\n",
      "Epoch 2/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0845 - hour_loss: 2.4889 - loss: 322.3623 - minute_loss: 319.8416 - minute_mae: 15.2535 - val_hour_accuracy: 0.0861 - val_hour_loss: 2.4912 - val_loss: 308.0358 - val_minute_loss: 305.8560 - val_minute_mae: 15.1308\n",
      "Epoch 3/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0859 - hour_loss: 2.4869 - loss: 303.3432 - minute_loss: 300.8137 - minute_mae: 14.9939 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4906 - val_loss: 303.1655 - val_minute_loss: 300.7621 - val_minute_mae: 15.0053\n",
      "Epoch 4/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0851 - hour_loss: 2.4860 - loss: 308.8290 - minute_loss: 306.3998 - minute_mae: 15.0812 - val_hour_accuracy: 0.0861 - val_hour_loss: 2.4855 - val_loss: 307.2587 - val_minute_loss: 304.7551 - val_minute_mae: 15.0586\n",
      "Epoch 5/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0800 - hour_loss: 2.4849 - loss: 308.0735 - minute_loss: 305.5131 - minute_mae: 15.0964 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4855 - val_loss: 304.4749 - val_minute_loss: 302.2079 - val_minute_mae: 15.0546\n",
      "Epoch 6/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0859 - hour_loss: 2.4849 - loss: 307.2395 - minute_loss: 304.7410 - minute_mae: 15.0913 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 304.9265 - val_minute_loss: 302.6581 - val_minute_mae: 15.0636\n",
      "Epoch 7/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0847 - hour_loss: 2.4850 - loss: 305.2268 - minute_loss: 302.7821 - minute_mae: 15.0287 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4858 - val_loss: 310.6407 - val_minute_loss: 308.4510 - val_minute_mae: 15.1744\n",
      "Epoch 8/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - hour_accuracy: 0.0832 - hour_loss: 2.4850 - loss: 304.0051 - minute_loss: 301.5880 - minute_mae: 14.9766 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 304.2296 - val_minute_loss: 301.9323 - val_minute_mae: 15.0450\n",
      "Epoch 9/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0835 - hour_loss: 2.4849 - loss: 304.1098 - minute_loss: 301.5475 - minute_mae: 14.9583 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 322.4780 - val_minute_loss: 320.3845 - val_minute_mae: 15.3852\n",
      "Epoch 10/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0833 - hour_loss: 2.4849 - loss: 305.1005 - minute_loss: 302.6041 - minute_mae: 14.9573 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 305.9532 - val_minute_loss: 303.6636 - val_minute_mae: 15.0787\n",
      "Epoch 11/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0868 - hour_loss: 2.4848 - loss: 303.1096 - minute_loss: 300.6066 - minute_mae: 14.9735 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 307.2397 - val_minute_loss: 304.6186 - val_minute_mae: 15.0418\n",
      "Epoch 12/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0863 - hour_loss: 2.4848 - loss: 306.4479 - minute_loss: 303.8913 - minute_mae: 15.0536 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 302.1205 - val_minute_loss: 299.7341 - val_minute_mae: 14.9868\n",
      "Epoch 13/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0856 - hour_loss: 2.4847 - loss: 302.9499 - minute_loss: 300.5273 - minute_mae: 14.9932 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4856 - val_loss: 313.6602 - val_minute_loss: 311.4506 - val_minute_mae: 15.2067\n",
      "Epoch 14/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0863 - hour_loss: 2.4848 - loss: 306.8985 - minute_loss: 304.4621 - minute_mae: 15.0560 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 300.6724 - val_minute_loss: 298.1796 - val_minute_mae: 14.9378\n",
      "Epoch 15/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0876 - hour_loss: 2.4848 - loss: 305.8167 - minute_loss: 303.3109 - minute_mae: 15.0096 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 309.0322 - val_minute_loss: 306.7843 - val_minute_mae: 15.1099\n",
      "Epoch 16/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0859 - hour_loss: 2.4848 - loss: 301.7711 - minute_loss: 299.2598 - minute_mae: 14.9462 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4858 - val_loss: 299.6266 - val_minute_loss: 297.1164 - val_minute_mae: 14.9030\n",
      "Epoch 17/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0864 - hour_loss: 2.4849 - loss: 306.9128 - minute_loss: 304.4610 - minute_mae: 15.0409 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 314.9013 - val_minute_loss: 312.1386 - val_minute_mae: 15.1350\n",
      "Epoch 18/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0853 - hour_loss: 2.4849 - loss: 305.4062 - minute_loss: 302.9399 - minute_mae: 14.9640 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4857 - val_loss: 298.4180 - val_minute_loss: 295.9067 - val_minute_mae: 14.8662\n",
      "Epoch 19/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0836 - hour_loss: 2.4849 - loss: 298.3048 - minute_loss: 295.7913 - minute_mae: 14.7812 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4858 - val_loss: 297.7803 - val_minute_loss: 295.3216 - val_minute_mae: 14.8277\n",
      "Epoch 20/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0867 - hour_loss: 2.4848 - loss: 299.2306 - minute_loss: 296.7489 - minute_mae: 14.7869 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 308.6993 - val_minute_loss: 306.0054 - val_minute_mae: 14.9913\n",
      "Epoch 21/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - hour_accuracy: 0.0844 - hour_loss: 2.4849 - loss: 301.9097 - minute_loss: 299.3268 - minute_mae: 14.8503 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 308.4829 - val_minute_loss: 305.7278 - val_minute_mae: 14.9356\n",
      "Epoch 22/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - hour_accuracy: 0.0872 - hour_loss: 2.4847 - loss: 301.1676 - minute_loss: 298.7786 - minute_mae: 14.7660 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 297.2985 - val_minute_loss: 294.5486 - val_minute_mae: 14.6891\n",
      "Epoch 23/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0833 - hour_loss: 2.4849 - loss: 293.2609 - minute_loss: 290.8000 - minute_mae: 14.5408 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 290.1761 - val_minute_loss: 287.5262 - val_minute_mae: 14.4693\n",
      "Epoch 24/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - hour_accuracy: 0.0880 - hour_loss: 2.4848 - loss: 287.7433 - minute_loss: 285.2914 - minute_mae: 14.2831 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 322.2050 - val_minute_loss: 319.7963 - val_minute_mae: 15.0085\n",
      "Epoch 25/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0842 - hour_loss: 2.4850 - loss: 302.3041 - minute_loss: 299.9163 - minute_mae: 14.6422 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 297.5887 - val_minute_loss: 294.1196 - val_minute_mae: 14.5099\n",
      "Epoch 26/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0831 - hour_loss: 2.4850 - loss: 288.0562 - minute_loss: 285.5314 - minute_mae: 14.2317 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4860 - val_loss: 278.5552 - val_minute_loss: 275.7726 - val_minute_mae: 14.0054\n",
      "Epoch 27/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0831 - hour_loss: 2.4850 - loss: 276.4994 - minute_loss: 274.0420 - minute_mae: 13.8703 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 283.6315 - val_minute_loss: 281.1789 - val_minute_mae: 13.8874\n",
      "Epoch 28/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0883 - hour_loss: 2.4848 - loss: 271.9418 - minute_loss: 269.4579 - minute_mae: 13.5834 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 263.0416 - val_minute_loss: 260.3309 - val_minute_mae: 13.2219\n",
      "Epoch 29/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - hour_accuracy: 0.0833 - hour_loss: 2.4849 - loss: 257.1381 - minute_loss: 254.7710 - minute_mae: 12.9842 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 286.2864 - val_minute_loss: 283.3994 - val_minute_mae: 13.7271\n",
      "Epoch 30/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - hour_accuracy: 0.0869 - hour_loss: 2.4849 - loss: 263.4276 - minute_loss: 261.0231 - minute_mae: 13.0866 - val_hour_accuracy: 0.0661 - val_hour_loss: 2.4859 - val_loss: 252.8348 - val_minute_loss: 249.7550 - val_minute_mae: 12.6005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x715e43f670a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = keras.layers.Input(shape = (75,75,1))\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (5,5), strides= (2,2), activation = \"relu\")(inp)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(32,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.MaxPooling2D(pool_size =2)(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (3,3),activation = \"relu\")(model)\n",
    "model = keras.layers.Convolution2D(64,kernel_size = (1,1),activation = \"relu\")(model)\n",
    "model = keras.layers.Flatten()(model)\n",
    "\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(model)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "d = keras.layers.Dropout(0.1)(d)\n",
    "d = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "\n",
    "hour = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "hour = keras.layers.Dense(128,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(64,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(32,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(16,activation = \"relu\")(hour)\n",
    "hour = keras.layers.Dense(12,activation= \"softmax\", name= \"hour\")(hour)\n",
    "\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(d)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(256,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(128,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(64,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(32,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(16,activation = \"relu\")(minute)\n",
    "minute = keras.layers.Dense(1, activation = \"softplus\", name = \"minute\")(minute)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=[hour, minute])\n",
    "optim = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=['sparse_categorical_crossentropy', 'mse'], optimizer=optim, metrics=['accuracy',\"mae\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "model.fit(train_imgs, [train_hours, train_minutes], epochs=30, batch_size = 512, validation_data = (val_imgs, [val_hours, val_minutes]), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "1.363423353909465 %\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_imgs)\n",
    "hour_p = np.argmax(predictions[0], axis = 1)\n",
    "minutes_p = predictions[1]\n",
    "\n",
    "accuracy = np.mean(np.abs(hour_p - test_hours) < 1) * np.mean(np.abs(minutes_p - test_minutes) < 5)\n",
    "print(accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Transformation using Periodic Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_time_train = (train_hours*60 + train_minutes) \n",
    "sine_time_test = (test_hours*60 + test_minutes)  \n",
    "sine_time_valid = (val_hours*60 + val_minutes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(719)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sine_time_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_angle_test = (sine_time_test/720)*2*np.pi\n",
    "sine_angle_train = (sine_time_train/720)*2*np.pi\n",
    "sine_angle_valid = (sine_time_valid/720)*2*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.1435 - mae: 0.2371 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 2/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7896e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 3/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 3.7661e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 4/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7713e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 5/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7717e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 6/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8013e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 7/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7782e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 8/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.7938e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 9/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 3.7552e-05 - mae: 0.0055 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 10/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8153e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n",
      "Epoch 11/45\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.8028e-05 - mae: 0.0056 - val_loss: 3.8348e-05 - val_mae: 0.0056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x715e14082a10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sine Regression CNN\n",
    "\n",
    "sin_reg = keras.models.Sequential()\n",
    "sin_reg.add(keras.layers.Conv2D(activation='relu', filters=32, kernel_size=(3,3), strides = (2,2),input_shape=(75, 75, 1)))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=32 ,kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "sin_reg.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "\n",
    "sin_reg.add(keras.layers.Flatten())\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dropout(0.2))\n",
    "sin_reg.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "sin_reg.add(keras.layers.Dense(units=1, activation=\"softplus\"))\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "sin_reg.compile(loss='mse', optimizer= optimizer, metrics=['mae'])\n",
    "sin_reg.fit(train_imgs, sine_angle_train, epochs=45, batch_size = 512, validation_data = (val_imgs, sine_angle_valid), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "predictions = sin_reg.predict(test_imgs)\n",
    "\n",
    "def difference_func(pred,y):\n",
    "  pred = np.transpose(pred)\n",
    "  diff_one = np.maximum(pred,y) - np.minimum(pred,y)\n",
    "  diff_two = np.minimum(pred,y) + 1 - np.maximum(pred,y)\n",
    "  return np.minimum(diff_one,diff_two)\n",
    "\n",
    "result = difference_func(predictions,sine_angle_test).reshape(-1)\n",
    "\n",
    "accuracy = np.mean(result < np.pi/6)\n",
    "print(accuracy*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
